{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM auto-encoder with bidirectional encoder and seq2seq decoder with attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "import helpers #for formatting data into batches and generating random sequence data\n",
    "\n",
    "tf.reset_default_graph() #Clears the default graph stack and resets the global default graph.\n",
    "sess = tf.InteractiveSession() #initializes a tensorflow session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.3.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PAD = 0 # padding\n",
    "BOS = 1 # Begin of sequence\n",
    "EOS = 2 # End of sequence\n",
    "\n",
    "vocab_size = 10 # max length of input sequence\n",
    "input_embedding_size = 20 #character length (vector)\n",
    "\n",
    "encoder_hidden_units = 16 #num neurons\n",
    "decoder_hidden_units = encoder_hidden_units * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#input placehodlers\n",
    "encoder_inputs = tf.placeholder(shape=(None, None), dtype=tf.int32, name='encoder_inputs')\n",
    "#contains the lengths for each of the sequence in the batch, we will pad so all the same\n",
    "#if you don't want to pad, check out dynamic memory networks to input variable length sequences\n",
    "encoder_inputs_length = tf.placeholder(shape=(None,), dtype=tf.int32, name='encoder_inputs_length')\n",
    "decoder_targets = tf.placeholder(shape=(None, None), dtype=tf.int32, name='decoder_targets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embeddings = tf.Variable(tf.random_uniform([vocab_size, input_embedding_size], -1.0, 1.0), dtype=tf.float32)\n",
    "\n",
    "#this thing could get huge in a real world application\n",
    "encoder_inputs_embedded = tf.nn.embedding_lookup(embeddings, encoder_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'embedding_lookup:0' shape=(?, ?, 20) dtype=float32>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_inputs_embedded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder\n",
    "Bidirectional encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.ops.rnn_cell import LSTMCell, LSTMStateTuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_cell =  LSTMCell(encoder_hidden_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "((encoder_fw_outputs,\n",
    "  encoder_bw_outputs),\n",
    " (encoder_fw_final_state,\n",
    "  encoder_bw_final_state)) = (\n",
    "    tf.nn.bidirectional_dynamic_rnn(cell_fw=encoder_cell,\n",
    "                                    cell_bw=encoder_cell,\n",
    "                                    inputs=encoder_inputs_embedded,\n",
    "                                    sequence_length=encoder_inputs_length,\n",
    "                                    dtype=tf.float32, time_major=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'bidirectional_rnn/fw/fw/TensorArrayStack/TensorArrayGatherV3:0' shape=(?, ?, 16) dtype=float32>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_fw_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'ReverseSequence:0' shape=(?, ?, 16) dtype=float32>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_bw_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMStateTuple(c=<tf.Tensor 'bidirectional_rnn/fw/fw/while/Exit_2:0' shape=(?, 16) dtype=float32>, h=<tf.Tensor 'bidirectional_rnn/fw/fw/while/Exit_3:0' shape=(?, 16) dtype=float32>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_fw_final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMStateTuple(c=<tf.Tensor 'bidirectional_rnn/bw/bw/while/Exit_2:0' shape=(?, 16) dtype=float32>, h=<tf.Tensor 'bidirectional_rnn/bw/bw/while/Exit_3:0' shape=(?, 16) dtype=float32>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_bw_final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Concatenates tensors along one dimension.\n",
    "encoder_outputs = tf.concat((encoder_fw_outputs, encoder_bw_outputs), 2)\n",
    "\n",
    "#letters h and c are commonly used to denote \"output value\" and \"cell state\". \n",
    "#http://colah.github.io/posts/2015-08-Understanding-LSTMs/ \n",
    "#Those tensors represent combined internal state of the cell, and should be passed together. \n",
    "\n",
    "encoder_final_state_c = tf.concat(\n",
    "    (encoder_fw_final_state.c, encoder_bw_final_state.c), 1)\n",
    "\n",
    "encoder_final_state_h = tf.concat(\n",
    "    (encoder_fw_final_state.h, encoder_bw_final_state.h), 1)\n",
    "\n",
    "#TF Tuple used by LSTM Cells for state_size, zero_state, and output state.\n",
    "encoder_final_state = LSTMStateTuple(\n",
    "    c=encoder_final_state_c,\n",
    "    h=encoder_final_state_h\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concat:0' shape=(?, ?, 32) dtype=float32>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMStateTuple(c=<tf.Tensor 'concat_1:0' shape=(?, 32) dtype=float32>, h=<tf.Tensor 'concat_2:0' shape=(?, 32) dtype=float32>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_final_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoder\n",
    "Common part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_cell = LSTMCell(decoder_hidden_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_max_time, batch_size = tf.unstack(tf.shape(encoder_inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_lengths = encoder_inputs_length + 2\n",
    "# +2 additional steps, +1 leading <EOS> token for decoder inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'embedding_lookup_1:0' shape=(?, ?, 20) dtype=float32>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# +2 additional steps, +1 leading <EOS> token for decoder inputs as for decoder_lengths\n",
    "max_length = encoder_max_time + 2\n",
    "\n",
    "decoder_inputs = tf.ones([max_length, batch_size], dtype=tf.int32)\n",
    "decoder_inputs_embedded = tf.nn.embedding_lookup(embeddings, decoder_inputs)\n",
    "decoder_inputs_embedded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic_rnn decoder\n",
    "For comparison purpose (no attention mechanisms)\n",
    "\n",
    "You can jump direclty to the seq2seq decoder part without running those cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "((decoder_outputs),\n",
    " (decoder_state)) = (\n",
    "    tf.nn.dynamic_rnn(cell=decoder_cell,\n",
    "                      inputs=decoder_inputs_embedded, # Make sense for training but how to infer?\n",
    "                      sequence_length=decoder_lengths,\n",
    "                      initial_state=encoder_final_state,\n",
    "                      dtype=tf.float32, time_major=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "decoder_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#manually specifying since we are going to implement attention details for the decoder in a sec\n",
    "#weights\n",
    "W = tf.Variable(tf.random_uniform([decoder_hidden_units, vocab_size], -1, 1), dtype=tf.float32)\n",
    "#bias\n",
    "b = tf.Variable(tf.zeros([vocab_size]), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#to convert output to human readable prediction\n",
    "#we will reshape output tensor\n",
    "\n",
    "#Unpacks the given dimension of a rank-R tensor into rank-(R-1) tensors.\n",
    "#reduces dimensionality\n",
    "decoder_max_steps, decoder_batch_size, decoder_dim = tf.unstack(tf.shape(decoder_outputs))\n",
    "#flettened output tensor\n",
    "decoder_outputs_flat = tf.reshape(decoder_outputs, (-1, decoder_dim))\n",
    "#pass flattened tensor through decoder\n",
    "decoder_logits_flat = tf.add(tf.matmul(decoder_outputs_flat, W), b)\n",
    "#prediction vals\n",
    "decoder_logits = tf.reshape(decoder_logits_flat, (decoder_max_steps, decoder_batch_size, vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "decoder_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#final prediction\n",
    "decoder_prediction = tf.argmax(decoder_logits, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seq2seq decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.layers import core as layers_core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# attention_states: [batch_size, max_time, num_units]\n",
    "attention_states = tf.transpose(encoder_outputs, [1, 0, 2])\n",
    "\n",
    "# Create an attention mechanism\n",
    "attention_mechanism = tf.contrib.seq2seq.LuongAttention(\n",
    "    num_units=decoder_hidden_units, \n",
    "    memory=attention_states,\n",
    "    #memory_sequence_length=None # default value\n",
    ")\n",
    "\n",
    "decoder_cell = tf.contrib.seq2seq.AttentionWrapper(\n",
    "    cell=decoder_cell, \n",
    "    attention_mechanism=attention_mechanism,\n",
    "    attention_layer_size=decoder_hidden_units)\n",
    "\n",
    "attention_zero = decoder_cell.zero_state(batch_size=batch_size, dtype=tf.float32)\n",
    "encoder_final_state_attention = attention_zero.clone(cell_state=encoder_final_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "projection_layer = layers_core.Dense(vocab_size, use_bias=True)\n",
    "\n",
    "mode = 'infer'\n",
    "\n",
    "# Helper\n",
    "if mode == 'train':\n",
    "    helper = tf.contrib.seq2seq.TrainingHelper(\n",
    "        inputs=decoder_inputs_embedded, \n",
    "        sequence_length=decoder_lengths, \n",
    "        time_major=True)\n",
    "\n",
    "elif mode == 'infer':\n",
    "    helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(\n",
    "          embedding=embeddings,\n",
    "          start_tokens=tf.tile([BOS], [batch_size]),\n",
    "          end_token=EOS)\n",
    "\n",
    "# Decoder\n",
    "decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "    cell=decoder_cell, \n",
    "    helper=helper, \n",
    "    initial_state=encoder_final_state_attention, # to use without attention change to 'encoder_final_state'\n",
    "    output_layer=projection_layer)\n",
    "\n",
    "# Dynamic decoding\n",
    "(decoder_outputs, final_state, final_sequence_lengths) = tf.contrib.seq2seq.dynamic_decode(\n",
    "    decoder,\n",
    "    output_time_major=True\n",
    ")\n",
    "decoder_logits = decoder_outputs.rnn_output\n",
    "decoder_prediction = decoder_outputs.sample_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BasicDecoderOutput(rnn_output=<tf.Tensor 'decoder/TensorArrayStack/TensorArrayGatherV3:0' shape=(?, ?, 10) dtype=float32>, sample_id=<tf.Tensor 'decoder/TensorArrayStack_1/TensorArrayGatherV3:0' shape=(?, ?) dtype=int32>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#cross entropy loss\n",
    "#one hot encode the target values so we don't rank just differentiate\n",
    "stepwise_cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "    labels=tf.one_hot(decoder_targets, depth=vocab_size, dtype=tf.float32),\n",
    "    logits=decoder_logits,\n",
    ")\n",
    "\n",
    "#loss function\n",
    "loss = tf.reduce_mean(stepwise_cross_entropy)\n",
    "#train it \n",
    "train_op = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load toy dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head of the batch:\n",
      "[9, 5, 7, 5, 9]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "\n",
    "batches = helpers.random_sequences(length_from=3, length_to=8,\n",
    "                                   vocab_lower=3, vocab_upper=10,\n",
    "                                   batch_size=batch_size)\n",
    "\n",
    "print('head of the batch:')\n",
    "for seq in next(batches)[:10]:\n",
    "    print(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def next_feed():\n",
    "    batch = next(batches)\n",
    "    encoder_inputs_, encoder_input_lengths_ = helpers.batch(\n",
    "        [[BOS] + (sequence) + [EOS] for sequence in batch]\n",
    "    )\n",
    "    decoder_targets_, _ = helpers.batch(\n",
    "        [[BOS] + (sequence) + [EOS] + [PAD] * 2 for sequence in batch]\n",
    "    )\n",
    "    return {\n",
    "        encoder_inputs: encoder_inputs_,\n",
    "        encoder_inputs_length: encoder_input_lengths_,\n",
    "        decoder_targets: decoder_targets_,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_track = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_model(max_batches=1001, batches_in_epoch=200):\n",
    "    try:\n",
    "        for batch in range(max_batches):\n",
    "            fd = next_feed()\n",
    "            _, l = sess.run([train_op, loss], fd)\n",
    "            loss_track.append(l)\n",
    "\n",
    "            if batch == 0 or batch % batches_in_epoch == 0:\n",
    "                predict_, l = sess.run([decoder_prediction, loss], fd)\n",
    "                print('batch {}'.format(batch))\n",
    "                print('  minibatch loss: {}'.format(l))\n",
    "                for i, (inp, pred) in enumerate(zip(fd[encoder_inputs].T, predict_.T)):\n",
    "                    print('  sample {}:'.format(i + 1))\n",
    "                    print('    input     > {}'.format(inp))\n",
    "                    print('    predicted > {}'.format(pred))\n",
    "                    if i >= 2:\n",
    "                        break\n",
    "                print\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print('training interrupted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model\n",
    "Possible to skip those cells and load a model checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0\n",
      "  minibatch loss: 2.26167750359\n",
      "  sample 1:\n",
      "    input     > [1 3 9 4 3 2 0 0 0 0]\n",
      "    predicted > [3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "  sample 2:\n",
      "    input     > [1 3 4 3 8 3 2 0 0 0]\n",
      "    predicted > [3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "  sample 3:\n",
      "    input     > [1 7 6 3 6 7 6 2 0 0]\n",
      "    predicted > [3 3 3 3 3 3 3 3 3 3 4 4]\n",
      "\n",
      "batch 200\n",
      "  minibatch loss: 0.685984611511\n",
      "  sample 1:\n",
      "    input     > [1 8 4 3 9 2 0 0 0 0]\n",
      "    predicted > [1 8 4 3 9 2 0 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [1 8 8 6 3 8 3 2 0 0]\n",
      "    predicted > [1 8 8 8 8 8 3 2 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [1 4 9 3 9 5 8 2 0 0]\n",
      "    predicted > [1 9 9 9 9 9 8 2 0 0 0 0]\n",
      "\n",
      "batch 400\n",
      "  minibatch loss: 0.12656570971\n",
      "  sample 1:\n",
      "    input     > [1 6 6 9 3 5 3 6 2 0]\n",
      "    predicted > [1 6 6 9 3 5 3 6 2 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [1 8 9 7 6 2 0 0 0 0]\n",
      "    predicted > [1 8 9 7 6 2 0 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [1 4 6 4 6 3 9 2 0 0]\n",
      "    predicted > [1 4 6 4 6 3 9 2 0 0 0 0]\n",
      "\n",
      "batch 600\n",
      "  minibatch loss: 0.0149441482499\n",
      "  sample 1:\n",
      "    input     > [1 3 5 5 2 0 0 0 0 0]\n",
      "    predicted > [1 3 5 5 2 0 0 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [1 9 3 9 4 3 2 0 0 0]\n",
      "    predicted > [1 9 3 9 4 3 2 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [1 9 8 7 2 0 0 0 0 0]\n",
      "    predicted > [1 9 8 7 2 0 0 0 0 0 0 0]\n",
      "\n",
      "batch 800\n",
      "  minibatch loss: 0.00770102674142\n",
      "  sample 1:\n",
      "    input     > [1 6 7 6 5 2 0 0 0 0]\n",
      "    predicted > [1 6 7 6 5 2 0 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [1 7 5 7 7 3 6 2 0 0]\n",
      "    predicted > [1 7 5 7 7 3 6 2 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [1 5 5 3 9 2 0 0 0 0]\n",
      "    predicted > [1 5 5 3 9 2 0 0 0 0 0 0]\n",
      "\n",
      "batch 1000\n",
      "  minibatch loss: 0.00295217242092\n",
      "  sample 1:\n",
      "    input     > [1 9 4 3 7 7 8 5 2 0]\n",
      "    predicted > [1 9 4 3 7 7 8 5 2 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [1 5 7 8 8 7 6 7 2 0]\n",
      "    predicted > [1 5 7 8 8 7 6 7 2 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [1 6 5 5 3 5 3 2 0 0]\n",
      "    predicted > [1 6 5 5 3 5 3 2 0 0 0 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Remember that '1' is the BOS tag and '2' the EOS tag, not predicted outputs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.0030 after 64064 examples (batch_size=64)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEACAYAAABfxaZOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x123aece50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_track)\n",
    "print('loss {:.4f} after {} examples (batch_size={})'.format(loss_track[-1], len(loss_track)*batch_size, batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model (create a checkpoint under the 'checkpoints' directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'checkpoints/seq2seq.ckpt'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "saver.save(sess, \"checkpoints/seq2seq.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load a checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/seq2seq.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/seq2seq.ckpt\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, \"checkpoints/seq2seq.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'encoder_inputs:0' shape=(?, ?) dtype=int32>, <tf.Tensor 'encoder_inputs_length:0' shape=(?,) dtype=int32>]\n"
     ]
    }
   ],
   "source": [
    "fd = next_feed()\n",
    "fd.pop(decoder_targets, None)\n",
    "print(fd.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 1, 32)\n",
      "(1, 32)\n",
      "[1 8 6 9 4 7 2]\n",
      "[1 8 6 9 4 7 7 2]\n",
      "\n",
      "(array([ 0.40023291, -0.58917397, -2.30250072,  2.58669639, -0.91088206,\n",
      "        1.16439533,  1.78416383,  0.96235991, -1.73630548, -0.46655616,\n",
      "       -1.26378036,  2.70004392, -1.57479513, -1.96860933, -0.74386686,\n",
      "       -1.75229454, -0.03932205, -0.69448853, -2.03278232,  2.42240119,\n",
      "       -0.78706419,  1.69245625,  1.8588593 ,  1.04569674, -1.02659595,\n",
      "       -1.69472444, -1.82233655,  2.21492791, -1.68707776, -2.41957664,\n",
      "       -0.91299194, -1.56797767], dtype=float32), array([-0.04471743, -0.26471651,  0.17375033,  0.03144662,  0.03910483,\n",
      "       -0.01637032,  0.35473436,  0.06948765,  0.08570214, -0.03199809,\n",
      "        0.03975524, -0.12645589,  0.05322534, -0.02965113, -0.13658004,\n",
      "        0.08771627, -0.01339012, -0.59790337, -0.82750249,  0.21970706,\n",
      "       -0.45475811,  0.55341053,  0.83924961,  0.59622633, -0.23960082,\n",
      "       -0.87738526, -0.8654319 ,  0.90147388, -0.6968345 , -0.90098828,\n",
      "       -0.71534425, -0.76475066], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "fd = next_feed()\n",
    "fd.pop(decoder_targets, None)\n",
    "pred, out, state = sess.run([decoder_prediction, encoder_outputs, encoder_final_state], fd)\n",
    "print(out.shape)\n",
    "print(state.c.shape)\n",
    "f = fd[encoder_inputs].T\n",
    "print(f[0])\n",
    "print(pred.T[0])\n",
    "print\n",
    "print(state.c[0], out[0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize graph\n",
    "\n",
    "Copy from https://stackoverflow.com/questions/38189119/simple-way-to-visualize-a-tensorflow-graph-in-jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "def strip_consts(graph_def, max_const_size=32):\n",
    "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
    "    strip_def = tf.GraphDef()\n",
    "    for n0 in graph_def.node:\n",
    "        n = strip_def.node.add() \n",
    "        n.MergeFrom(n0)\n",
    "        if n.op == 'Const':\n",
    "            tensor = n.attr['value'].tensor\n",
    "            size = len(tensor.tensor_content)\n",
    "            if size > max_const_size:\n",
    "                tensor.tensor_content = \"<stripped %d bytes>\"%size\n",
    "    return strip_def\n",
    "\n",
    "def show_graph(graph_def, max_const_size=32):\n",
    "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
    "    if hasattr(graph_def, 'as_graph_def'):\n",
    "        graph_def = graph_def.as_graph_def()\n",
    "    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
    "    code = \"\"\"\n",
    "        <script>\n",
    "          function load() {{\n",
    "            document.getElementById(\"{id}\").pbtxt = {data};\n",
    "          }}\n",
    "        </script>\n",
    "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
    "        <div style=\"height:600px\">\n",
    "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
    "        </div>\n",
    "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
    "\n",
    "    iframe = \"\"\"\n",
    "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n",
    "    \"\"\".format(code.replace('\"', '&quot;'))\n",
    "    display(HTML(iframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.324218408367&quot;).pbtxt = 'node {\\n  name: &quot;encoder_inputs&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n        dim {\\n          size: -1\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;encoder_inputs_length&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder_targets&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n        dim {\\n          size: -1\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\n\\\\000\\\\000\\\\000\\\\024\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;random_uniform/max&quot;\\n  input: &quot;random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;random_uniform/RandomUniform&quot;\\n  input: &quot;random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;random_uniform/mul&quot;\\n  input: &quot;random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Variable&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 10\\n        }\\n        dim {\\n          size: 20\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Variable/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Variable&quot;\\n  input: &quot;random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Variable/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Variable&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;embedding_lookup&quot;\\n  op: &quot;Gather&quot;\\n  input: &quot;Variable/read&quot;\\n  input: &quot;encoder_inputs&quot;\\n  attr {\\n    key: &quot;Tindices&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tparams&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_indices&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/sequence_length&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;encoder_inputs_length&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;embedding_lookup&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/strided_slice/stack&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/strided_slice/stack_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/strided_slice/stack_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/strided_slice&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/Shape&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/strided_slice/stack&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/strided_slice/stack_1&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/strided_slice/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/ExpandDims/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/ExpandDims&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/strided_slice&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/ExpandDims/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 16\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/ExpandDims&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/Const&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/ExpandDims_1/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/ExpandDims_1&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/strided_slice&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/ExpandDims_1/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 16\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/zeros/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/zeros&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/concat&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/zeros/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/ExpandDims_2/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/ExpandDims_2&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/strided_slice&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/ExpandDims_2/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/Const_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 16\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/concat_1/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/concat_1&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/ExpandDims_2&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/Const_2&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/concat_1/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/ExpandDims_3/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/ExpandDims_3&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/strided_slice&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/ExpandDims_3/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/Const_3&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 16\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/zeros_1/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/zeros_1&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/concat_1&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/zeros_1/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/fw/sequence_length&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/stack&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/strided_slice&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/Equal&quot;\\n  op: &quot;Equal&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/Shape_1&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/stack&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/All&quot;\\n  op: &quot;All&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/Equal&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/Const&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/Assert/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;Expected shape for Tensor bidirectional_rnn/fw/sequence_length:0 is &quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/Assert/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot; but saw shape: &quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/Assert/Assert/data_0&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;Expected shape for Tensor bidirectional_rnn/fw/sequence_length:0 is &quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/Assert/Assert/data_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot; but saw shape: &quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/Assert/Assert&quot;\\n  op: &quot;Assert&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/All&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/Assert/Assert/data_0&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/stack&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/Assert/Assert/data_2&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      list {\\n        type: DT_STRING\\n        type: DT_INT32\\n        type: DT_STRING\\n        type: DT_INT32\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;summarize&quot;\\n    value {\\n      i: 3\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/CheckSeqLen&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;bidirectional_rnn/fw/sequence_length&quot;\\n  input: &quot;^bidirectional_rnn/fw/fw/Assert/Assert&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/Shape_2&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;embedding_lookup&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/strided_slice_1/stack&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/strided_slice_1/stack_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/strided_slice_1/stack_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/strided_slice_1&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/Shape_2&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/strided_slice_1/stack&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/strided_slice_1/stack_1&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/strided_slice_1/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/Shape_3&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;embedding_lookup&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/strided_slice_2/stack&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/strided_slice_2/stack_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/strided_slice_2/stack_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/strided_slice_2&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/Shape_3&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/strided_slice_2/stack&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/strided_slice_2/stack_1&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/strided_slice_2/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/ExpandDims/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/ExpandDims&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/strided_slice_2&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/ExpandDims/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 16\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/ExpandDims&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/Const_1&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/zeros/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/zeros&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/concat&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/zeros/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/Const_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/Min&quot;\\n  op: &quot;Min&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/CheckSeqLen&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/Const_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/Const_3&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/Max&quot;\\n  op: &quot;Max&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/CheckSeqLen&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/Const_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/time&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/TensorArray&quot;\\n  op: &quot;TensorArrayV3&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/strided_slice_1&quot;\\n  attr {\\n    key: &quot;clear_after_read&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;dynamic_size&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;element_shape&quot;\\n    value {\\n      shape {\\n        unknown_rank: true\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;tensor_array_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/dynamic_rnn/output_0&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/TensorArray_1&quot;\\n  op: &quot;TensorArrayV3&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/strided_slice_1&quot;\\n  attr {\\n    key: &quot;clear_after_read&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;dynamic_size&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;element_shape&quot;\\n    value {\\n      shape {\\n        unknown_rank: true\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;tensor_array_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/dynamic_rnn/input_0&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/TensorArrayUnstack/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;embedding_lookup&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/TensorArrayUnstack/strided_slice/stack&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/TensorArrayUnstack/strided_slice/stack_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/TensorArrayUnstack/strided_slice/stack_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/TensorArrayUnstack/strided_slice&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArrayUnstack/Shape&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArrayUnstack/strided_slice/stack&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArrayUnstack/strided_slice/stack_1&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArrayUnstack/strided_slice/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/TensorArrayUnstack/range/start&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/TensorArrayUnstack/range/delta&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/TensorArrayUnstack/range&quot;\\n  op: &quot;Range&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArrayUnstack/range/start&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArrayUnstack/strided_slice&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArrayUnstack/range/delta&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3&quot;\\n  op: &quot;TensorArrayScatterV3&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArray_1&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArrayUnstack/range&quot;\\n  input: &quot;embedding_lookup&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArray_1:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/time&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/Enter_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArray:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/Enter_2&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/Enter_3&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/zeros_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/Merge&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Enter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/Merge_1&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Enter_1&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/NextIteration_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/Merge_2&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Enter_2&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/NextIteration_2&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/Merge_3&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Enter_3&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/NextIteration_3&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/Less/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/strided_slice_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/Less&quot;\\n  op: &quot;Less&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Merge&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Less/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/LoopCond&quot;\\n  op: &quot;LoopCond&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Less&quot;\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Merge&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/LoopCond&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/Merge&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/Switch_1&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Merge_1&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/LoopCond&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/Merge_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/Switch_2&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Merge_2&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/LoopCond&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/Merge_2&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/Switch_3&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Merge_3&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/LoopCond&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/Merge_3&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/Identity&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Switch:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/Identity_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Switch_1:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/Identity_2&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Switch_2:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/Identity_3&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Switch_3:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArray_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/TensorArrayReadV3&quot;\\n  op: &quot;TensorArrayReadV3&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Identity&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;$\\\\000\\\\000\\\\000@\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.244948968291\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.244948968291\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform/max&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform/mul&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/kernel&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 36\\n        }\\n        dim {\\n          size: 64\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/kernel&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/kernel/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/kernel&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^bidirectional_rnn/fw/fw/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/TensorArrayReadV3&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Identity_3&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/bias/Initializer/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 64\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/bias&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 64\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/bias&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/bias/Initializer/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd&quot;\\n  op: &quot;BiasAdd&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^bidirectional_rnn/fw/fw/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 4\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split/split_dim&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^bidirectional_rnn/fw/fw/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split&quot;\\n  op: &quot;Split&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split/split_dim&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;num_split&quot;\\n    value {\\n      i: 4\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add/y&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^bidirectional_rnn/fw/fw/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split:2&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid&quot;\\n  op: &quot;Sigmoid&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Identity_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid_1&quot;\\n  op: &quot;Sigmoid&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Tanh&quot;\\n  op: &quot;Tanh&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid_1&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Tanh&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid_2&quot;\\n  op: &quot;Sigmoid&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split:3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Tanh_1&quot;\\n  op: &quot;Tanh&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid_2&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Tanh_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/GreaterEqual/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/CheckSeqLen&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/GreaterEqual&quot;\\n  op: &quot;GreaterEqual&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Identity&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/GreaterEqual/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/Select/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/Select&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/GreaterEqual&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Select/Enter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/GreaterEqual_1&quot;\\n  op: &quot;GreaterEqual&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Identity&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/GreaterEqual/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/Select_1&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/GreaterEqual_1&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Identity_2&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/GreaterEqual_2&quot;\\n  op: &quot;GreaterEqual&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Identity&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/GreaterEqual/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/Select_2&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/GreaterEqual_2&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Identity_3&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArray&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3&quot;\\n  op: &quot;TensorArrayWriteV3&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3/Enter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Identity&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Select&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Identity_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/add/y&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^bidirectional_rnn/fw/fw/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Identity&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/add/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/NextIteration_1&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/NextIteration_2&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Select_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/NextIteration_3&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Select_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/Exit&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/Exit_1&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Switch_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/Exit_2&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Switch_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/Exit_3&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Switch_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/TensorArrayStack/TensorArraySizeV3&quot;\\n  op: &quot;TensorArraySizeV3&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArray&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Exit_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/TensorArray&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/TensorArrayStack/range/start&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/TensorArray&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/TensorArrayStack/range/delta&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/TensorArray&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/TensorArrayStack/range&quot;\\n  op: &quot;Range&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArrayStack/range/start&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArrayStack/TensorArraySizeV3&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArrayStack/range/delta&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/TensorArray&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/TensorArrayStack/TensorArrayGatherV3&quot;\\n  op: &quot;TensorArrayGatherV3&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArray&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArrayStack/range&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Exit_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/TensorArray&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;element_shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n        dim {\\n          size: 16\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/Const_4&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 16\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/ReverseSequence&quot;\\n  op: &quot;ReverseSequence&quot;\\n  input: &quot;embedding_lookup&quot;\\n  input: &quot;encoder_inputs_length&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tlen&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;batch_dim&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;seq_dim&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/sequence_length&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;encoder_inputs_length&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/bw/ReverseSequence&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/strided_slice/stack&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/strided_slice/stack_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/strided_slice/stack_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/strided_slice&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/Shape&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/strided_slice/stack&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/strided_slice/stack_1&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/strided_slice/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/ExpandDims/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/ExpandDims&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/strided_slice&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/ExpandDims/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 16\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/ExpandDims&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/Const&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/ExpandDims_1/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/ExpandDims_1&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/strided_slice&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/ExpandDims_1/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 16\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/zeros/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/zeros&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/concat&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/zeros/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/ExpandDims_2/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/ExpandDims_2&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/strided_slice&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/ExpandDims_2/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/Const_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 16\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/concat_1/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/concat_1&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/ExpandDims_2&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/Const_2&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/concat_1/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/ExpandDims_3/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/ExpandDims_3&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/strided_slice&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/ExpandDims_3/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/Const_3&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 16\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/zeros_1/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/zeros_1&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/concat_1&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/zeros_1/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/bw/sequence_length&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/stack&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/strided_slice&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/Equal&quot;\\n  op: &quot;Equal&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/Shape_1&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/stack&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/All&quot;\\n  op: &quot;All&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/Equal&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/Const&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/Assert/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;Expected shape for Tensor bidirectional_rnn/bw/sequence_length:0 is &quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/Assert/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot; but saw shape: &quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/Assert/Assert/data_0&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;Expected shape for Tensor bidirectional_rnn/bw/sequence_length:0 is &quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/Assert/Assert/data_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot; but saw shape: &quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/Assert/Assert&quot;\\n  op: &quot;Assert&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/All&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/Assert/Assert/data_0&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/stack&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/Assert/Assert/data_2&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      list {\\n        type: DT_STRING\\n        type: DT_INT32\\n        type: DT_STRING\\n        type: DT_INT32\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;summarize&quot;\\n    value {\\n      i: 3\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/CheckSeqLen&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;bidirectional_rnn/bw/sequence_length&quot;\\n  input: &quot;^bidirectional_rnn/bw/bw/Assert/Assert&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/Shape_2&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/bw/ReverseSequence&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/strided_slice_1/stack&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/strided_slice_1/stack_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/strided_slice_1/stack_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/strided_slice_1&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/Shape_2&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/strided_slice_1/stack&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/strided_slice_1/stack_1&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/strided_slice_1/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/Shape_3&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/bw/ReverseSequence&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/strided_slice_2/stack&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/strided_slice_2/stack_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/strided_slice_2/stack_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/strided_slice_2&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/Shape_3&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/strided_slice_2/stack&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/strided_slice_2/stack_1&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/strided_slice_2/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/ExpandDims/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/ExpandDims&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/strided_slice_2&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/ExpandDims/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 16\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/ExpandDims&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/Const_1&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/zeros/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/zeros&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/concat&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/zeros/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/Const_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/Min&quot;\\n  op: &quot;Min&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/CheckSeqLen&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/Const_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/Const_3&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/Max&quot;\\n  op: &quot;Max&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/CheckSeqLen&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/Const_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/time&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/TensorArray&quot;\\n  op: &quot;TensorArrayV3&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/strided_slice_1&quot;\\n  attr {\\n    key: &quot;clear_after_read&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;dynamic_size&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;element_shape&quot;\\n    value {\\n      shape {\\n        unknown_rank: true\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;tensor_array_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/dynamic_rnn/output_0&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/TensorArray_1&quot;\\n  op: &quot;TensorArrayV3&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/strided_slice_1&quot;\\n  attr {\\n    key: &quot;clear_after_read&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;dynamic_size&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;element_shape&quot;\\n    value {\\n      shape {\\n        unknown_rank: true\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;tensor_array_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/dynamic_rnn/input_0&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/TensorArrayUnstack/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/bw/ReverseSequence&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/TensorArrayUnstack/strided_slice/stack&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/TensorArrayUnstack/strided_slice/stack_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/TensorArrayUnstack/strided_slice/stack_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/TensorArrayUnstack/strided_slice&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArrayUnstack/Shape&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArrayUnstack/strided_slice/stack&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArrayUnstack/strided_slice/stack_1&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArrayUnstack/strided_slice/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/TensorArrayUnstack/range/start&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/TensorArrayUnstack/range/delta&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/TensorArrayUnstack/range&quot;\\n  op: &quot;Range&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArrayUnstack/range/start&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArrayUnstack/strided_slice&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArrayUnstack/range/delta&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3&quot;\\n  op: &quot;TensorArrayScatterV3&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArray_1&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArrayUnstack/range&quot;\\n  input: &quot;bidirectional_rnn/bw/ReverseSequence&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArray_1:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/ReverseSequence&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/time&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/Enter_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArray:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/Enter_2&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/Enter_3&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/zeros_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/Merge&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Enter&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/Merge_1&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Enter_1&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/NextIteration_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/Merge_2&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Enter_2&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/NextIteration_2&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/Merge_3&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Enter_3&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/NextIteration_3&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/Less/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/strided_slice_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/Less&quot;\\n  op: &quot;Less&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Merge&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Less/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/LoopCond&quot;\\n  op: &quot;LoopCond&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Less&quot;\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Merge&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/LoopCond&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/Merge&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/Switch_1&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Merge_1&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/LoopCond&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/Merge_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/Switch_2&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Merge_2&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/LoopCond&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/Merge_2&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/Switch_3&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Merge_3&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/LoopCond&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/Merge_3&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/Identity&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Switch:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/Identity_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Switch_1:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/Identity_2&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Switch_2:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/Identity_3&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Switch_3:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArray_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/TensorArrayReadV3&quot;\\n  op: &quot;TensorArrayReadV3&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Identity&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^bidirectional_rnn/bw/bw/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/TensorArrayReadV3&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Identity_3&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd&quot;\\n  op: &quot;BiasAdd&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^bidirectional_rnn/bw/bw/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 4\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split/split_dim&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^bidirectional_rnn/bw/bw/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split&quot;\\n  op: &quot;Split&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split/split_dim&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;num_split&quot;\\n    value {\\n      i: 4\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add/y&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^bidirectional_rnn/bw/bw/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split:2&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid&quot;\\n  op: &quot;Sigmoid&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Identity_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid_1&quot;\\n  op: &quot;Sigmoid&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Tanh&quot;\\n  op: &quot;Tanh&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid_1&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Tanh&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid_2&quot;\\n  op: &quot;Sigmoid&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split:3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Tanh_1&quot;\\n  op: &quot;Tanh&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid_2&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Tanh_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/GreaterEqual/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/CheckSeqLen&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/GreaterEqual&quot;\\n  op: &quot;GreaterEqual&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Identity&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/GreaterEqual/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/Select/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/Select&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/GreaterEqual&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Select/Enter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/GreaterEqual_1&quot;\\n  op: &quot;GreaterEqual&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Identity&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/GreaterEqual/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/Select_1&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/GreaterEqual_1&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Identity_2&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/GreaterEqual_2&quot;\\n  op: &quot;GreaterEqual&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Identity&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/GreaterEqual/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/Select_2&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/GreaterEqual_2&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Identity_3&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArray&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3&quot;\\n  op: &quot;TensorArrayWriteV3&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3/Enter&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Identity&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Select&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Identity_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/add/y&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^bidirectional_rnn/bw/bw/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Identity&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/add/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/NextIteration_1&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/NextIteration_2&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Select_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/NextIteration_3&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Select_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/Exit&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/Exit_1&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Switch_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/Exit_2&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Switch_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/Exit_3&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Switch_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/TensorArrayStack/TensorArraySizeV3&quot;\\n  op: &quot;TensorArraySizeV3&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArray&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Exit_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/TensorArray&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/TensorArrayStack/range/start&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/TensorArray&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/TensorArrayStack/range/delta&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/TensorArray&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/TensorArrayStack/range&quot;\\n  op: &quot;Range&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArrayStack/range/start&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArrayStack/TensorArraySizeV3&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArrayStack/range/delta&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/TensorArray&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/TensorArrayStack/TensorArrayGatherV3&quot;\\n  op: &quot;TensorArrayGatherV3&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArray&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArrayStack/range&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Exit_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/TensorArray&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;element_shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n        dim {\\n          size: 16\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/Const_4&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 16\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;ReverseSequence&quot;\\n  op: &quot;ReverseSequence&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArrayStack/TensorArrayGatherV3&quot;\\n  input: &quot;encoder_inputs_length&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tlen&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;batch_dim&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;seq_dim&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;concat/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArrayStack/TensorArrayGatherV3&quot;\\n  input: &quot;ReverseSequence&quot;\\n  input: &quot;concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;concat_1/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;concat_1&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Exit_2&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Exit_2&quot;\\n  input: &quot;concat_1/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;concat_2/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;concat_2&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Exit_3&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Exit_3&quot;\\n  input: &quot;concat_2/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;encoder_inputs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;unstack&quot;\\n  op: &quot;Unpack&quot;\\n  input: &quot;Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;num&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;add/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 3\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;encoder_inputs_length&quot;\\n  input: &quot;add/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;add_1/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 3\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;add_1&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;unstack&quot;\\n  input: &quot;add_1/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;ones/shape&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;add_1&quot;\\n  input: &quot;unstack:1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;ones/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;ones&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;ones/shape&quot;\\n  input: &quot;ones/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;embedding_lookup_1&quot;\\n  op: &quot;Gather&quot;\\n  input: &quot;Variable/read&quot;\\n  input: &quot;ones&quot;\\n  attr {\\n    key: &quot;Tindices&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tparams&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_indices&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;transpose/perm&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 3\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;transpose&quot;\\n  op: &quot;Transpose&quot;\\n  input: &quot;concat&quot;\\n  input: &quot;transpose/perm&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tperm&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/ones&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;transpose&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/strided_slice/stack&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/strided_slice/stack_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/strided_slice/stack_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/strided_slice&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;LuongAttention/Shape&quot;\\n  input: &quot;LuongAttention/strided_slice/stack&quot;\\n  input: &quot;LuongAttention/strided_slice/stack_1&quot;\\n  input: &quot;LuongAttention/strided_slice/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;memory_layer/kernel/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@memory_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot; \\\\000\\\\000\\\\000 \\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;memory_layer/kernel/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@memory_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.306186228991\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;memory_layer/kernel/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@memory_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.306186228991\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;memory_layer/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;memory_layer/kernel/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@memory_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;memory_layer/kernel/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;memory_layer/kernel/Initializer/random_uniform/max&quot;\\n  input: &quot;memory_layer/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@memory_layer/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;memory_layer/kernel/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;memory_layer/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;memory_layer/kernel/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@memory_layer/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;memory_layer/kernel/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;memory_layer/kernel/Initializer/random_uniform/mul&quot;\\n  input: &quot;memory_layer/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@memory_layer/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;memory_layer/kernel&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@memory_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 32\\n        }\\n        dim {\\n          size: 32\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;memory_layer/kernel/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;memory_layer/kernel&quot;\\n  input: &quot;memory_layer/kernel/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@memory_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;memory_layer/kernel/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;memory_layer/kernel&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@memory_layer/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;transpose&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/Rank&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 3\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/axes&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/GreaterEqual/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/GreaterEqual&quot;\\n  op: &quot;GreaterEqual&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/axes&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/GreaterEqual/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/GreaterEqual&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/Cast&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/axes&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/Less/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/Less&quot;\\n  op: &quot;Less&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/axes&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/Less/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/Cast_1&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/Less&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/axes&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/Rank&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/Cast_1&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/add_1&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/mul&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/mul_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/range/start&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/range/delta&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/range&quot;\\n  op: &quot;Range&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/range/start&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/Rank&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/range/delta&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/ListDiff&quot;\\n  op: &quot;ListDiff&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/range&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;out_idx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/Gather&quot;\\n  op: &quot;Gather&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/Shape&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/ListDiff&quot;\\n  attr {\\n    key: &quot;Tindices&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tparams&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_indices&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/Gather_1&quot;\\n  op: &quot;Gather&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/Shape&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/add_1&quot;\\n  attr {\\n    key: &quot;Tindices&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tparams&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_indices&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/Prod&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/Gather&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/Prod_1&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/Gather_1&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/Gather_1&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/Gather&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/concat_1/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/concat_1&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/ListDiff&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/add_1&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/concat_1/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/stack&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/Prod&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/Prod_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/transpose&quot;\\n  op: &quot;Transpose&quot;\\n  input: &quot;transpose&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/concat_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tperm&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/transpose&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/stack&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/transpose_1/perm&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/transpose_1&quot;\\n  op: &quot;Transpose&quot;\\n  input: &quot;memory_layer/kernel/read&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/transpose_1/perm&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tperm&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/Reshape_1/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot; \\\\000\\\\000\\\\000 \\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/transpose_1&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/Reshape_1/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/Reshape&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/Reshape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/Const_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 32\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/concat_2/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/concat_2&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/Gather&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/Const_2&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/concat_2/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/MatMul&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/concat_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/strided_slice_1/stack&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/strided_slice_1/stack_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/strided_slice_1/stack_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/strided_slice_1&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;LuongAttention/Shape_1&quot;\\n  input: &quot;LuongAttention/strided_slice_1/stack&quot;\\n  input: &quot;LuongAttention/strided_slice_1/stack_1&quot;\\n  input: &quot;LuongAttention/strided_slice_1/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/Shape_2&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/strided_slice_2/stack&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/strided_slice_2/stack_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/strided_slice_2/stack_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/strided_slice_2&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;LuongAttention/Shape_2&quot;\\n  input: &quot;LuongAttention/strided_slice_2/stack&quot;\\n  input: &quot;LuongAttention/strided_slice_2/stack_1&quot;\\n  input: &quot;LuongAttention/strided_slice_2/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/LSTMCellZeroState/ExpandDims/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/LSTMCellZeroState/ExpandDims&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;unstack:1&quot;\\n  input: &quot;AttentionWrapperZeroState/LSTMCellZeroState/ExpandDims/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/LSTMCellZeroState/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 32\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/LSTMCellZeroState/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/LSTMCellZeroState/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;AttentionWrapperZeroState/LSTMCellZeroState/ExpandDims&quot;\\n  input: &quot;AttentionWrapperZeroState/LSTMCellZeroState/Const&quot;\\n  input: &quot;AttentionWrapperZeroState/LSTMCellZeroState/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/LSTMCellZeroState/ExpandDims_1/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/LSTMCellZeroState/ExpandDims_1&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;unstack:1&quot;\\n  input: &quot;AttentionWrapperZeroState/LSTMCellZeroState/ExpandDims_1/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/LSTMCellZeroState/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 32\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/LSTMCellZeroState/zeros/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/LSTMCellZeroState/zeros&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;AttentionWrapperZeroState/LSTMCellZeroState/concat&quot;\\n  input: &quot;AttentionWrapperZeroState/LSTMCellZeroState/zeros/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/LSTMCellZeroState/ExpandDims_2/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/LSTMCellZeroState/ExpandDims_2&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;unstack:1&quot;\\n  input: &quot;AttentionWrapperZeroState/LSTMCellZeroState/ExpandDims_2/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/LSTMCellZeroState/Const_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 32\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/LSTMCellZeroState/concat_1/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/LSTMCellZeroState/concat_1&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;AttentionWrapperZeroState/LSTMCellZeroState/ExpandDims_2&quot;\\n  input: &quot;AttentionWrapperZeroState/LSTMCellZeroState/Const_2&quot;\\n  input: &quot;AttentionWrapperZeroState/LSTMCellZeroState/concat_1/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/LSTMCellZeroState/ExpandDims_3/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/LSTMCellZeroState/ExpandDims_3&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;unstack:1&quot;\\n  input: &quot;AttentionWrapperZeroState/LSTMCellZeroState/ExpandDims_3/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/LSTMCellZeroState/Const_3&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 32\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/LSTMCellZeroState/zeros_1/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/LSTMCellZeroState/zeros_1&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;AttentionWrapperZeroState/LSTMCellZeroState/concat_1&quot;\\n  input: &quot;AttentionWrapperZeroState/LSTMCellZeroState/zeros_1/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/assert_equal/Equal&quot;\\n  op: &quot;Equal&quot;\\n  input: &quot;unstack:1&quot;\\n  input: &quot;LuongAttention/strided_slice_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/assert_equal/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/assert_equal/All&quot;\\n  op: &quot;All&quot;\\n  input: &quot;AttentionWrapperZeroState/assert_equal/Equal&quot;\\n  input: &quot;AttentionWrapperZeroState/assert_equal/Const&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/assert_equal/Assert/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;When calling zero_state of AttentionWrapper attention_wrapper: Non-matching batch sizes between the memory (encoder output) and the requested batch size.  Are you using the BeamSearchDecoder?  If so, make sure your encoder output has been tiled to beam_width via tf.contrib.seq2seq.tile_batch, and the batch_size= argument passed to zero_state is batch_size * beam_width.&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/assert_equal/Assert/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;Condition x == y did not hold element-wise:&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/assert_equal/Assert/Const_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;x (unstack:1) = &quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/assert_equal/Assert/Const_3&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;y (LuongAttention/strided_slice_1:0) = &quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/assert_equal/Assert/Assert/data_0&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;When calling zero_state of AttentionWrapper attention_wrapper: Non-matching batch sizes between the memory (encoder output) and the requested batch size.  Are you using the BeamSearchDecoder?  If so, make sure your encoder output has been tiled to beam_width via tf.contrib.seq2seq.tile_batch, and the batch_size= argument passed to zero_state is batch_size * beam_width.&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/assert_equal/Assert/Assert/data_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;Condition x == y did not hold element-wise:&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/assert_equal/Assert/Assert/data_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;x (unstack:1) = &quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/assert_equal/Assert/Assert/data_4&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;y (LuongAttention/strided_slice_1:0) = &quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/assert_equal/Assert/Assert&quot;\\n  op: &quot;Assert&quot;\\n  input: &quot;AttentionWrapperZeroState/assert_equal/All&quot;\\n  input: &quot;AttentionWrapperZeroState/assert_equal/Assert/Assert/data_0&quot;\\n  input: &quot;AttentionWrapperZeroState/assert_equal/Assert/Assert/data_1&quot;\\n  input: &quot;AttentionWrapperZeroState/assert_equal/Assert/Assert/data_2&quot;\\n  input: &quot;unstack:1&quot;\\n  input: &quot;AttentionWrapperZeroState/assert_equal/Assert/Assert/data_4&quot;\\n  input: &quot;LuongAttention/strided_slice_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      list {\\n        type: DT_STRING\\n        type: DT_STRING\\n        type: DT_STRING\\n        type: DT_INT32\\n        type: DT_STRING\\n        type: DT_INT32\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;summarize&quot;\\n    value {\\n      i: 3\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/checked_cell_state&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;AttentionWrapperZeroState/LSTMCellZeroState/zeros&quot;\\n  input: &quot;^AttentionWrapperZeroState/assert_equal/Assert/Assert&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/checked_cell_state_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;AttentionWrapperZeroState/LSTMCellZeroState/zeros_1&quot;\\n  input: &quot;^AttentionWrapperZeroState/assert_equal/Assert/Assert&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/ExpandDims/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/ExpandDims&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;unstack:1&quot;\\n  input: &quot;AttentionWrapperZeroState/ExpandDims/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 32\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;AttentionWrapperZeroState/ExpandDims&quot;\\n  input: &quot;AttentionWrapperZeroState/Const&quot;\\n  input: &quot;AttentionWrapperZeroState/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/ExpandDims_1/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/ExpandDims_1&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;unstack:1&quot;\\n  input: &quot;AttentionWrapperZeroState/ExpandDims_1/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 32\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/zeros_1/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/zeros_1&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;AttentionWrapperZeroState/concat&quot;\\n  input: &quot;AttentionWrapperZeroState/zeros_1/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/ExpandDims_2/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/ExpandDims_2&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;unstack:1&quot;\\n  input: &quot;AttentionWrapperZeroState/ExpandDims_2/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/ExpandDims_3/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/ExpandDims_3&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;LuongAttention/strided_slice_2&quot;\\n  input: &quot;AttentionWrapperZeroState/ExpandDims_3/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/concat_1/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/concat_1&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;AttentionWrapperZeroState/ExpandDims_2&quot;\\n  input: &quot;AttentionWrapperZeroState/ExpandDims_3&quot;\\n  input: &quot;AttentionWrapperZeroState/concat_1/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/ExpandDims_4/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/ExpandDims_4&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;unstack:1&quot;\\n  input: &quot;AttentionWrapperZeroState/ExpandDims_4/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/ExpandDims_5/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/ExpandDims_5&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;LuongAttention/strided_slice_2&quot;\\n  input: &quot;AttentionWrapperZeroState/ExpandDims_5/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/zeros_2/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/zeros_2&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;AttentionWrapperZeroState/concat_1&quot;\\n  input: &quot;AttentionWrapperZeroState/zeros_2/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;TrainingHelper/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;embedding_lookup_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;TrainingHelper/strided_slice/stack&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;TrainingHelper/strided_slice/stack_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;TrainingHelper/strided_slice/stack_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;TrainingHelper/strided_slice&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;TrainingHelper/Shape&quot;\\n  input: &quot;TrainingHelper/strided_slice/stack&quot;\\n  input: &quot;TrainingHelper/strided_slice/stack_1&quot;\\n  input: &quot;TrainingHelper/strided_slice/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;TrainingHelper/TensorArray&quot;\\n  op: &quot;TensorArrayV3&quot;\\n  input: &quot;TrainingHelper/strided_slice&quot;\\n  attr {\\n    key: &quot;clear_after_read&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;dynamic_size&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;element_shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n        dim {\\n          size: 20\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;tensor_array_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;TrainingHelper/TensorArrayUnstack/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;embedding_lookup_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;TrainingHelper/TensorArrayUnstack/strided_slice/stack&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;TrainingHelper/TensorArrayUnstack/strided_slice/stack_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;TrainingHelper/TensorArrayUnstack/strided_slice/stack_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;TrainingHelper/TensorArrayUnstack/strided_slice&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;TrainingHelper/TensorArrayUnstack/Shape&quot;\\n  input: &quot;TrainingHelper/TensorArrayUnstack/strided_slice/stack&quot;\\n  input: &quot;TrainingHelper/TensorArrayUnstack/strided_slice/stack_1&quot;\\n  input: &quot;TrainingHelper/TensorArrayUnstack/strided_slice/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;TrainingHelper/TensorArrayUnstack/range/start&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;TrainingHelper/TensorArrayUnstack/range/delta&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;TrainingHelper/TensorArrayUnstack/range&quot;\\n  op: &quot;Range&quot;\\n  input: &quot;TrainingHelper/TensorArrayUnstack/range/start&quot;\\n  input: &quot;TrainingHelper/TensorArrayUnstack/strided_slice&quot;\\n  input: &quot;TrainingHelper/TensorArrayUnstack/range/delta&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;TrainingHelper/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3&quot;\\n  op: &quot;TensorArrayScatterV3&quot;\\n  input: &quot;TrainingHelper/TensorArray&quot;\\n  input: &quot;TrainingHelper/TensorArrayUnstack/range&quot;\\n  input: &quot;embedding_lookup_1&quot;\\n  input: &quot;TrainingHelper/TensorArray:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;TrainingHelper/strided_slice_1/stack&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;TrainingHelper/strided_slice_1/stack_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;TrainingHelper/strided_slice_1/stack_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;TrainingHelper/strided_slice_1&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;embedding_lookup_1&quot;\\n  input: &quot;TrainingHelper/strided_slice_1/stack&quot;\\n  input: &quot;TrainingHelper/strided_slice_1/stack_1&quot;\\n  input: &quot;TrainingHelper/strided_slice_1/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;TrainingHelper/zeros_like&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;TrainingHelper/strided_slice_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;TrainingHelper/Size&quot;\\n  op: &quot;Size&quot;\\n  input: &quot;add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TrainingHelperInitialize/Equal/x&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TrainingHelperInitialize/Equal&quot;\\n  op: &quot;Equal&quot;\\n  input: &quot;decoder/TrainingHelperInitialize/Equal/x&quot;\\n  input: &quot;add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TrainingHelperInitialize/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TrainingHelperInitialize/All&quot;\\n  op: &quot;All&quot;\\n  input: &quot;decoder/TrainingHelperInitialize/Equal&quot;\\n  input: &quot;decoder/TrainingHelperInitialize/Const&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TrainingHelperInitialize/cond/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;decoder/TrainingHelperInitialize/All&quot;\\n  input: &quot;decoder/TrainingHelperInitialize/All&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TrainingHelperInitialize/cond/switch_t&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/TrainingHelperInitialize/cond/Switch:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TrainingHelperInitialize/cond/switch_f&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/TrainingHelperInitialize/cond/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TrainingHelperInitialize/cond/pred_id&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/TrainingHelperInitialize/All&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TrainingHelperInitialize/cond/Switch_1&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;TrainingHelper/zeros_like&quot;\\n  input: &quot;decoder/TrainingHelperInitialize/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@TrainingHelper/zeros_like&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TrainingHelperInitialize/cond/TensorArrayReadV3/index&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/TrainingHelperInitialize/cond/switch_f&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TrainingHelperInitialize/cond/TensorArrayReadV3/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;TrainingHelper/TensorArray&quot;\\n  input: &quot;decoder/TrainingHelperInitialize/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@TrainingHelper/TensorArray&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TrainingHelperInitialize/cond/TensorArrayReadV3/Switch_1&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;TrainingHelper/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3&quot;\\n  input: &quot;decoder/TrainingHelperInitialize/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TrainingHelperInitialize/cond/TensorArrayReadV3&quot;\\n  op: &quot;TensorArrayReadV3&quot;\\n  input: &quot;decoder/TrainingHelperInitialize/cond/TensorArrayReadV3/Switch&quot;\\n  input: &quot;decoder/TrainingHelperInitialize/cond/TensorArrayReadV3/index&quot;\\n  input: &quot;decoder/TrainingHelperInitialize/cond/TensorArrayReadV3/Switch_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TrainingHelperInitialize/cond/Merge&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;decoder/TrainingHelperInitialize/cond/TensorArrayReadV3&quot;\\n  input: &quot;decoder/TrainingHelperInitialize/cond/Switch_1:1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/zero_suffix_shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 10\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/concat/values_0&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;TrainingHelper/Size&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;decoder/concat/values_0&quot;\\n  input: &quot;decoder/zero_suffix_shape&quot;\\n  input: &quot;decoder/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/zeros/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/zeros&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;decoder/concat&quot;\\n  input: &quot;decoder/zeros/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/zero_suffix_shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/concat_1/values_0&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;TrainingHelper/Size&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/concat_1/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/concat_1&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;decoder/concat_1/values_0&quot;\\n  input: &quot;decoder/zero_suffix_shape_1&quot;\\n  input: &quot;decoder/concat_1/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/zeros_1/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/zeros_1&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;decoder/concat_1&quot;\\n  input: &quot;decoder/zeros_1/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/zeros_like/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;decoder/TrainingHelperInitialize/Equal&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/zeros_like/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/zeros_like&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;decoder/zeros_like/Shape&quot;\\n  input: &quot;decoder/zeros_like/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TensorArray/size&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TensorArray&quot;\\n  op: &quot;TensorArrayV3&quot;\\n  input: &quot;decoder/TensorArray/size&quot;\\n  attr {\\n    key: &quot;clear_after_read&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;dynamic_size&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;element_shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;tensor_array_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TensorArray_1/size&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TensorArray_1&quot;\\n  op: &quot;TensorArrayV3&quot;\\n  input: &quot;decoder/TensorArray_1/size&quot;\\n  attr {\\n    key: &quot;clear_after_read&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dynamic_size&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;element_shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;tensor_array_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;decoder/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Enter_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;decoder/TensorArray:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Enter_2&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;decoder/TensorArray_1:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Enter_3&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;concat_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Enter_4&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;concat_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Enter_5&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;AttentionWrapperZeroState/zeros_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Enter_6&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;AttentionWrapperZeroState/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Enter_7&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;AttentionWrapperZeroState/zeros_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Enter_8&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;decoder/TrainingHelperInitialize/cond/Merge&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Enter_9&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;decoder/TrainingHelperInitialize/Equal&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Enter_10&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;decoder/zeros_like&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Merge&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;decoder/while/Enter&quot;\\n  input: &quot;decoder/while/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Merge_1&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;decoder/while/Enter_1&quot;\\n  input: &quot;decoder/while/NextIteration_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Merge_2&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;decoder/while/Enter_2&quot;\\n  input: &quot;decoder/while/NextIteration_2&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Merge_3&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;decoder/while/Enter_3&quot;\\n  input: &quot;decoder/while/NextIteration_3&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Merge_4&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;decoder/while/Enter_4&quot;\\n  input: &quot;decoder/while/NextIteration_4&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Merge_5&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;decoder/while/Enter_5&quot;\\n  input: &quot;decoder/while/NextIteration_5&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Merge_6&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;decoder/while/Enter_6&quot;\\n  input: &quot;decoder/while/NextIteration_6&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Merge_7&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;decoder/while/Enter_7&quot;\\n  input: &quot;decoder/while/NextIteration_7&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Merge_8&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;decoder/while/Enter_8&quot;\\n  input: &quot;decoder/while/NextIteration_8&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Merge_9&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;decoder/while/Enter_9&quot;\\n  input: &quot;decoder/while/NextIteration_9&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Merge_10&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;decoder/while/Enter_10&quot;\\n  input: &quot;decoder/while/NextIteration_10&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Merge&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/All&quot;\\n  op: &quot;All&quot;\\n  input: &quot;decoder/while/Merge_9&quot;\\n  input: &quot;decoder/while/Const&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/LogicalNot&quot;\\n  op: &quot;LogicalNot&quot;\\n  input: &quot;decoder/while/All&quot;\\n}\\nnode {\\n  name: &quot;decoder/while/LoopCond&quot;\\n  op: &quot;LoopCond&quot;\\n  input: &quot;decoder/while/LogicalNot&quot;\\n}\\nnode {\\n  name: &quot;decoder/while/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;decoder/while/Merge&quot;\\n  input: &quot;decoder/while/LoopCond&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Merge&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Switch_1&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;decoder/while/Merge_1&quot;\\n  input: &quot;decoder/while/LoopCond&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Merge_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Switch_2&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;decoder/while/Merge_2&quot;\\n  input: &quot;decoder/while/LoopCond&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Merge_2&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Switch_3&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;decoder/while/Merge_3&quot;\\n  input: &quot;decoder/while/LoopCond&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Merge_3&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Switch_4&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;decoder/while/Merge_4&quot;\\n  input: &quot;decoder/while/LoopCond&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Merge_4&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Switch_5&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;decoder/while/Merge_5&quot;\\n  input: &quot;decoder/while/LoopCond&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Merge_5&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Switch_6&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;decoder/while/Merge_6&quot;\\n  input: &quot;decoder/while/LoopCond&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Merge_6&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Switch_7&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;decoder/while/Merge_7&quot;\\n  input: &quot;decoder/while/LoopCond&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Merge_7&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Switch_8&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;decoder/while/Merge_8&quot;\\n  input: &quot;decoder/while/LoopCond&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Merge_8&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Switch_9&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;decoder/while/Merge_9&quot;\\n  input: &quot;decoder/while/LoopCond&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Merge_9&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Switch_10&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;decoder/while/Merge_10&quot;\\n  input: &quot;decoder/while/LoopCond&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Merge_10&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Identity&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/while/Switch:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Identity_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/while/Switch_1:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Identity_2&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/while/Switch_2:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Identity_3&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/while/Switch_3:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Identity_4&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/while/Switch_4:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Identity_5&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/while/Switch_5:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Identity_6&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/while/Switch_6:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Identity_7&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/while/Switch_7:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Identity_8&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/while/Switch_8:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Identity_9&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/while/Switch_9:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Identity_10&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/while/Switch_10:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;decoder/while/Identity_8&quot;\\n  input: &quot;decoder/while/Identity_5&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/kernel/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;T\\\\000\\\\000\\\\000\\\\200\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/kernel/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.168231651187\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/kernel/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.168231651187\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/kernel/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/kernel/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/kernel/Initializer/random_uniform/max&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/kernel/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/kernel/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/kernel/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/kernel/Initializer/random_uniform/mul&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/kernel&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 84\\n        }\\n        dim {\\n          size: 128\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/kernel/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/kernel&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/kernel/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/kernel/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/kernel&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat&quot;\\n  input: &quot;decoder/while/Identity_4&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/bias/Initializer/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 128\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/bias&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 128\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/bias&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/bias/Initializer/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd&quot;\\n  op: &quot;BiasAdd&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 4\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split/split_dim&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split&quot;\\n  op: &quot;Split&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split/split_dim&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;num_split&quot;\\n    value {\\n      i: 4\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add/y&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split:2&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid&quot;\\n  op: &quot;Sigmoid&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid&quot;\\n  input: &quot;decoder/while/Identity_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid_1&quot;\\n  op: &quot;Sigmoid&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Tanh&quot;\\n  op: &quot;Tanh&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid_1&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Tanh&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid_2&quot;\\n  op: &quot;Sigmoid&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split:3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Tanh_1&quot;\\n  op: &quot;Tanh&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid_2&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Tanh_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/strided_slice/stack&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/strided_slice/stack_1&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/strided_slice/stack_2&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/strided_slice&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/Shape&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/strided_slice/stack&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/strided_slice/stack_1&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/strided_slice/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/Equal/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;LuongAttention/strided_slice_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/Equal&quot;\\n  op: &quot;Equal&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/strided_slice&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/Equal/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/All&quot;\\n  op: &quot;All&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/Equal&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/Const&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/Assert/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;When applying AttentionWrapper attention_wrapper_1: Non-matching batch sizes between the memory (encoder output) and the query (decoder output).  Are you using the BeamSearchDecoder?  You may need to tile your memory input via the tf.contrib.seq2seq.tile_batch function with argument multiple=beam_width.&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/Assert/Const_1&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;Condition x == y did not hold element-wise:&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/Assert/Const_2&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;x (decoder/while/BasicDecoderStep/decoder/attention_wrapper/strided_slice:0) = &quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/Assert/Const_3&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;y (LuongAttention/strided_slice_1:0) = &quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/Assert/Assert/data_0&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;When applying AttentionWrapper attention_wrapper_1: Non-matching batch sizes between the memory (encoder output) and the query (decoder output).  Are you using the BeamSearchDecoder?  You may need to tile your memory input via the tf.contrib.seq2seq.tile_batch function with argument multiple=beam_width.&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/Assert/Assert/data_1&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;Condition x == y did not hold element-wise:&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/Assert/Assert/data_2&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;x (decoder/while/BasicDecoderStep/decoder/attention_wrapper/strided_slice:0) = &quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/Assert/Assert/data_4&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;y (LuongAttention/strided_slice_1:0) = &quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/Assert/Assert&quot;\\n  op: &quot;Assert&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/All&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/Assert/Assert/data_0&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/Assert/Assert/data_1&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/Assert/Assert/data_2&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/strided_slice&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/Assert/Assert/data_4&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/Equal/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      list {\\n        type: DT_STRING\\n        type: DT_STRING\\n        type: DT_STRING\\n        type: DT_INT32\\n        type: DT_STRING\\n        type: DT_INT32\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;summarize&quot;\\n    value {\\n      i: 3\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/checked_cell_output&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2&quot;\\n  input: &quot;^decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/Assert/Assert&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims/dim&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/checked_cell_output&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul&quot;\\n  op: &quot;BatchMatMul&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;adj_x&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;adj_y&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/Squeeze&quot;\\n  op: &quot;Squeeze&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;squeeze_dims&quot;\\n    value {\\n      list {\\n        i: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax&quot;\\n  op: &quot;Softmax&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/Squeeze&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims/dim&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;transpose&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul&quot;\\n  op: &quot;BatchMatMul&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;adj_x&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;adj_y&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze&quot;\\n  op: &quot;Squeeze&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;squeeze_dims&quot;\\n    value {\\n      list {\\n        i: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1/axis&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/checked_cell_output&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/attention_layer/kernel/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/attention_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;@\\\\000\\\\000\\\\000 \\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/attention_layer/kernel/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/attention_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.25\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/attention_layer/kernel/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/attention_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.25\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/attention_layer/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;decoder/attention_wrapper/attention_layer/kernel/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/attention_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/attention_layer/kernel/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;decoder/attention_wrapper/attention_layer/kernel/Initializer/random_uniform/max&quot;\\n  input: &quot;decoder/attention_wrapper/attention_layer/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/attention_layer/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/attention_layer/kernel/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;decoder/attention_wrapper/attention_layer/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;decoder/attention_wrapper/attention_layer/kernel/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/attention_layer/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/attention_layer/kernel/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;decoder/attention_wrapper/attention_layer/kernel/Initializer/random_uniform/mul&quot;\\n  input: &quot;decoder/attention_wrapper/attention_layer/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/attention_layer/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/attention_layer/kernel&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/attention_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 64\\n        }\\n        dim {\\n          size: 32\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/attention_layer/kernel/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;decoder/attention_wrapper/attention_layer/kernel&quot;\\n  input: &quot;decoder/attention_wrapper/attention_layer/kernel/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/attention_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/attention_layer/kernel/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/attention_wrapper/attention_layer/kernel&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;decoder/attention_wrapper/attention_layer/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_2/concat_dim&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_2&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/add/y&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;decoder/while/Identity_6&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/add/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/kernel/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot; \\\\000\\\\000\\\\000\\\\n\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/kernel/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.37796446681\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/kernel/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.37796446681\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;decoder/dense/kernel/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/kernel/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;decoder/dense/kernel/Initializer/random_uniform/max&quot;\\n  input: &quot;decoder/dense/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/kernel/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;decoder/dense/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;decoder/dense/kernel/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/kernel/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;decoder/dense/kernel/Initializer/random_uniform/mul&quot;\\n  input: &quot;decoder/dense/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/kernel&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 32\\n        }\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/kernel/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;decoder/dense/kernel&quot;\\n  input: &quot;decoder/dense/kernel/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/kernel/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/dense/kernel&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/bias/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 10\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/bias&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;decoder/dense/bias&quot;\\n  input: &quot;decoder/dense/bias/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/dense/bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/dense/MatMul/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;decoder/dense/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/dense/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_2&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/dense/MatMul/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/dense/BiasAdd/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;decoder/dense/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/dense/BiasAdd&quot;\\n  op: &quot;BiasAdd&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/dense/MatMul&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/dense/BiasAdd/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/TrainingHelperSample/ArgMax/dimension&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/TrainingHelperSample/ArgMax&quot;\\n  op: &quot;ArgMax&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/dense/BiasAdd&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperSample/ArgMax/dimension&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;output_type&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/TrainingHelperSample/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperSample/ArgMax&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/add/y&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;decoder/while/Identity&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/add/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/GreaterEqual/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/GreaterEqual&quot;\\n  op: &quot;GreaterEqual&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/add&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/GreaterEqual/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/All&quot;\\n  op: &quot;All&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/GreaterEqual&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/Const&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/All&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/All&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/switch_t&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Switch:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/switch_f&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/pred_id&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/All&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;TrainingHelper/zeros_like&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Switch_1&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Enter&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Enter&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;TrainingHelper/TensorArray&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Enter&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Enter&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Switch_1&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/add&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/TrainingHelperNextInputs/add&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Enter_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;TrainingHelper/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Switch_2&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Enter_1&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Enter_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3&quot;\\n  op: &quot;TensorArrayReadV3&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Switch&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Switch_1&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Switch_2&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Switch_1:1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/LogicalOr&quot;\\n  op: &quot;LogicalOr&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/GreaterEqual&quot;\\n  input: &quot;decoder/while/Identity_9&quot;\\n}\\nnode {\\n  name: &quot;decoder/while/LogicalNot_1&quot;\\n  op: &quot;LogicalNot&quot;\\n  input: &quot;decoder/while/Identity_9&quot;\\n}\\nnode {\\n  name: &quot;decoder/while/LogicalAnd&quot;\\n  op: &quot;LogicalAnd&quot;\\n  input: &quot;decoder/while/LogicalNot_1&quot;\\n  input: &quot;decoder/while/LogicalOr&quot;\\n}\\nnode {\\n  name: &quot;decoder/while/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;decoder/while/Identity_10&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/add/y&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;decoder/while/Identity&quot;\\n  input: &quot;decoder/while/add/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;decoder/while/Shape&quot;\\n  input: &quot;decoder/while/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Select&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;decoder/while/LogicalAnd&quot;\\n  input: &quot;decoder/while/Fill&quot;\\n  input: &quot;decoder/while/Identity_10&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/TensorArrayWrite/TensorArrayWriteV3/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;decoder/TensorArray&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/dense/BiasAdd&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/TensorArrayWrite/TensorArrayWriteV3&quot;\\n  op: &quot;TensorArrayWriteV3&quot;\\n  input: &quot;decoder/while/TensorArrayWrite/TensorArrayWriteV3/Enter&quot;\\n  input: &quot;decoder/while/Identity&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/dense/BiasAdd&quot;\\n  input: &quot;decoder/while/Identity_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/dense/BiasAdd&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;decoder/TensorArray_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/TrainingHelperSample/Cast&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/TensorArrayWrite_1/TensorArrayWriteV3&quot;\\n  op: &quot;TensorArrayWriteV3&quot;\\n  input: &quot;decoder/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter&quot;\\n  input: &quot;decoder/while/Identity&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperSample/Cast&quot;\\n  input: &quot;decoder/while/Identity_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/TrainingHelperSample/Cast&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/add_1/y&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/add_1&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;decoder/while/Identity&quot;\\n  input: &quot;decoder/while/add_1/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;decoder/while/add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/NextIteration_1&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;decoder/while/TensorArrayWrite/TensorArrayWriteV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/NextIteration_2&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;decoder/while/TensorArrayWrite_1/TensorArrayWriteV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/NextIteration_3&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/NextIteration_4&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/NextIteration_5&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/NextIteration_6&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/NextIteration_7&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/NextIteration_8&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/NextIteration_9&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;decoder/while/LogicalOr&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/NextIteration_10&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;decoder/while/Select&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Exit&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;decoder/while/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Exit_1&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;decoder/while/Switch_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Exit_2&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;decoder/while/Switch_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Exit_3&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;decoder/while/Switch_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Exit_4&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;decoder/while/Switch_4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Exit_5&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;decoder/while/Switch_5&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Exit_6&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;decoder/while/Switch_6&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Exit_7&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;decoder/while/Switch_7&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Exit_8&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;decoder/while/Switch_8&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Exit_9&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;decoder/while/Switch_9&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Exit_10&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;decoder/while/Switch_10&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TensorArrayStack/TensorArraySizeV3&quot;\\n  op: &quot;TensorArraySizeV3&quot;\\n  input: &quot;decoder/TensorArray&quot;\\n  input: &quot;decoder/while/Exit_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/TensorArray&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TensorArrayStack/range/start&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/TensorArray&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TensorArrayStack/range/delta&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/TensorArray&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TensorArrayStack/range&quot;\\n  op: &quot;Range&quot;\\n  input: &quot;decoder/TensorArrayStack/range/start&quot;\\n  input: &quot;decoder/TensorArrayStack/TensorArraySizeV3&quot;\\n  input: &quot;decoder/TensorArrayStack/range/delta&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/TensorArray&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TensorArrayStack/TensorArrayGatherV3&quot;\\n  op: &quot;TensorArrayGatherV3&quot;\\n  input: &quot;decoder/TensorArray&quot;\\n  input: &quot;decoder/TensorArrayStack/range&quot;\\n  input: &quot;decoder/while/Exit_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/TensorArray&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;element_shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TensorArrayStack_1/TensorArraySizeV3&quot;\\n  op: &quot;TensorArraySizeV3&quot;\\n  input: &quot;decoder/TensorArray_1&quot;\\n  input: &quot;decoder/while/Exit_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/TensorArray_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TensorArrayStack_1/range/start&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/TensorArray_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TensorArrayStack_1/range/delta&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/TensorArray_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TensorArrayStack_1/range&quot;\\n  op: &quot;Range&quot;\\n  input: &quot;decoder/TensorArrayStack_1/range/start&quot;\\n  input: &quot;decoder/TensorArrayStack_1/TensorArraySizeV3&quot;\\n  input: &quot;decoder/TensorArrayStack_1/range/delta&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/TensorArray_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TensorArrayStack_1/TensorArrayGatherV3&quot;\\n  op: &quot;TensorArrayGatherV3&quot;\\n  input: &quot;decoder/TensorArray_1&quot;\\n  input: &quot;decoder/TensorArrayStack_1/range&quot;\\n  input: &quot;decoder/while/Exit_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/TensorArray_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;element_shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;one_hot/on_value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;one_hot/off_value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;one_hot/depth&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 10\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;one_hot&quot;\\n  op: &quot;OneHot&quot;\\n  input: &quot;decoder_targets&quot;\\n  input: &quot;one_hot/depth&quot;\\n  input: &quot;one_hot/on_value&quot;\\n  input: &quot;one_hot/off_value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;TI&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: -1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Rank&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 3\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;decoder/TensorArrayStack/TensorArrayGatherV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Rank_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 3\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Shape_2&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;decoder/TensorArrayStack/TensorArrayGatherV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Sub/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;Rank_1&quot;\\n  input: &quot;Sub/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Slice/begin&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;Sub&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Slice/size&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Slice&quot;\\n  op: &quot;Slice&quot;\\n  input: &quot;Shape_2&quot;\\n  input: &quot;Slice/begin&quot;\\n  input: &quot;Slice/size&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;concat_3/values_0&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;concat_3/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;concat_3&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;concat_3/values_0&quot;\\n  input: &quot;Slice&quot;\\n  input: &quot;concat_3/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;decoder/TensorArrayStack/TensorArrayGatherV3&quot;\\n  input: &quot;concat_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Rank_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 3\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Shape_3&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;one_hot&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Sub_1/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Sub_1&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;Rank_2&quot;\\n  input: &quot;Sub_1/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Slice_1/begin&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;Sub_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Slice_1/size&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Slice_1&quot;\\n  op: &quot;Slice&quot;\\n  input: &quot;Shape_3&quot;\\n  input: &quot;Slice_1/begin&quot;\\n  input: &quot;Slice_1/size&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;concat_4/values_0&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;concat_4/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;concat_4&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;concat_4/values_0&quot;\\n  input: &quot;Slice_1&quot;\\n  input: &quot;concat_4/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;one_hot&quot;\\n  input: &quot;concat_4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;SoftmaxCrossEntropyWithLogits&quot;\\n  op: &quot;SoftmaxCrossEntropyWithLogits&quot;\\n  input: &quot;Reshape&quot;\\n  input: &quot;Reshape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Sub_2/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Sub_2&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;Rank&quot;\\n  input: &quot;Sub_2/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Slice_2/begin&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Slice_2/size&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;Sub_2&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Slice_2&quot;\\n  op: &quot;Slice&quot;\\n  input: &quot;Shape_1&quot;\\n  input: &quot;Slice_2/begin&quot;\\n  input: &quot;Slice_2/size&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Reshape_2&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;SoftmaxCrossEntropyWithLogits&quot;\\n  input: &quot;Slice_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Mean&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;Reshape_2&quot;\\n  input: &quot;Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape&quot;\\n  input: &quot;gradients/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/f_count&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/f_count_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/f_count&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Merge&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/f_count_1&quot;\\n  input: &quot;gradients/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/Merge&quot;\\n  input: &quot;decoder/while/LoopCond&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Add/y&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;gradients/Switch:1&quot;\\n  input: &quot;gradients/Add/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/Add&quot;\\n  input: &quot;^gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayWrite/TensorArrayWriteV3/f_sync&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/MatMul_1/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/MatMul_1/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/mod/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN/StackPush_1&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze_grad/Reshape/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/MatMul_1/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims_grad/Reshape/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax_grad/mul/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/Squeeze_grad/Reshape/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/MatMul_1/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims_grad/Reshape/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPush_1&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul_1/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPush_1&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPush_1&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul_1/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPush_1&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul_1/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split_grad/concat/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/StackPush_1&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/mod/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN/StackPush_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/f_count_2&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/b_count&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/b_count_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/f_count_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Merge_1&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/b_count_1&quot;\\n  input: &quot;gradients/NextIteration_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/GreaterEqual/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/b_count&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/GreaterEqual&quot;\\n  op: &quot;GreaterEqual&quot;\\n  input: &quot;gradients/Merge_1&quot;\\n  input: &quot;gradients/GreaterEqual/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/b_count_2&quot;\\n  op: &quot;LoopCond&quot;\\n  input: &quot;gradients/GreaterEqual&quot;\\n}\\nnode {\\n  name: &quot;gradients/Switch_1&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/Merge_1&quot;\\n  input: &quot;gradients/b_count_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;gradients/Switch_1:1&quot;\\n  input: &quot;gradients/GreaterEqual/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/NextIteration_1&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/Sub&quot;\\n  input: &quot;^gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/b_sync&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/b_count_3&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/Switch_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/f_count_3&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/f_count_4&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/f_count_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Merge_2&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/f_count_4&quot;\\n  input: &quot;gradients/NextIteration_2&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch_2&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/Merge_2&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/LoopCond&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Add_1/y&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^bidirectional_rnn/fw/fw/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Add_1&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;gradients/Switch_2:1&quot;\\n  input: &quot;gradients/Add_1/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/NextIteration_2&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/Add_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/zeros_like/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/Select/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/zeros_like/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/Select/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Select_grad/Select/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPush_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul_1/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPush_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPush_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/mul_1/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPush_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul_1/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split_grad/concat/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/StackPush&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/f_count_5&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/Switch_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/b_count_4&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/b_count_5&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/f_count_5&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Merge_3&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/b_count_5&quot;\\n  input: &quot;gradients/NextIteration_3&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/GreaterEqual_1/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/b_count_4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/GreaterEqual_1&quot;\\n  op: &quot;GreaterEqual&quot;\\n  input: &quot;gradients/Merge_3&quot;\\n  input: &quot;gradients/GreaterEqual_1/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/b_count_6&quot;\\n  op: &quot;LoopCond&quot;\\n  input: &quot;gradients/GreaterEqual_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/Switch_3&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/Merge_3&quot;\\n  input: &quot;gradients/b_count_6&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Sub_1&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;gradients/Switch_3:1&quot;\\n  input: &quot;gradients/GreaterEqual_1/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/NextIteration_3&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/Sub_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/zeros_like/b_sync&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/b_count_7&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/Switch_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/f_count_6&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/f_count_7&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/f_count_6&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Merge_4&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/f_count_7&quot;\\n  input: &quot;gradients/NextIteration_4&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch_4&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/Merge_4&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/LoopCond&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Add_2/y&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^bidirectional_rnn/bw/bw/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Add_2&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;gradients/Switch_4:1&quot;\\n  input: &quot;gradients/Add_2/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/NextIteration_4&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/Add_2&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/zeros_like/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/Select/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/zeros_like/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/Select/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Select_grad/Select/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs/StackPush_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul_1/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs/StackPush_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs/StackPush_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/mul_1/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs/StackPush_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul_1/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/BroadcastGradientArgs/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split_grad/concat/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/MatMul_1/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/mod/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/ShapeN/StackPush&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/f_count_8&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/Switch_4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/b_count_8&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/b_count_9&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/f_count_8&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Merge_5&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/b_count_9&quot;\\n  input: &quot;gradients/NextIteration_5&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/GreaterEqual_2/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/b_count_8&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/GreaterEqual_2&quot;\\n  op: &quot;GreaterEqual&quot;\\n  input: &quot;gradients/Merge_5&quot;\\n  input: &quot;gradients/GreaterEqual_2/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/b_count_10&quot;\\n  op: &quot;LoopCond&quot;\\n  input: &quot;gradients/GreaterEqual_2&quot;\\n}\\nnode {\\n  name: &quot;gradients/Switch_5&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/Merge_5&quot;\\n  input: &quot;gradients/b_count_10&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Sub_2&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;gradients/Switch_5:1&quot;\\n  input: &quot;gradients/GreaterEqual_2/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/NextIteration_5&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/Sub_2&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/zeros_like/b_sync&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/b_count_11&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/Switch_5&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/Fill&quot;\\n  input: &quot;gradients/Mean_grad/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Reshape_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;gradients/Mean_grad/Reshape&quot;\\n  input: &quot;gradients/Mean_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Reshape_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Shape_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Prod&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;gradients/Mean_grad/Shape_1&quot;\\n  input: &quot;gradients/Mean_grad/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Prod_1&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;gradients/Mean_grad/Shape_2&quot;\\n  input: &quot;gradients/Mean_grad/Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Maximum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Maximum&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;gradients/Mean_grad/Prod_1&quot;\\n  input: &quot;gradients/Mean_grad/Maximum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/floordiv&quot;\\n  op: &quot;FloorDiv&quot;\\n  input: &quot;gradients/Mean_grad/Prod&quot;\\n  input: &quot;gradients/Mean_grad/Maximum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;gradients/Mean_grad/floordiv&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/truediv&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;gradients/Mean_grad/Tile&quot;\\n  input: &quot;gradients/Mean_grad/Cast&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Reshape_2_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;SoftmaxCrossEntropyWithLogits&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Reshape_2_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/Mean_grad/truediv&quot;\\n  input: &quot;gradients/Reshape_2_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;SoftmaxCrossEntropyWithLogits:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/SoftmaxCrossEntropyWithLogits_grad/ExpandDims/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/SoftmaxCrossEntropyWithLogits_grad/ExpandDims&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;gradients/Reshape_2_grad/Reshape&quot;\\n  input: &quot;gradients/SoftmaxCrossEntropyWithLogits_grad/ExpandDims/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/SoftmaxCrossEntropyWithLogits_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/SoftmaxCrossEntropyWithLogits_grad/ExpandDims&quot;\\n  input: &quot;SoftmaxCrossEntropyWithLogits:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Reshape_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;decoder/TensorArrayStack/TensorArrayGatherV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Reshape_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/SoftmaxCrossEntropyWithLogits_grad/mul&quot;\\n  input: &quot;gradients/Reshape_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  op: &quot;TensorArrayGradV3&quot;\\n  input: &quot;decoder/TensorArray&quot;\\n  input: &quot;decoder/while/Exit_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/TensorArray&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;source&quot;\\n    value {\\n      s: &quot;gradients&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayGrad/gradient_flow&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/while/Exit_1&quot;\\n  input: &quot;^gradients/decoder/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/TensorArray&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayScatter/TensorArrayScatterV3&quot;\\n  op: &quot;TensorArrayScatterV3&quot;\\n  input: &quot;gradients/decoder/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  input: &quot;decoder/TensorArrayStack/range&quot;\\n  input: &quot;gradients/Reshape_grad/Reshape&quot;\\n  input: &quot;gradients/decoder/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayGrad/gradient_flow&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_1&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;decoder/while/Exit_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_2&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;decoder/while/Exit_4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_3&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;decoder/while/Exit_5&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_4&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;decoder/while/Exit_7&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_5&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;decoder/while/Exit_8&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Exit_1_grad/b_exit&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/decoder/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayScatter/TensorArrayScatterV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Exit_2_grad/b_exit&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Exit_3_grad/b_exit&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/zeros_like_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Exit_4_grad/b_exit&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/zeros_like_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Exit_5_grad/b_exit&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/zeros_like_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Exit_7_grad/b_exit&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/zeros_like_4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Exit_8_grad/b_exit&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/zeros_like_5&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Switch_1_grad/b_switch&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/decoder/while/Exit_1_grad/b_exit&quot;\\n  input: &quot;gradients/decoder/while/Switch_1_grad_1/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Switch_3_grad/b_switch&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/decoder/while/Exit_3_grad/b_exit&quot;\\n  input: &quot;gradients/decoder/while/Switch_3_grad_1/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Switch_4_grad/b_switch&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/decoder/while/Exit_4_grad/b_exit&quot;\\n  input: &quot;gradients/decoder/while/Switch_4_grad_1/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Switch_5_grad/b_switch&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/decoder/while/Exit_5_grad/b_exit&quot;\\n  input: &quot;gradients/decoder/while/Switch_5_grad_1/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Switch_8_grad/b_switch&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/decoder/while/Exit_8_grad/b_exit&quot;\\n  input: &quot;gradients/decoder/while/Switch_8_grad_1/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Merge_1_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/decoder/while/Switch_1_grad/b_switch&quot;\\n  input: &quot;gradients/b_count_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/Switch_1_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Merge_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/decoder/while/Merge_1_grad/Switch&quot;\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Merge_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/Merge_1_grad/Switch&quot;\\n  input: &quot;^gradients/decoder/while/Merge_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/Switch_1_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Merge_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/Merge_1_grad/Switch:1&quot;\\n  input: &quot;^gradients/decoder/while/Merge_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/Switch_1_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Merge_3_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/decoder/while/Switch_3_grad/b_switch&quot;\\n  input: &quot;gradients/b_count_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/Switch_3_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Merge_3_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/decoder/while/Merge_3_grad/Switch&quot;\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Merge_3_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/Merge_3_grad/Switch&quot;\\n  input: &quot;^gradients/decoder/while/Merge_3_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/Switch_3_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Merge_3_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/Merge_3_grad/Switch:1&quot;\\n  input: &quot;^gradients/decoder/while/Merge_3_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/Switch_3_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Merge_4_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/decoder/while/Switch_4_grad/b_switch&quot;\\n  input: &quot;gradients/b_count_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/Switch_4_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Merge_4_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/decoder/while/Merge_4_grad/Switch&quot;\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Merge_4_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/Merge_4_grad/Switch&quot;\\n  input: &quot;^gradients/decoder/while/Merge_4_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/Switch_4_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Merge_4_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/Merge_4_grad/Switch:1&quot;\\n  input: &quot;^gradients/decoder/while/Merge_4_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/Switch_4_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Merge_5_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/decoder/while/Switch_5_grad/b_switch&quot;\\n  input: &quot;gradients/b_count_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/Switch_5_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Merge_5_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/decoder/while/Merge_5_grad/Switch&quot;\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Merge_5_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/Merge_5_grad/Switch&quot;\\n  input: &quot;^gradients/decoder/while/Merge_5_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/Switch_5_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Merge_5_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/Merge_5_grad/Switch:1&quot;\\n  input: &quot;^gradients/decoder/while/Merge_5_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/Switch_5_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Merge_8_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/decoder/while/Switch_8_grad/b_switch&quot;\\n  input: &quot;gradients/b_count_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/Switch_8_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Merge_8_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/decoder/while/Merge_8_grad/Switch&quot;\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Merge_8_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/Merge_8_grad/Switch&quot;\\n  input: &quot;^gradients/decoder/while/Merge_8_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/Switch_8_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Merge_8_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/Merge_8_grad/Switch:1&quot;\\n  input: &quot;^gradients/decoder/while/Merge_8_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/Switch_8_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Enter_1_grad/Exit&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/decoder/while/Merge_1_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Enter_3_grad/Exit&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/decoder/while/Merge_3_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Enter_4_grad/Exit&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/decoder/while/Merge_4_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Enter_5_grad/Exit&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/decoder/while/Merge_5_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Enter_8_grad/Exit&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/decoder/while/Merge_8_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayGrad/TensorArrayGradV3/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;decoder/TensorArray&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/dense/BiasAdd&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  op: &quot;TensorArrayGradV3&quot;\\n  input: &quot;gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayGrad/TensorArrayGradV3/Enter&quot;\\n  input: &quot;gradients/decoder/while/Merge_1_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/dense/BiasAdd&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;source&quot;\\n    value {\\n      s: &quot;gradients&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayGrad/gradient_flow&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/Merge_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;^gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/dense/BiasAdd&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Identity&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Identity&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/RefEnter&quot;\\n  input: &quot;decoder/while/Identity&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Identity&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Identity&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Identity&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/b_sync&quot;\\n  op: &quot;ControlTrigger&quot;\\n  input: &quot;^gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayWrite/TensorArrayWriteV3/StackPop&quot;\\n  input: &quot;^gradients/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/MatMul_1/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/MatMul_1/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/mod/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN/StackPop_1&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze_grad/Reshape/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/MatMul_1/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims_grad/Reshape/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax_grad/mul/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/Squeeze_grad/Reshape/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/MatMul_1/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims_grad/Reshape/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul_1/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul_1/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul_1/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split_grad/concat/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/StackPop_1&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/mod/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN/StackPop_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3&quot;\\n  op: &quot;TensorArrayReadV3&quot;\\n  input: &quot;gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  input: &quot;gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPop&quot;\\n  input: &quot;gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayGrad/gradient_flow&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/decoder/while/Merge_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;^gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3&quot;\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3&quot;\\n  input: &quot;^gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/Merge_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;^gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/Switch_1_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_1_grad/Rank&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_1_grad/mod&quot;\\n  op: &quot;FloorMod&quot;\\n  input: &quot;concat_1/axis&quot;\\n  input: &quot;gradients/concat_1_grad/Rank&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_1_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Exit_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_1_grad/ShapeN&quot;\\n  op: &quot;ShapeN&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Exit_2&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Exit_2&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_1_grad/ConcatOffset&quot;\\n  op: &quot;ConcatOffset&quot;\\n  input: &quot;gradients/concat_1_grad/mod&quot;\\n  input: &quot;gradients/concat_1_grad/ShapeN&quot;\\n  input: &quot;gradients/concat_1_grad/ShapeN:1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_1_grad/Slice&quot;\\n  op: &quot;Slice&quot;\\n  input: &quot;gradients/decoder/while/Enter_3_grad/Exit&quot;\\n  input: &quot;gradients/concat_1_grad/ConcatOffset&quot;\\n  input: &quot;gradients/concat_1_grad/ShapeN&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_1_grad/Slice_1&quot;\\n  op: &quot;Slice&quot;\\n  input: &quot;gradients/decoder/while/Enter_3_grad/Exit&quot;\\n  input: &quot;gradients/concat_1_grad/ConcatOffset:1&quot;\\n  input: &quot;gradients/concat_1_grad/ShapeN:1&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/concat_1_grad/Slice&quot;\\n  input: &quot;^gradients/concat_1_grad/Slice_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/concat_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/concat_1_grad/Slice&quot;\\n  input: &quot;^gradients/concat_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/concat_1_grad/Slice&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/concat_1_grad/Slice_1&quot;\\n  input: &quot;^gradients/concat_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/concat_1_grad/Slice_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_2_grad/Rank&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_2_grad/mod&quot;\\n  op: &quot;FloorMod&quot;\\n  input: &quot;concat_2/axis&quot;\\n  input: &quot;gradients/concat_2_grad/Rank&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_2_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Exit_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_2_grad/ShapeN&quot;\\n  op: &quot;ShapeN&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Exit_3&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Exit_3&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_2_grad/ConcatOffset&quot;\\n  op: &quot;ConcatOffset&quot;\\n  input: &quot;gradients/concat_2_grad/mod&quot;\\n  input: &quot;gradients/concat_2_grad/ShapeN&quot;\\n  input: &quot;gradients/concat_2_grad/ShapeN:1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_2_grad/Slice&quot;\\n  op: &quot;Slice&quot;\\n  input: &quot;gradients/decoder/while/Enter_4_grad/Exit&quot;\\n  input: &quot;gradients/concat_2_grad/ConcatOffset&quot;\\n  input: &quot;gradients/concat_2_grad/ShapeN&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_2_grad/Slice_1&quot;\\n  op: &quot;Slice&quot;\\n  input: &quot;gradients/decoder/while/Enter_4_grad/Exit&quot;\\n  input: &quot;gradients/concat_2_grad/ConcatOffset:1&quot;\\n  input: &quot;gradients/concat_2_grad/ShapeN:1&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_2_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/concat_2_grad/Slice&quot;\\n  input: &quot;^gradients/concat_2_grad/Slice_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/concat_2_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/concat_2_grad/Slice&quot;\\n  input: &quot;^gradients/concat_2_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/concat_2_grad/Slice&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_2_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/concat_2_grad/Slice_1&quot;\\n  input: &quot;^gradients/concat_2_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/concat_2_grad/Slice_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/TrainingHelperInitialize/cond/Merge_grad/cond_grad&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/decoder/while/Enter_8_grad/Exit&quot;\\n  input: &quot;decoder/TrainingHelperInitialize/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/Enter_8_grad/Exit&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/TrainingHelperInitialize/cond/Merge_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/decoder/TrainingHelperInitialize/cond/Merge_grad/cond_grad&quot;\\n}\\nnode {\\n  name: &quot;gradients/decoder/TrainingHelperInitialize/cond/Merge_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/TrainingHelperInitialize/cond/Merge_grad/cond_grad&quot;\\n  input: &quot;^gradients/decoder/TrainingHelperInitialize/cond/Merge_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/Enter_8_grad/Exit&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/TrainingHelperInitialize/cond/Merge_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/TrainingHelperInitialize/cond/Merge_grad/cond_grad:1&quot;\\n  input: &quot;^gradients/decoder/TrainingHelperInitialize/cond/Merge_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/Enter_8_grad/Exit&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/pred_id&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/pred_id&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/RefEnter&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/pred_id&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/pred_id&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/pred_id&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/pred_id&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/cond_grad&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/decoder/while/Merge_8_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/Switch_8_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/cond_grad&quot;\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/cond_grad&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/Switch_8_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/cond_grad:1&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/Switch_8_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/BiasAdd_grad/BiasAddGrad&quot;\\n  op: &quot;BiasAddGrad&quot;\\n  input: &quot;gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/BiasAdd_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/control_dependency&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/dense/BiasAdd_grad/BiasAddGrad&quot;\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/BiasAdd_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/control_dependency&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/dense/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/BiasAdd_grad/BiasAddGrad&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/dense/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/dense/BiasAdd_grad/BiasAddGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/TrainingHelperInitialize/cond/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  op: &quot;TensorArrayGradV3&quot;\\n  input: &quot;decoder/TrainingHelperInitialize/cond/TensorArrayReadV3/Switch&quot;\\n  input: &quot;decoder/TrainingHelperInitialize/cond/TensorArrayReadV3/Switch_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@TrainingHelper/TensorArray&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;source&quot;\\n    value {\\n      s: &quot;gradients&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/TrainingHelperInitialize/cond/TensorArrayReadV3_grad/TensorArrayGrad/gradient_flow&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/TrainingHelperInitialize/cond/TensorArrayReadV3/Switch_1&quot;\\n  input: &quot;^gradients/decoder/TrainingHelperInitialize/cond/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@TrainingHelper/TensorArray&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/TrainingHelperInitialize/cond/TensorArrayReadV3_grad/TensorArrayWrite/TensorArrayWriteV3&quot;\\n  op: &quot;TensorArrayWriteV3&quot;\\n  input: &quot;gradients/decoder/TrainingHelperInitialize/cond/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  input: &quot;decoder/TrainingHelperInitialize/cond/TensorArrayReadV3/index&quot;\\n  input: &quot;gradients/decoder/TrainingHelperInitialize/cond/Merge_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/decoder/TrainingHelperInitialize/cond/TensorArrayReadV3_grad/TensorArrayGrad/gradient_flow&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch_6&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;TrainingHelper/zeros_like&quot;\\n  input: &quot;decoder/TrainingHelperInitialize/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;gradients/Switch_6&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_1/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_1&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape_1&quot;\\n  input: &quot;gradients/zeros_1/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/TrainingHelperInitialize/cond/Switch_1_grad/cond_grad&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/decoder/TrainingHelperInitialize/cond/Merge_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/zeros_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;TrainingHelper/TensorArray&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Enter&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3/Enter_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;TrainingHelper/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Enter&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  op: &quot;TensorArrayGradV3&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3/Enter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3/Enter_1&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Enter&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;source&quot;\\n    value {\\n      s: &quot;gradients&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayGrad/gradient_flow&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3/Enter_1&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Enter&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayWrite/TensorArrayWriteV3/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/TrainingHelperNextInputs/add&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayWrite/TensorArrayWriteV3/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayWrite/TensorArrayWriteV3/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/TrainingHelperNextInputs/add&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayWrite/TensorArrayWriteV3/StackPush/Switch&quot;\\n  op: &quot;RefSwitch&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayWrite/TensorArrayWriteV3/RefEnter&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/TrainingHelperNextInputs/add&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayWrite/TensorArrayWriteV3/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayWrite/TensorArrayWriteV3/StackPush/Switch&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Switch_1&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/TrainingHelperNextInputs/add&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayWrite/TensorArrayWriteV3/f_sync&quot;\\n  op: &quot;ControlTrigger&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayWrite/TensorArrayWriteV3/StackPush&quot;\\n  input: &quot;^gradients/StackPush&quot;\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayWrite/TensorArrayWriteV3/Switch/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayWrite/TensorArrayWriteV3/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/TrainingHelperNextInputs/add&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayWrite/TensorArrayWriteV3/Switch&quot;\\n  op: &quot;RefSwitch&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayWrite/TensorArrayWriteV3/Switch/RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/TrainingHelperNextInputs/add&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayWrite/TensorArrayWriteV3/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayWrite/TensorArrayWriteV3/Switch&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/TrainingHelperNextInputs/add&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayWrite/TensorArrayWriteV3&quot;\\n  op: &quot;TensorArrayWriteV3&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayWrite/TensorArrayWriteV3/StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayGrad/gradient_flow&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch_7&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Enter&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Enter&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape_2&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;gradients/Switch_7&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Shape_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Shape_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/RefEnter&quot;\\n  input: &quot;gradients/Shape_2&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Shape_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch_8/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Shape_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch_8&quot;\\n  op: &quot;RefSwitch&quot;\\n  input: &quot;gradients/Switch_8/RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Shape_2&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/Switch_8&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Shape_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_2/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_2&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/StackPop&quot;\\n  input: &quot;gradients/zeros_2/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Switch_1_grad/cond_grad&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/zeros_2&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/MatMul/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;decoder/dense/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/BiasAdd_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/MatMul/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/MatMul_1/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/MatMul_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/MatMul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/MatMul_1/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/MatMul_1/RefEnter&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_2&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/MatMul_1/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/MatMul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/MatMul_1/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/MatMul_1/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/MatMul_1/StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/BiasAdd_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/BiasAdd/Enter_grad/b_acc&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 10\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/BiasAdd/Enter_grad/b_acc_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/BiasAdd/Enter_grad/b_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/BiasAdd/Enter_grad/b_acc_2&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/BiasAdd/Enter_grad/b_acc_1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/BiasAdd/Enter_grad/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/BiasAdd/Enter_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/BiasAdd/Enter_grad/b_acc_2&quot;\\n  input: &quot;gradients/b_count_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/BiasAdd/Enter_grad/Add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/BiasAdd/Enter_grad/Switch:1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/BiasAdd/Enter_grad/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/BiasAdd/Enter_grad/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/BiasAdd/Enter_grad/b_acc_3&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/BiasAdd/Enter_grad/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Switch_1_grad_1/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch_9&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;TrainingHelper/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3&quot;\\n  input: &quot;decoder/TrainingHelperInitialize/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape_3&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;gradients/Switch_9:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_3/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_3&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape_3&quot;\\n  input: &quot;gradients/zeros_3/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/TrainingHelperInitialize/cond/TensorArrayReadV3/Switch_1_grad/cond_grad&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/decoder/TrainingHelperInitialize/cond/TensorArrayReadV3_grad/TensorArrayWrite/TensorArrayWriteV3&quot;\\n  input: &quot;gradients/zeros_3&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Const_1&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch_10&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/Const_1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Const_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Switch_2_grad/cond_grad&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayWrite/TensorArrayWriteV3&quot;\\n  input: &quot;gradients/Switch_10:1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Enter_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;TrainingHelper/zeros_like&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Enter_grad/zeros/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Enter_grad/zeros&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Enter_grad/Shape&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Enter_grad/zeros/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Enter_grad/b_acc&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Enter_grad/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Enter_grad/b_acc_1&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Enter_grad/b_acc&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Enter_grad/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Enter_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Enter_grad/b_acc_1&quot;\\n  input: &quot;gradients/b_count_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Enter_grad/Add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Enter_grad/Switch:1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Switch_1_grad/cond_grad&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Enter_grad/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Enter_grad/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Enter_grad/b_acc_2&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Enter_grad/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/decoder/while/Merge_5_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/Switch_5_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul/Enter_grad/b_acc&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 32\\n          }\\n          dim {\\n            size: 10\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul/Enter_grad/b_acc_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul/Enter_grad/b_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul/Enter_grad/b_acc_2&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul/Enter_grad/b_acc_1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul/Enter_grad/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul/Enter_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul/Enter_grad/b_acc_2&quot;\\n  input: &quot;gradients/b_count_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul/Enter_grad/Add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul/Enter_grad/Switch:1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul/Enter_grad/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul/Enter_grad/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul/Enter_grad/b_acc_3&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul/Enter_grad/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Enter_1_grad/b_acc&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Enter_1_grad/b_acc_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Enter_1_grad/b_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Enter_1_grad/b_acc_2&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Enter_1_grad/b_acc_1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Enter_1_grad/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Enter_1_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Enter_1_grad/b_acc_2&quot;\\n  input: &quot;gradients/b_count_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Enter_1_grad/Add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Enter_1_grad/Switch:1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Switch_2_grad/cond_grad&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Enter_1_grad/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Enter_1_grad/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Enter_1_grad/b_acc_3&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Enter_1_grad/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_1&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/decoder/TrainingHelperInitialize/cond/Switch_1_grad/cond_grad&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Enter_grad/b_acc_2&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/TrainingHelperInitialize/cond/Switch_1_grad/cond_grad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/MatMul/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;decoder/attention_wrapper/attention_layer/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradients/AddN&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/MatMul/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/MatMul_1/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/MatMul_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/MatMul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/MatMul_1/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/MatMul_1/RefEnter&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/MatMul_1/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/MatMul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/MatMul_1/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/MatMul_1/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/MatMul_1/StackPop&quot;\\n  input: &quot;gradients/AddN&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_2&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/decoder/TrainingHelperInitialize/cond/TensorArrayReadV3/Switch_1_grad/cond_grad&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Enter_1_grad/b_acc_3&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/TrainingHelperInitialize/cond/TensorArrayReadV3/Switch_1_grad/cond_grad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/TrainingHelper/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  op: &quot;TensorArrayGradV3&quot;\\n  input: &quot;TrainingHelper/TensorArray&quot;\\n  input: &quot;gradients/AddN_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@TrainingHelper/TensorArray&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;source&quot;\\n    value {\\n      s: &quot;gradients&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/TrainingHelper/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGrad/gradient_flow&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/AddN_2&quot;\\n  input: &quot;^gradients/TrainingHelper/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@TrainingHelper/TensorArray&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/TrainingHelper/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGatherV3&quot;\\n  op: &quot;TensorArrayGatherV3&quot;\\n  input: &quot;gradients/TrainingHelper/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  input: &quot;TrainingHelper/TensorArrayUnstack/range&quot;\\n  input: &quot;gradients/TrainingHelper/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGrad/gradient_flow&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;element_shape&quot;\\n    value {\\n      shape {\\n        unknown_rank: true\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/TrainingHelper/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/AddN_2&quot;\\n  input: &quot;^gradients/TrainingHelper/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGatherV3&quot;\\n}\\nnode {\\n  name: &quot;gradients/TrainingHelper/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/TrainingHelper/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGatherV3&quot;\\n  input: &quot;^gradients/TrainingHelper/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/TrainingHelper/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGatherV3&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/TrainingHelper/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/AddN_2&quot;\\n  input: &quot;^gradients/TrainingHelper/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/TrainingHelperInitialize/cond/TensorArrayReadV3/Switch_1_grad/cond_grad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/Rank&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/mod/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1/axis&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/mod/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/mod/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1/axis&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/mod/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/mod/RefEnter&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1/axis&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1/axis&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/mod/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/mod/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1/axis&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/mod/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/mod/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1/axis&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/mod&quot;\\n  op: &quot;FloorMod&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/mod/StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/Rank&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/checked_cell_output&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/checked_cell_output&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/checked_cell_output&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN/RefEnter&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/checked_cell_output&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/checked_cell_output&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/checked_cell_output&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/checked_cell_output&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN/f_acc_1&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN/RefEnter_1&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN/StackPush_1&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN/RefEnter_1&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN/StackPop_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN/StackPop_1&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN/StackPop_1/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN&quot;\\n  op: &quot;ShapeN&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN/StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN/StackPop_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ConcatOffset&quot;\\n  op: &quot;ConcatOffset&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/mod&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN:1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/Slice&quot;\\n  op: &quot;Slice&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ConcatOffset&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/Slice_1&quot;\\n  op: &quot;Slice&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ConcatOffset:1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN:1&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/Slice&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/Slice_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/Slice&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/Slice&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/Slice_1&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/Slice_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul/Enter_grad/b_acc&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 64\\n          }\\n          dim {\\n            size: 32\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul/Enter_grad/b_acc_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul/Enter_grad/b_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul/Enter_grad/b_acc_2&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul/Enter_grad/b_acc_1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul/Enter_grad/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul/Enter_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul/Enter_grad/b_acc_2&quot;\\n  input: &quot;gradients/b_count_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul/Enter_grad/Add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul/Enter_grad/Switch:1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul/Enter_grad/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul/Enter_grad/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul/Enter_grad/b_acc_3&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul/Enter_grad/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze_grad/Reshape/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze_grad/Reshape/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze_grad/Reshape/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze_grad/Reshape/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze_grad/Reshape/RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze_grad/Shape&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze_grad/Reshape/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze_grad/Reshape/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze_grad/Reshape/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze_grad/Reshape/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze_grad/Reshape/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/MatMul/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;transpose&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/MatMul&quot;\\n  op: &quot;BatchMatMul&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze_grad/Reshape&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/MatMul/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;adj_x&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;adj_y&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/MatMul_1/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/MatMul_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/MatMul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/MatMul_1/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/MatMul_1/RefEnter&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/MatMul_1/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/MatMul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/MatMul_1/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/MatMul_1/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/MatMul_1&quot;\\n  op: &quot;BatchMatMul&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/MatMul_1/StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze_grad/Reshape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;adj_x&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;adj_y&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims_grad/Reshape/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims_grad/Reshape/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims_grad/Reshape/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims_grad/Reshape/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims_grad/Reshape/RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims_grad/Shape&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims_grad/Reshape/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims_grad/Reshape/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims_grad/Reshape/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims_grad/Reshape/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims_grad/Reshape/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul/Enter_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;transpose&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul/Enter_grad/zeros/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul/Enter_grad/zeros&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul/Enter_grad/Shape&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul/Enter_grad/zeros/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul/Enter_grad/b_acc&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul/Enter_grad/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul/Enter_grad/b_acc_1&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul/Enter_grad/b_acc&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul/Enter_grad/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul/Enter_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul/Enter_grad/b_acc_1&quot;\\n  input: &quot;gradients/b_count_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul/Enter_grad/Add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul/Enter_grad/Switch:1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul/Enter_grad/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul/Enter_grad/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul/Enter_grad/b_acc_2&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul/Enter_grad/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/embedding_lookup_1_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT64\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\n\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\024\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/embedding_lookup_1_grad/ToInt32&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;gradients/embedding_lookup_1_grad/Shape&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/embedding_lookup_1_grad/Size&quot;\\n  op: &quot;Size&quot;\\n  input: &quot;ones&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/embedding_lookup_1_grad/ExpandDims/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/embedding_lookup_1_grad/ExpandDims&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;gradients/embedding_lookup_1_grad/Size&quot;\\n  input: &quot;gradients/embedding_lookup_1_grad/ExpandDims/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/embedding_lookup_1_grad/strided_slice/stack&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/embedding_lookup_1_grad/strided_slice/stack_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/embedding_lookup_1_grad/strided_slice/stack_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/embedding_lookup_1_grad/strided_slice&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;gradients/embedding_lookup_1_grad/ToInt32&quot;\\n  input: &quot;gradients/embedding_lookup_1_grad/strided_slice/stack&quot;\\n  input: &quot;gradients/embedding_lookup_1_grad/strided_slice/stack_1&quot;\\n  input: &quot;gradients/embedding_lookup_1_grad/strided_slice/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/embedding_lookup_1_grad/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/embedding_lookup_1_grad/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;gradients/embedding_lookup_1_grad/ExpandDims&quot;\\n  input: &quot;gradients/embedding_lookup_1_grad/strided_slice&quot;\\n  input: &quot;gradients/embedding_lookup_1_grad/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/embedding_lookup_1_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/TrainingHelper/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/embedding_lookup_1_grad/concat&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/embedding_lookup_1_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;ones&quot;\\n  input: &quot;gradients/embedding_lookup_1_grad/ExpandDims&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax_grad/mul/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax_grad/mul/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax_grad/mul/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax_grad/mul/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax_grad/mul/RefEnter&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax_grad/mul/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax_grad/mul/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax_grad/mul/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax_grad/mul/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims_grad/Reshape&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax_grad/mul/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax_grad/Sum/reduction_indices&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax_grad/mul&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax_grad/Sum/reduction_indices&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax_grad/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\377\\\\377\\\\377\\\\377\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax_grad/Sum&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax_grad/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax_grad/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims_grad/Reshape&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax_grad/Reshape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax_grad/sub&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax_grad/mul/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/Squeeze_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/Squeeze_grad/Reshape/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/Squeeze_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/Squeeze_grad/Reshape/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/Squeeze_grad/Reshape/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/Squeeze_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/Squeeze_grad/Reshape/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/Squeeze_grad/Reshape/RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/Squeeze_grad/Shape&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/Squeeze_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/Squeeze_grad/Reshape/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/Squeeze_grad/Reshape/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/Squeeze_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/Squeeze_grad/Reshape/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/Squeeze_grad/Reshape/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/Squeeze_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/Squeeze_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax_grad/mul_1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/Squeeze_grad/Reshape/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/MatMul/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/MatMul&quot;\\n  op: &quot;BatchMatMul&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/Squeeze_grad/Reshape&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/MatMul/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;adj_x&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;adj_y&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/MatMul_1/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/MatMul_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/MatMul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/MatMul_1/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/MatMul_1/RefEnter&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/MatMul_1/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/MatMul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/MatMul_1/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/MatMul_1/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/MatMul_1&quot;\\n  op: &quot;BatchMatMul&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/Squeeze_grad/Reshape&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/MatMul_1/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;adj_x&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;adj_y&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/checked_cell_output&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims_grad/Reshape/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims_grad/Reshape/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims_grad/Reshape/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims_grad/Reshape/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims_grad/Reshape/RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims_grad/Shape&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims_grad/Reshape/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims_grad/Reshape/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims_grad/Reshape/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims_grad/Reshape/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims_grad/Reshape/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul/Enter_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul/Enter_grad/zeros/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul/Enter_grad/zeros&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul/Enter_grad/Shape&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul/Enter_grad/zeros/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul/Enter_grad/b_acc&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul/Enter_grad/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul/Enter_grad/b_acc_1&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul/Enter_grad/b_acc&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul/Enter_grad/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul/Enter_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul/Enter_grad/b_acc_1&quot;\\n  input: &quot;gradients/b_count_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul/Enter_grad/Add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul/Enter_grad/Switch:1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul/Enter_grad/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul/Enter_grad/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul/Enter_grad/b_acc_2&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul/Enter_grad/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_3&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims_grad/Reshape&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/Slice&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/LuongAttention/memory_layer/Tensordot_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/MatMul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/LuongAttention/memory_layer/Tensordot_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul/Enter_grad/b_acc_2&quot;\\n  input: &quot;gradients/LuongAttention/memory_layer/Tensordot_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_4&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/decoder/while/Merge_4_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/AddN_3&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/Switch_4_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Tanh_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/Shape&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/RefEnter_1&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPush_1&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/RefEnter_1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/Shape_1&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPop_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPop_1/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Tanh_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Tanh_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul/RefEnter&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Tanh_1&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Tanh_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Tanh_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Tanh_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/AddN_4&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/Sum&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul_1/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul_1/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul_1/RefEnter&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid_2&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul_1/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul_1/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul_1/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul_1/StackPop&quot;\\n  input: &quot;gradients/AddN_4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul_1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/Sum_1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/Reshape&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/Reshape&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/Reshape_1&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/LuongAttention/memory_layer/Tensordot/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradients/LuongAttention/memory_layer/Tensordot_grad/Reshape&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/Reshape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/LuongAttention/memory_layer/Tensordot/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/Reshape&quot;\\n  input: &quot;gradients/LuongAttention/memory_layer/Tensordot_grad/Reshape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/LuongAttention/memory_layer/Tensordot/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/LuongAttention/memory_layer/Tensordot/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/LuongAttention/memory_layer/Tensordot/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/LuongAttention/memory_layer/Tensordot/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/LuongAttention/memory_layer/Tensordot/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/LuongAttention/memory_layer/Tensordot/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/LuongAttention/memory_layer/Tensordot/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/LuongAttention/memory_layer/Tensordot/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/LuongAttention/memory_layer/Tensordot/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^gradients/LuongAttention/memory_layer/Tensordot/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/LuongAttention/memory_layer/Tensordot/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid_2_grad/SigmoidGrad&quot;\\n  op: &quot;SigmoidGrad&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul_1/StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Tanh_1_grad/TanhGrad&quot;\\n  op: &quot;TanhGrad&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul/StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/LuongAttention/memory_layer/Tensordot/Reshape_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/transpose&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/LuongAttention/memory_layer/Tensordot/Reshape_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/LuongAttention/memory_layer/Tensordot/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/LuongAttention/memory_layer/Tensordot/Reshape_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/LuongAttention/memory_layer/Tensordot/Reshape_1_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot; \\\\000\\\\000\\\\000 \\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/LuongAttention/memory_layer/Tensordot/Reshape_1_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/LuongAttention/memory_layer/Tensordot/MatMul_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/LuongAttention/memory_layer/Tensordot/Reshape_1_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_5&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/decoder/while/Merge_3_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Tanh_1_grad/TanhGrad&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/Switch_3_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/Shape&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/RefEnter_1&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPush_1&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/RefEnter_1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/Shape_1&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPop_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPop_1/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/AddN_5&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/Sum&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/AddN_5&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/Sum_1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/Reshape&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/Reshape&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/Reshape_1&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/LuongAttention/memory_layer/Tensordot/transpose_grad/InvertPermutation&quot;\\n  op: &quot;InvertPermutation&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/concat_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/LuongAttention/memory_layer/Tensordot/transpose_grad/transpose&quot;\\n  op: &quot;Transpose&quot;\\n  input: &quot;gradients/LuongAttention/memory_layer/Tensordot/Reshape_grad/Reshape&quot;\\n  input: &quot;gradients/LuongAttention/memory_layer/Tensordot/transpose_grad/InvertPermutation&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tperm&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/LuongAttention/memory_layer/Tensordot/transpose_1_grad/InvertPermutation&quot;\\n  op: &quot;InvertPermutation&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/transpose_1/perm&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/LuongAttention/memory_layer/Tensordot/transpose_1_grad/transpose&quot;\\n  op: &quot;Transpose&quot;\\n  input: &quot;gradients/LuongAttention/memory_layer/Tensordot/Reshape_1_grad/Reshape&quot;\\n  input: &quot;gradients/LuongAttention/memory_layer/Tensordot/transpose_1_grad/InvertPermutation&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tperm&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;decoder/while/Identity_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/Shape&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/RefEnter_1&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPush_1&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/RefEnter_1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/Shape_1&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPop_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPop_1/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Identity_3&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Identity_3&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul/RefEnter&quot;\\n  input: &quot;decoder/while/Identity_3&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Identity_3&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Identity_3&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Identity_3&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/Sum&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul_1/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul_1/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul_1/RefEnter&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul_1/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul_1/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul_1/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul_1/StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul_1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/Sum_1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/Reshape&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/Reshape&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/Reshape_1&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Tanh&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/Shape&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/RefEnter_1&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPush_1&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/RefEnter_1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/Shape_1&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPop_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPop_1/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Tanh&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Tanh&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul/RefEnter&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Tanh&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Tanh&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Tanh&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Tanh&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/Sum&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul_1/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul_1/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul_1/RefEnter&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid_1&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul_1/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul_1/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul_1/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul_1/StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul_1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/Sum_1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/Reshape&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/Reshape&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/Reshape_1&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid_grad/SigmoidGrad&quot;\\n  op: &quot;SigmoidGrad&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul_1/StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid_1_grad/SigmoidGrad&quot;\\n  op: &quot;SigmoidGrad&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul_1/StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Tanh_grad/TanhGrad&quot;\\n  op: &quot;TanhGrad&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul/StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split:2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs/RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/Shape&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid_grad/SigmoidGrad&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/Sum&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid_grad/SigmoidGrad&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/Sum_1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/Reshape&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/Reshape&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/Reshape_1&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Switch_3_grad_1/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split_grad/concat/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split/split_dim&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split_grad/concat/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split_grad/concat/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split/split_dim&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split_grad/concat/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split_grad/concat/RefEnter&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split/split_dim&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split/split_dim&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split_grad/concat/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split_grad/concat/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split/split_dim&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split_grad/concat/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split_grad/concat/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split/split_dim&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split_grad/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid_1_grad/SigmoidGrad&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Tanh_grad/TanhGrad&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid_2_grad/SigmoidGrad&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split_grad/concat/StackPop&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 4\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_6&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul/Enter_grad/b_acc_2&quot;\\n  input: &quot;gradients/LuongAttention/memory_layer/Tensordot/transpose_grad/transpose&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul/Enter_grad/b_acc_2&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/transpose_grad/InvertPermutation&quot;\\n  op: &quot;InvertPermutation&quot;\\n  input: &quot;transpose/perm&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/transpose_grad/transpose&quot;\\n  op: &quot;Transpose&quot;\\n  input: &quot;gradients/AddN_6&quot;\\n  input: &quot;gradients/transpose_grad/InvertPermutation&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tperm&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd_grad/BiasAddGrad&quot;\\n  op: &quot;BiasAddGrad&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split_grad/concat&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split_grad/concat&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd_grad/BiasAddGrad&quot;\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split_grad/concat&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split_grad/concat&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd_grad/BiasAddGrad&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd_grad/BiasAddGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_grad/Rank&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 3\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_grad/mod&quot;\\n  op: &quot;FloorMod&quot;\\n  input: &quot;concat/axis&quot;\\n  input: &quot;gradients/concat_grad/Rank&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArrayStack/TensorArrayGatherV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_grad/ShapeN&quot;\\n  op: &quot;ShapeN&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArrayStack/TensorArrayGatherV3&quot;\\n  input: &quot;ReverseSequence&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_grad/ConcatOffset&quot;\\n  op: &quot;ConcatOffset&quot;\\n  input: &quot;gradients/concat_grad/mod&quot;\\n  input: &quot;gradients/concat_grad/ShapeN&quot;\\n  input: &quot;gradients/concat_grad/ShapeN:1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_grad/Slice&quot;\\n  op: &quot;Slice&quot;\\n  input: &quot;gradients/transpose_grad/transpose&quot;\\n  input: &quot;gradients/concat_grad/ConcatOffset&quot;\\n  input: &quot;gradients/concat_grad/ShapeN&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_grad/Slice_1&quot;\\n  op: &quot;Slice&quot;\\n  input: &quot;gradients/transpose_grad/transpose&quot;\\n  input: &quot;gradients/concat_grad/ConcatOffset:1&quot;\\n  input: &quot;gradients/concat_grad/ShapeN:1&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/concat_grad/Slice&quot;\\n  input: &quot;^gradients/concat_grad/Slice_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/concat_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/concat_grad/Slice&quot;\\n  input: &quot;^gradients/concat_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/concat_grad/Slice&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/concat_grad/Slice_1&quot;\\n  input: &quot;^gradients/concat_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/concat_grad/Slice_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1/RefEnter&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1/StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/b_acc&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 128\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/b_acc_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/b_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/b_acc_2&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/b_acc_1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/b_acc_2&quot;\\n  input: &quot;gradients/b_count_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/Add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/Switch:1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/b_acc_3&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  op: &quot;TensorArrayGradV3&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArray&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Exit_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/TensorArray&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;source&quot;\\n    value {\\n      s: &quot;gradients&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayGrad/gradient_flow&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Exit_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/TensorArray&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayScatter/TensorArrayScatterV3&quot;\\n  op: &quot;TensorArrayScatterV3&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArrayStack/range&quot;\\n  input: &quot;gradients/concat_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayGrad/gradient_flow&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/ReverseSequence_grad/ReverseSequence&quot;\\n  op: &quot;ReverseSequence&quot;\\n  input: &quot;gradients/concat_grad/tuple/control_dependency_1&quot;\\n  input: &quot;encoder_inputs_length&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tlen&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;batch_dim&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;seq_dim&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/Rank&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat/axis&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat/axis&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod/RefEnter&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat/axis&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat/axis&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat/axis&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat/axis&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod&quot;\\n  op: &quot;FloorMod&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod/StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/Rank&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/RefEnter&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/f_acc_1&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Identity_4&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/RefEnter_1&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Identity_4&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/StackPush_1&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/RefEnter_1&quot;\\n  input: &quot;decoder/while/Identity_4&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Identity_4&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/StackPop_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Identity_4&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/StackPop_1&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/StackPop_1/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Identity_4&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN&quot;\\n  op: &quot;ShapeN&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/StackPop_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ConcatOffset&quot;\\n  op: &quot;ConcatOffset&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN:1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/Slice&quot;\\n  op: &quot;Slice&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ConcatOffset&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/Slice_1&quot;\\n  op: &quot;Slice&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ConcatOffset:1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN:1&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/Slice&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/Slice_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/Slice&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/Slice&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/Slice_1&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/Slice_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/b_acc&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 84\\n          }\\n          dim {\\n            size: 128\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/b_acc_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/b_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/b_acc_2&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/b_acc_1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/b_acc_2&quot;\\n  input: &quot;gradients/b_count_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/Add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/Switch:1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/b_acc_3&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  op: &quot;TensorArrayGradV3&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArray&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Exit_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/TensorArray&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;source&quot;\\n    value {\\n      s: &quot;gradients&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayGrad/gradient_flow&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Exit_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/TensorArray&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayScatter/TensorArrayScatterV3&quot;\\n  op: &quot;TensorArrayScatterV3&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArrayStack/range&quot;\\n  input: &quot;gradients/ReverseSequence_grad/ReverseSequence&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayGrad/gradient_flow&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/Rank&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/mod/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat/axis&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/mod/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/mod/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat/axis&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/mod/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/mod/RefEnter&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat/axis&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat/axis&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/mod/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/mod/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat/axis&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/mod/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/mod/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat/axis&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/mod&quot;\\n  op: &quot;FloorMod&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/mod/StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/Rank&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;decoder/while/Identity_8&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Identity_8&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Identity_8&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN/RefEnter&quot;\\n  input: &quot;decoder/while/Identity_8&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Identity_8&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Identity_8&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Identity_8&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN/f_acc_1&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Identity_5&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN/RefEnter_1&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Identity_5&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN/StackPush_1&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN/RefEnter_1&quot;\\n  input: &quot;decoder/while/Identity_5&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Identity_5&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN/StackPop_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Identity_5&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN/StackPop_1&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN/StackPop_1/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Identity_5&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN&quot;\\n  op: &quot;ShapeN&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN/StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN/StackPop_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ConcatOffset&quot;\\n  op: &quot;ConcatOffset&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/mod&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN:1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/Slice&quot;\\n  op: &quot;Slice&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ConcatOffset&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/Slice_1&quot;\\n  op: &quot;Slice&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ConcatOffset:1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN:1&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/Slice&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/Slice_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/Slice&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/Slice&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/Slice_1&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/Slice_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Switch_4_grad_1/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Exit_2_grad/b_exit&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/concat_1_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Exit_3_grad/b_exit&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/concat_2_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Exit_1_grad/b_exit&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayScatter/TensorArrayScatterV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Switch_8_grad_1/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Switch_5_grad_1/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Switch_2_grad/b_switch&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Exit_2_grad/b_exit&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Switch_2_grad_1/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Switch_3_grad/b_switch&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Exit_3_grad/b_exit&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Switch_3_grad_1/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Switch_1_grad/b_switch&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Exit_1_grad/b_exit&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Switch_1_grad_1/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Exit_2_grad/b_exit&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/concat_1_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Exit_3_grad/b_exit&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/concat_2_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Exit_1_grad/b_exit&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayScatter/TensorArrayScatterV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_2_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Switch_2_grad/b_switch&quot;\\n  input: &quot;gradients/b_count_6&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/Switch_2_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_2_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Merge_2_grad/Switch&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_2_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_2_grad/Switch&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Merge_2_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/Switch_2_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_2_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_2_grad/Switch:1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Merge_2_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/Switch_2_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_3_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Switch_3_grad/b_switch&quot;\\n  input: &quot;gradients/b_count_6&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/Switch_3_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_3_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Merge_3_grad/Switch&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_3_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_3_grad/Switch&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Merge_3_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/Switch_3_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_3_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_3_grad/Switch:1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Merge_3_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/Switch_3_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_1_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Switch_1_grad/b_switch&quot;\\n  input: &quot;gradients/b_count_6&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/Switch_1_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Merge_1_grad/Switch&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_1_grad/Switch&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Merge_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/Switch_1_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_1_grad/Switch:1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Merge_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/Switch_1_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Switch_2_grad/b_switch&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Exit_2_grad/b_exit&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Switch_2_grad_1/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Switch_3_grad/b_switch&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Exit_3_grad/b_exit&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Switch_3_grad_1/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Switch_1_grad/b_switch&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Exit_1_grad/b_exit&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Switch_1_grad_1/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Enter_2_grad/Exit&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_2_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Enter_3_grad/Exit&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_3_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Enter_1_grad/Exit&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_1_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_2_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Switch_2_grad/b_switch&quot;\\n  input: &quot;gradients/b_count_10&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/bw/bw/while/Switch_2_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_2_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Merge_2_grad/Switch&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_2_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_2_grad/Switch&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Merge_2_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/bw/bw/while/Switch_2_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_2_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_2_grad/Switch:1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Merge_2_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/bw/bw/while/Switch_2_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_3_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Switch_3_grad/b_switch&quot;\\n  input: &quot;gradients/b_count_10&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/bw/bw/while/Switch_3_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_3_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Merge_3_grad/Switch&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_3_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_3_grad/Switch&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Merge_3_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/bw/bw/while/Switch_3_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_3_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_3_grad/Switch:1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Merge_3_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/bw/bw/while/Switch_3_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_1_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Switch_1_grad/b_switch&quot;\\n  input: &quot;gradients/b_count_10&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/bw/bw/while/Switch_1_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Merge_1_grad/Switch&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_1_grad/Switch&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Merge_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/bw/bw/while/Switch_1_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_1_grad/Switch:1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Merge_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/bw/bw/while/Switch_1_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/LSTMCellZeroState/zeros_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/LSTMCellZeroState/zeros_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Enter_2_grad/Exit&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/LSTMCellZeroState/zeros_grad/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/zeros_like/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/Identity_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/zeros_like/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/zeros_like/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/Identity_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/zeros_like/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/zeros_like/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Identity_2&quot;\\n  input: &quot;^gradients/Add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/Identity_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/zeros_like/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/zeros_like/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/Identity_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/zeros_like/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/zeros_like/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/Identity_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/zeros_like/b_sync&quot;\\n  op: &quot;ControlTrigger&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/zeros_like/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/Select/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/zeros_like/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/Select/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Select_grad/Select/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul_1/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/mul_1/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul_1/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split_grad/concat/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/StackPop&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/zeros_like&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/zeros_like/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/Select/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/GreaterEqual_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/Select/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/Select/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/GreaterEqual_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/Select/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/Select/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/GreaterEqual_1&quot;\\n  input: &quot;^gradients/Add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/GreaterEqual_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/Select/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/Select/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/GreaterEqual_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/Select/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/Select/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/GreaterEqual_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/Select&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/Select/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_2_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/zeros_like&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/Select_1&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/Select/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/zeros_like&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_2_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/Select&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/Select_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/Select&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/Select&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/Select_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/Select_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/LSTMCellZeroState/zeros_1_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/LSTMCellZeroState/zeros_1_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Enter_3_grad/Exit&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/LSTMCellZeroState/zeros_1_grad/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/zeros_like/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/Identity_3&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/zeros_like/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/zeros_like/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/Identity_3&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/zeros_like/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/zeros_like/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Identity_3&quot;\\n  input: &quot;^gradients/Add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/Identity_3&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/zeros_like/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/zeros_like/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/Identity_3&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/zeros_like/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/zeros_like/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/Identity_3&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/zeros_like&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/zeros_like/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/Select/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/GreaterEqual_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/Select/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/Select/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/GreaterEqual_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/Select/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/Select/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/GreaterEqual_2&quot;\\n  input: &quot;^gradients/Add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/GreaterEqual_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/Select/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/Select/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/GreaterEqual_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/Select/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/Select/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/GreaterEqual_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/Select&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/Select/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_3_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/zeros_like&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/Select_1&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/Select/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/zeros_like&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_3_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/Select&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/Select_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/Select&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/Select&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/Select_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/Select_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayGrad/TensorArrayGradV3/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArray&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  op: &quot;TensorArrayGradV3&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayGrad/TensorArrayGradV3/Enter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_1_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;source&quot;\\n    value {\\n      s: &quot;gradients&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayGrad/gradient_flow&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/Identity&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/Identity&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Identity&quot;\\n  input: &quot;^gradients/Add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/Identity&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/Identity&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/Identity&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3&quot;\\n  op: &quot;TensorArrayReadV3&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayGrad/gradient_flow&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Merge_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/Switch_1_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Enter_2_grad/Exit&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_2_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Enter_3_grad/Exit&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_3_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Enter_1_grad/Exit&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_1_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_grad/zeros_like/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_grad/zeros_like&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_grad/zeros_like/Enter&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_grad/Select/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/GreaterEqual&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_grad/Select/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_grad/Select/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/GreaterEqual&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_grad/Select/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_grad/Select/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/GreaterEqual&quot;\\n  input: &quot;^gradients/Add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/GreaterEqual&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_grad/Select/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_grad/Select/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/GreaterEqual&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_grad/Select/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_grad/Select/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/GreaterEqual&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_grad/Select&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_grad/Select/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_grad/zeros_like&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_grad/Select_1&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_grad/Select/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_grad/zeros_like&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Select_grad/Select&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Select_grad/Select_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_grad/Select&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Select_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/Select_grad/Select&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_grad/Select_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Select_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/Select_grad/Select_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/LSTMCellZeroState/zeros_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/LSTMCellZeroState/zeros_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Enter_2_grad/Exit&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/LSTMCellZeroState/zeros_grad/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/zeros_like/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/Identity_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/zeros_like/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/zeros_like/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/Identity_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/zeros_like/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/zeros_like/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Identity_2&quot;\\n  input: &quot;^gradients/Add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/Identity_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/zeros_like/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/zeros_like/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/Identity_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/zeros_like/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/zeros_like/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/Identity_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/zeros_like/b_sync&quot;\\n  op: &quot;ControlTrigger&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/zeros_like/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/Select/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/zeros_like/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/Select/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Select_grad/Select/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul_1/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/mul_1/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul_1/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split_grad/concat/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/MatMul_1/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/mod/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/ShapeN/StackPop&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/zeros_like&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/zeros_like/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/Select/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/GreaterEqual_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/Select/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/Select/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/GreaterEqual_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/Select/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/Select/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/GreaterEqual_1&quot;\\n  input: &quot;^gradients/Add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/GreaterEqual_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/Select/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/Select/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/GreaterEqual_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/Select/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/Select/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/GreaterEqual_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/Select&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/Select/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_2_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/zeros_like&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/Select_1&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/Select/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/zeros_like&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_2_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/Select&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/Select_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/Select&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/Select&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/Select_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/Select_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/LSTMCellZeroState/zeros_1_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/LSTMCellZeroState/zeros_1_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Enter_3_grad/Exit&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/LSTMCellZeroState/zeros_1_grad/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/zeros_like/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/Identity_3&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/zeros_like/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/zeros_like/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/Identity_3&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/zeros_like/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/zeros_like/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Identity_3&quot;\\n  input: &quot;^gradients/Add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/Identity_3&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/zeros_like/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/zeros_like/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/Identity_3&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/zeros_like/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/zeros_like/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/Identity_3&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/zeros_like&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/zeros_like/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/Select/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/GreaterEqual_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/Select/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/Select/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/GreaterEqual_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/Select/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/Select/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/GreaterEqual_2&quot;\\n  input: &quot;^gradients/Add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/GreaterEqual_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/Select/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/Select/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/GreaterEqual_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/Select/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/Select/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/GreaterEqual_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/Select&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/Select/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_3_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/zeros_like&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/Select_1&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/Select/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/zeros_like&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_3_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/Select&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/Select_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/Select&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/Select&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/Select_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/Select_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayGrad/TensorArrayGradV3/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArray&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  op: &quot;TensorArrayGradV3&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayGrad/TensorArrayGradV3/Enter&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_1_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;source&quot;\\n    value {\\n      s: &quot;gradients&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayGrad/gradient_flow&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/Identity&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/Identity&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Identity&quot;\\n  input: &quot;^gradients/Add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/Identity&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/Identity&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/Identity&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3&quot;\\n  op: &quot;TensorArrayReadV3&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayGrad/gradient_flow&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Merge_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/bw/bw/while/Switch_1_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select/Enter_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select/Enter_grad/zeros/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select/Enter_grad/zeros&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select/Enter_grad/Shape&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select/Enter_grad/zeros/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select/Enter_grad/b_acc&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select/Enter_grad/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select/Enter_grad/b_acc_1&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select/Enter_grad/b_acc&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select/Enter_grad/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select/Enter_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select/Enter_grad/b_acc_1&quot;\\n  input: &quot;gradients/b_count_6&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select/Enter_grad/Add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select/Enter_grad/Switch:1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select/Enter_grad/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select/Enter_grad/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select/Enter_grad/b_acc_2&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select/Enter_grad/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_7&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/Select_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Tanh_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/Shape&quot;\\n  input: &quot;^gradients/Add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/RefEnter_1&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPush_1&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/RefEnter_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/Shape_1&quot;\\n  input: &quot;^gradients/Add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPop_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPop_1/RefEnter&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Tanh_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Tanh_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Tanh_1&quot;\\n  input: &quot;^gradients/Add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Tanh_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Tanh_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Tanh_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/AddN_7&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul_1/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul_1/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul_1/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid_2&quot;\\n  input: &quot;^gradients/Add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul_1/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul_1/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul_1/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul_1/StackPop&quot;\\n  input: &quot;gradients/AddN_7&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/Sum_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/Reshape&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/Reshape&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/Reshape_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Switch_1_grad_1/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_grad/zeros_like/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_grad/zeros_like&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_grad/zeros_like/Enter&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_grad/Select/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/GreaterEqual&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_grad/Select/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_grad/Select/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/GreaterEqual&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_grad/Select/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_grad/Select/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/GreaterEqual&quot;\\n  input: &quot;^gradients/Add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/GreaterEqual&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_grad/Select/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_grad/Select/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/GreaterEqual&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_grad/Select/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_grad/Select/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/GreaterEqual&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_grad/Select&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_grad/Select/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_grad/zeros_like&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_grad/Select_1&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_grad/Select/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_grad/zeros_like&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Select_grad/Select&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Select_grad/Select_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_grad/Select&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Select_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/bw/bw/while/Select_grad/Select&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_grad/Select_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Select_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/bw/bw/while/Select_grad/Select_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/zeros_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/zeros_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select/Enter_grad/b_acc_2&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/zeros_grad/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid_2_grad/SigmoidGrad&quot;\\n  op: &quot;SigmoidGrad&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul_1/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Tanh_1_grad/TanhGrad&quot;\\n  op: &quot;TanhGrad&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select/Enter_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select/Enter_grad/zeros/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select/Enter_grad/zeros&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select/Enter_grad/Shape&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select/Enter_grad/zeros/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select/Enter_grad/b_acc&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select/Enter_grad/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select/Enter_grad/b_acc_1&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select/Enter_grad/b_acc&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select/Enter_grad/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select/Enter_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select/Enter_grad/b_acc_1&quot;\\n  input: &quot;gradients/b_count_10&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select/Enter_grad/Add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select/Enter_grad/Switch:1&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select/Enter_grad/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select/Enter_grad/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select/Enter_grad/b_acc_2&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select/Enter_grad/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_8&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/Select_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Tanh_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs/RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/Shape&quot;\\n  input: &quot;^gradients/Add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs/RefEnter_1&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs/StackPush_1&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs/RefEnter_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/Shape_1&quot;\\n  input: &quot;^gradients/Add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs/StackPop_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs/StackPop_1/RefEnter&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Tanh_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Tanh_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Tanh_1&quot;\\n  input: &quot;^gradients/Add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Tanh_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Tanh_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Tanh_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/AddN_8&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul_1/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul_1/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul_1/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid_2&quot;\\n  input: &quot;^gradients/Add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul_1/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul_1/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul_1/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul_1/StackPop&quot;\\n  input: &quot;gradients/AddN_8&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/Sum_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/Reshape&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/Reshape&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/Reshape_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Switch_1_grad_1/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_9&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Tanh_1_grad/TanhGrad&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/Select_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/Shape&quot;\\n  input: &quot;^gradients/Add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/RefEnter_1&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPush_1&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/RefEnter_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/Shape_1&quot;\\n  input: &quot;^gradients/Add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPop_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPop_1/RefEnter&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/AddN_9&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/AddN_9&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/Sum_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/Reshape&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/Reshape&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/Reshape_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/zeros_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/zeros_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select/Enter_grad/b_acc_2&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/zeros_grad/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid_2_grad/SigmoidGrad&quot;\\n  op: &quot;SigmoidGrad&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul_1/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Tanh_1_grad/TanhGrad&quot;\\n  op: &quot;TanhGrad&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Identity_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/Shape&quot;\\n  input: &quot;^gradients/Add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/RefEnter_1&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPush_1&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/RefEnter_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/Shape_1&quot;\\n  input: &quot;^gradients/Add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPop_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPop_1/RefEnter&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/zeros_like/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/mul&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/mul_1/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/mul_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/mul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/mul_1/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/mul_1/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid&quot;\\n  input: &quot;^gradients/Add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/mul_1/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/mul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/mul_1/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/mul_1/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/mul_1/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/mul_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/Sum_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/Reshape&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/Reshape&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/Reshape_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Tanh&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/Shape&quot;\\n  input: &quot;^gradients/Add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/RefEnter_1&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPush_1&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/RefEnter_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/Shape_1&quot;\\n  input: &quot;^gradients/Add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPop_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPop_1/RefEnter&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Tanh&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Tanh&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Tanh&quot;\\n  input: &quot;^gradients/Add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Tanh&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Tanh&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Tanh&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul_1/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul_1/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul_1/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid_1&quot;\\n  input: &quot;^gradients/Add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul_1/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul_1/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul_1/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul_1/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/Sum_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/Reshape&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/Reshape&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/Reshape_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_10&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Tanh_1_grad/TanhGrad&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/Select_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs/RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/Shape&quot;\\n  input: &quot;^gradients/Add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs/RefEnter_1&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs/StackPush_1&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs/RefEnter_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/Shape_1&quot;\\n  input: &quot;^gradients/Add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs/StackPop_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs/StackPop_1/RefEnter&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/AddN_10&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/AddN_10&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/Sum_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/Reshape&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/Reshape&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/Reshape_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid_grad/SigmoidGrad&quot;\\n  op: &quot;SigmoidGrad&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/mul_1/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_11&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/Select&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid_1_grad/SigmoidGrad&quot;\\n  op: &quot;SigmoidGrad&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul_1/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Tanh_grad/TanhGrad&quot;\\n  op: &quot;TanhGrad&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Identity_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs/RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/Shape&quot;\\n  input: &quot;^gradients/Add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs/RefEnter_1&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs/StackPush_1&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs/RefEnter_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/Shape_1&quot;\\n  input: &quot;^gradients/Add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs/StackPop_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs/StackPop_1/RefEnter&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/zeros_like/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/mul&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/mul_1/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/mul_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/mul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/mul_1/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/mul_1/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid&quot;\\n  input: &quot;^gradients/Add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/mul_1/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/mul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/mul_1/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/mul_1/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/mul_1/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/mul_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/Sum_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/Reshape&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/Reshape&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/Reshape_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Tanh&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs/RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/Shape&quot;\\n  input: &quot;^gradients/Add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs/RefEnter_1&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs/StackPush_1&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs/RefEnter_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/Shape_1&quot;\\n  input: &quot;^gradients/Add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs/StackPop_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs/StackPop_1/RefEnter&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Tanh&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Tanh&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Tanh&quot;\\n  input: &quot;^gradients/Add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Tanh&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Tanh&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Tanh&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul_1/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul_1/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul_1/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid_1&quot;\\n  input: &quot;^gradients/Add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul_1/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul_1/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul_1/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul_1/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/Sum_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/Reshape&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/Reshape&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/Reshape_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split:2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs/RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/Shape&quot;\\n  input: &quot;^gradients/Add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid_grad/SigmoidGrad&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid_grad/SigmoidGrad&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/Sum_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/Reshape&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/Reshape&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/Reshape_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Switch_2_grad_1/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/AddN_11&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid_grad/SigmoidGrad&quot;\\n  op: &quot;SigmoidGrad&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/mul_1/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_12&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/Select&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid_1_grad/SigmoidGrad&quot;\\n  op: &quot;SigmoidGrad&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul_1/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Tanh_grad/TanhGrad&quot;\\n  op: &quot;TanhGrad&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split_grad/concat/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split/split_dim&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split_grad/concat/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split_grad/concat/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split/split_dim&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split_grad/concat/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split_grad/concat/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split/split_dim&quot;\\n  input: &quot;^gradients/Add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split/split_dim&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split_grad/concat/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split_grad/concat/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split/split_dim&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split_grad/concat/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split_grad/concat/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split/split_dim&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split_grad/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid_1_grad/SigmoidGrad&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Tanh_grad/TanhGrad&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid_2_grad/SigmoidGrad&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split_grad/concat/StackPop&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 4\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split:2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/BroadcastGradientArgs/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/BroadcastGradientArgs/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/BroadcastGradientArgs/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/BroadcastGradientArgs/RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/Shape&quot;\\n  input: &quot;^gradients/Add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/BroadcastGradientArgs/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid_grad/SigmoidGrad&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/BroadcastGradientArgs/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid_grad/SigmoidGrad&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/Sum_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/Reshape&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/Reshape&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/Reshape_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Switch_2_grad_1/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/AddN_12&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd_grad/BiasAddGrad&quot;\\n  op: &quot;BiasAddGrad&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split_grad/concat&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split_grad/concat&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd_grad/BiasAddGrad&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split_grad/concat&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split_grad/concat&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd_grad/BiasAddGrad&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd_grad/BiasAddGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split_grad/concat/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split/split_dim&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split_grad/concat/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split_grad/concat/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split/split_dim&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split_grad/concat/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split_grad/concat/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split/split_dim&quot;\\n  input: &quot;^gradients/Add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split/split_dim&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split_grad/concat/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split_grad/concat/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split/split_dim&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split_grad/concat/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split_grad/concat/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split/split_dim&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split_grad/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid_1_grad/SigmoidGrad&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Tanh_grad/TanhGrad&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid_2_grad/SigmoidGrad&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split_grad/concat/StackPop&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 4\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat&quot;\\n  input: &quot;^gradients/Add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/b_acc&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 64\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/b_acc_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/b_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/b_acc_2&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/b_acc_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/b_acc_2&quot;\\n  input: &quot;gradients/b_count_6&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/Add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/Switch:1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/b_acc_3&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd_grad/BiasAddGrad&quot;\\n  op: &quot;BiasAddGrad&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split_grad/concat&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split_grad/concat&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd_grad/BiasAddGrad&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split_grad/concat&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split_grad/concat&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd_grad/BiasAddGrad&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd_grad/BiasAddGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/Rank&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat/axis&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat/axis&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat/axis&quot;\\n  input: &quot;^gradients/Add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat/axis&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat/axis&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat/axis&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod&quot;\\n  op: &quot;FloorMod&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/Rank&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/TensorArrayReadV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/TensorArrayReadV3&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/TensorArrayReadV3&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/TensorArrayReadV3&quot;\\n  input: &quot;^gradients/Add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/TensorArrayReadV3&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/TensorArrayReadV3&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/TensorArrayReadV3&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN&quot;\\n  op: &quot;ShapeN&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/zeros_like/StackPop&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/ConcatOffset&quot;\\n  op: &quot;ConcatOffset&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN:1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/Slice&quot;\\n  op: &quot;Slice&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/ConcatOffset&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/Slice_1&quot;\\n  op: &quot;Slice&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/ConcatOffset:1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN:1&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/Slice&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/Slice_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/Slice&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/Slice&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/Slice_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/Slice_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/b_acc&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 36\\n          }\\n          dim {\\n            size: 64\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/b_acc_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/b_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/b_acc_2&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/b_acc_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/b_acc_2&quot;\\n  input: &quot;gradients/b_count_6&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/Add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/Switch:1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/b_acc_3&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/MatMul/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/MatMul/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/MatMul_1/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/MatMul_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/MatMul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/MatMul_1/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/MatMul_1/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat&quot;\\n  input: &quot;^gradients/Add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/MatMul_1/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/MatMul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/MatMul_1/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/MatMul_1/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/MatMul_1/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd/Enter_grad/b_acc&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 64\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd/Enter_grad/b_acc_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd/Enter_grad/b_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd/Enter_grad/b_acc_2&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd/Enter_grad/b_acc_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd/Enter_grad/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd/Enter_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd/Enter_grad/b_acc_2&quot;\\n  input: &quot;gradients/b_count_10&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd/Enter_grad/Add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd/Enter_grad/Switch:1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd/Enter_grad/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd/Enter_grad/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd/Enter_grad/b_acc_3&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd/Enter_grad/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArray_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3/Enter_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  op: &quot;TensorArrayGradV3&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3/Enter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3/Enter_1&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;source&quot;\\n    value {\\n      s: &quot;gradients&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3_grad/TensorArrayGrad/gradient_flow&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3/Enter_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3_grad/TensorArrayWrite/TensorArrayWriteV3&quot;\\n  op: &quot;TensorArrayWriteV3&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3_grad/TensorArrayGrad/gradient_flow&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_13&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/Select&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/Rank&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/mod/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat/axis&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/mod/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/mod/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat/axis&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/mod/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/mod/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat/axis&quot;\\n  input: &quot;^gradients/Add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat/axis&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/mod/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/mod/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat/axis&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/mod/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/mod/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat/axis&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/mod&quot;\\n  op: &quot;FloorMod&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/mod/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/Rank&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/TensorArrayReadV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/ShapeN/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/TensorArrayReadV3&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/ShapeN/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/ShapeN/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/TensorArrayReadV3&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/ShapeN/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/ShapeN/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/TensorArrayReadV3&quot;\\n  input: &quot;^gradients/Add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/TensorArrayReadV3&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/ShapeN/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/ShapeN/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/TensorArrayReadV3&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/ShapeN/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/ShapeN/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/TensorArrayReadV3&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/ShapeN&quot;\\n  op: &quot;ShapeN&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/ShapeN/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/zeros_like/StackPop&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/ConcatOffset&quot;\\n  op: &quot;ConcatOffset&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/mod&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/ShapeN&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/ShapeN:1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/Slice&quot;\\n  op: &quot;Slice&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/ConcatOffset&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/ShapeN&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/Slice_1&quot;\\n  op: &quot;Slice&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/ConcatOffset:1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/ShapeN:1&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/Slice&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/Slice_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/Slice&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/Slice&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/Slice_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/Slice_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul/Enter_grad/b_acc&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 36\\n          }\\n          dim {\\n            size: 64\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul/Enter_grad/b_acc_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul/Enter_grad/b_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul/Enter_grad/b_acc_2&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul/Enter_grad/b_acc_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul/Enter_grad/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul/Enter_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul/Enter_grad/b_acc_2&quot;\\n  input: &quot;gradients/b_count_10&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul/Enter_grad/Add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul/Enter_grad/Switch:1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul/Enter_grad/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul/Enter_grad/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul/Enter_grad/b_acc_3&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul/Enter_grad/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_14&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/b_acc_3&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd/Enter_grad/b_acc_3&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/b_acc_3&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1_grad/b_acc&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1_grad/b_acc_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1_grad/b_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1_grad/b_acc_2&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1_grad/b_acc_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1_grad/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1_grad/b_acc_2&quot;\\n  input: &quot;gradients/b_count_6&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1_grad/Add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1_grad/Switch:1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3_grad/TensorArrayWrite/TensorArrayWriteV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1_grad/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1_grad/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1_grad/b_acc_3&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1_grad/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Switch_3_grad_1/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/AddN_13&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArray_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3/Enter_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  op: &quot;TensorArrayGradV3&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3/Enter&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3/Enter_1&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;source&quot;\\n    value {\\n      s: &quot;gradients&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3_grad/TensorArrayGrad/gradient_flow&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3/Enter_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3_grad/TensorArrayWrite/TensorArrayWriteV3&quot;\\n  op: &quot;TensorArrayWriteV3&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3_grad/TensorArrayGrad/gradient_flow&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_15&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/Select&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_16&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/b_acc_3&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul/Enter_grad/b_acc_3&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/b_acc_3&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  op: &quot;TensorArrayGradV3&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArray_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1_grad/b_acc_3&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/TensorArray_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;source&quot;\\n    value {\\n      s: &quot;gradients&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGrad/gradient_flow&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1_grad/b_acc_3&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/TensorArray_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGatherV3&quot;\\n  op: &quot;TensorArrayGatherV3&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArrayUnstack/range&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGrad/gradient_flow&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;element_shape&quot;\\n    value {\\n      shape {\\n        unknown_rank: true\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1_grad/b_acc_3&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGatherV3&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGatherV3&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGatherV3&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1_grad/b_acc_3&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1_grad/b_acc_3&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter_1_grad/b_acc&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter_1_grad/b_acc_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter_1_grad/b_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter_1_grad/b_acc_2&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter_1_grad/b_acc_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter_1_grad/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter_1_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter_1_grad/b_acc_2&quot;\\n  input: &quot;gradients/b_count_10&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter_1_grad/Add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter_1_grad/Switch:1&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3_grad/TensorArrayWrite/TensorArrayWriteV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter_1_grad/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter_1_grad/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter_1_grad/b_acc_3&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter_1_grad/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Switch_3_grad_1/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/AddN_15&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  op: &quot;TensorArrayGradV3&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArray_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter_1_grad/b_acc_3&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/TensorArray_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;source&quot;\\n    value {\\n      s: &quot;gradients&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGrad/gradient_flow&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter_1_grad/b_acc_3&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/TensorArray_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGatherV3&quot;\\n  op: &quot;TensorArrayGatherV3&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArrayUnstack/range&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGrad/gradient_flow&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;element_shape&quot;\\n    value {\\n      shape {\\n        unknown_rank: true\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter_1_grad/b_acc_3&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGatherV3&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGatherV3&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/bw/bw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGatherV3&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter_1_grad/b_acc_3&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter_1_grad/b_acc_3&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/ReverseSequence_grad/ReverseSequence&quot;\\n  op: &quot;ReverseSequence&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/tuple/control_dependency&quot;\\n  input: &quot;encoder_inputs_length&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tlen&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;batch_dim&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;seq_dim&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_17&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/ReverseSequence_grad/ReverseSequence&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGatherV3&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/embedding_lookup_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT64\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\n\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\024\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/embedding_lookup_grad/ToInt32&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;gradients/embedding_lookup_grad/Shape&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/embedding_lookup_grad/Size&quot;\\n  op: &quot;Size&quot;\\n  input: &quot;encoder_inputs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/embedding_lookup_grad/ExpandDims/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/embedding_lookup_grad/ExpandDims&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;gradients/embedding_lookup_grad/Size&quot;\\n  input: &quot;gradients/embedding_lookup_grad/ExpandDims/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/embedding_lookup_grad/strided_slice/stack&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/embedding_lookup_grad/strided_slice/stack_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/embedding_lookup_grad/strided_slice/stack_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/embedding_lookup_grad/strided_slice&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;gradients/embedding_lookup_grad/ToInt32&quot;\\n  input: &quot;gradients/embedding_lookup_grad/strided_slice/stack&quot;\\n  input: &quot;gradients/embedding_lookup_grad/strided_slice/stack_1&quot;\\n  input: &quot;gradients/embedding_lookup_grad/strided_slice/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/embedding_lookup_grad/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/embedding_lookup_grad/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;gradients/embedding_lookup_grad/ExpandDims&quot;\\n  input: &quot;gradients/embedding_lookup_grad/strided_slice&quot;\\n  input: &quot;gradients/embedding_lookup_grad/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/embedding_lookup_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/AddN_17&quot;\\n  input: &quot;gradients/embedding_lookup_grad/concat&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/embedding_lookup_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;encoder_inputs&quot;\\n  input: &quot;gradients/embedding_lookup_grad/ExpandDims&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;gradients/embedding_lookup_1_grad/Reshape&quot;\\n  input: &quot;gradients/embedding_lookup_grad/Reshape&quot;\\n  input: &quot;gradients/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_1/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_1&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;gradients/embedding_lookup_1_grad/Reshape_1&quot;\\n  input: &quot;gradients/embedding_lookup_grad/Reshape_1&quot;\\n  input: &quot;gradients/concat_1/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;beta1_power/initial_value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.899999976158\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;beta1_power&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;beta1_power/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;beta1_power&quot;\\n  input: &quot;beta1_power/initial_value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;beta1_power/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;beta1_power&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;beta2_power/initial_value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.999000012875\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;beta2_power&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;beta2_power/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;beta2_power&quot;\\n  input: &quot;beta2_power/initial_value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;beta2_power/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;beta2_power&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Variable/Adam/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 10\\n          }\\n          dim {\\n            size: 20\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Variable/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 10\\n        }\\n        dim {\\n          size: 20\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Variable/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Variable/Adam&quot;\\n  input: &quot;Variable/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Variable/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Variable/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Variable/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 10\\n          }\\n          dim {\\n            size: 20\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Variable/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 10\\n        }\\n        dim {\\n          size: 20\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Variable/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Variable/Adam_1&quot;\\n  input: &quot;Variable/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Variable/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Variable/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Adam/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 36\\n          }\\n          dim {\\n            size: 64\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 36\\n        }\\n        dim {\\n          size: 64\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Adam&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 36\\n          }\\n          dim {\\n            size: 64\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 36\\n        }\\n        dim {\\n          size: 64\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Adam_1&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/bias/Adam/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 64\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/bias/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 64\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/bias/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/bias/Adam&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/bias/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/bias/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/bias/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/bias/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 64\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/bias/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 64\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/bias/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/bias/Adam_1&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/bias/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/bias/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/bias/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;memory_layer/kernel/Adam/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@memory_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 32\\n          }\\n          dim {\\n            size: 32\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;memory_layer/kernel/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@memory_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 32\\n        }\\n        dim {\\n          size: 32\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;memory_layer/kernel/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;memory_layer/kernel/Adam&quot;\\n  input: &quot;memory_layer/kernel/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@memory_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;memory_layer/kernel/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;memory_layer/kernel/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@memory_layer/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;memory_layer/kernel/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@memory_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 32\\n          }\\n          dim {\\n            size: 32\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;memory_layer/kernel/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@memory_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 32\\n        }\\n        dim {\\n          size: 32\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;memory_layer/kernel/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;memory_layer/kernel/Adam_1&quot;\\n  input: &quot;memory_layer/kernel/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@memory_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;memory_layer/kernel/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;memory_layer/kernel/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@memory_layer/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/kernel/Adam/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 84\\n          }\\n          dim {\\n            size: 128\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/kernel/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 84\\n        }\\n        dim {\\n          size: 128\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/kernel/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/kernel/Adam&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/kernel/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/kernel/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/kernel/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/kernel/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 84\\n          }\\n          dim {\\n            size: 128\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/kernel/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 84\\n        }\\n        dim {\\n          size: 128\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/kernel/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/kernel/Adam_1&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/kernel/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/kernel/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/kernel/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/bias/Adam/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 128\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/bias/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 128\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/bias/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/bias/Adam&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/bias/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/bias/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/bias/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/bias/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 128\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/bias/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 128\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/bias/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/bias/Adam_1&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/bias/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/bias/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/bias/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/attention_layer/kernel/Adam/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/attention_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 64\\n          }\\n          dim {\\n            size: 32\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/attention_layer/kernel/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/attention_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 64\\n        }\\n        dim {\\n          size: 32\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/attention_layer/kernel/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;decoder/attention_wrapper/attention_layer/kernel/Adam&quot;\\n  input: &quot;decoder/attention_wrapper/attention_layer/kernel/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/attention_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/attention_layer/kernel/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/attention_wrapper/attention_layer/kernel/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/attention_layer/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/attention_layer/kernel/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/attention_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 64\\n          }\\n          dim {\\n            size: 32\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/attention_layer/kernel/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/attention_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 64\\n        }\\n        dim {\\n          size: 32\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/attention_layer/kernel/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;decoder/attention_wrapper/attention_layer/kernel/Adam_1&quot;\\n  input: &quot;decoder/attention_wrapper/attention_layer/kernel/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/attention_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/attention_layer/kernel/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/attention_wrapper/attention_layer/kernel/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/attention_layer/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/kernel/Adam/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 32\\n          }\\n          dim {\\n            size: 10\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/kernel/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 32\\n        }\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/kernel/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;decoder/dense/kernel/Adam&quot;\\n  input: &quot;decoder/dense/kernel/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/kernel/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/dense/kernel/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/kernel/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 32\\n          }\\n          dim {\\n            size: 10\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/kernel/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 32\\n        }\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/kernel/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;decoder/dense/kernel/Adam_1&quot;\\n  input: &quot;decoder/dense/kernel/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/kernel/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/dense/kernel/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/bias/Adam/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 10\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/bias/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/bias/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;decoder/dense/bias/Adam&quot;\\n  input: &quot;decoder/dense/bias/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/bias/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/dense/bias/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/bias/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 10\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/bias/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/bias/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;decoder/dense/bias/Adam_1&quot;\\n  input: &quot;decoder/dense/bias/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/bias/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/dense/bias/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/learning_rate&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0010000000475\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/beta1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.899999976158\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/beta2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.999000012875\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/epsilon&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 9.99999993923e-09\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/Unique&quot;\\n  op: &quot;Unique&quot;\\n  input: &quot;gradients/concat_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;out_idx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Adam/update_Variable/Unique&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/strided_slice/stack&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/strided_slice/stack_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/strided_slice/stack_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/strided_slice&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;Adam/update_Variable/Shape&quot;\\n  input: &quot;Adam/update_Variable/strided_slice/stack&quot;\\n  input: &quot;Adam/update_Variable/strided_slice/stack_1&quot;\\n  input: &quot;Adam/update_Variable/strided_slice/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/UnsortedSegmentSum&quot;\\n  op: &quot;UnsortedSegmentSum&quot;\\n  input: &quot;gradients/concat&quot;\\n  input: &quot;Adam/update_Variable/Unique:1&quot;\\n  input: &quot;Adam/update_Variable/strided_slice&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tindices&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/sub/x&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;Adam/update_Variable/sub/x&quot;\\n  input: &quot;beta2_power/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/Sqrt&quot;\\n  op: &quot;Sqrt&quot;\\n  input: &quot;Adam/update_Variable/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Adam/learning_rate&quot;\\n  input: &quot;Adam/update_Variable/Sqrt&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/sub_1/x&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/sub_1&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;Adam/update_Variable/sub_1/x&quot;\\n  input: &quot;beta1_power/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/truediv&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;Adam/update_Variable/mul&quot;\\n  input: &quot;Adam/update_Variable/sub_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/sub_2/x&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/sub_2&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;Adam/update_Variable/sub_2/x&quot;\\n  input: &quot;Adam/beta1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Adam/update_Variable/UnsortedSegmentSum&quot;\\n  input: &quot;Adam/update_Variable/sub_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/mul_2&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Variable/Adam/read&quot;\\n  input: &quot;Adam/beta1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Variable/Adam&quot;\\n  input: &quot;Adam/update_Variable/mul_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/ScatterAdd&quot;\\n  op: &quot;ScatterAdd&quot;\\n  input: &quot;Variable/Adam&quot;\\n  input: &quot;Adam/update_Variable/Unique&quot;\\n  input: &quot;Adam/update_Variable/mul_1&quot;\\n  input: &quot;^Adam/update_Variable/Assign&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tindices&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/mul_3&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Adam/update_Variable/UnsortedSegmentSum&quot;\\n  input: &quot;Adam/update_Variable/UnsortedSegmentSum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/sub_3/x&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/sub_3&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;Adam/update_Variable/sub_3/x&quot;\\n  input: &quot;Adam/beta2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/mul_4&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Adam/update_Variable/mul_3&quot;\\n  input: &quot;Adam/update_Variable/sub_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/mul_5&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Variable/Adam_1/read&quot;\\n  input: &quot;Adam/beta2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/Assign_1&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Variable/Adam_1&quot;\\n  input: &quot;Adam/update_Variable/mul_5&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/ScatterAdd_1&quot;\\n  op: &quot;ScatterAdd&quot;\\n  input: &quot;Variable/Adam_1&quot;\\n  input: &quot;Adam/update_Variable/Unique&quot;\\n  input: &quot;Adam/update_Variable/mul_4&quot;\\n  input: &quot;^Adam/update_Variable/Assign_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tindices&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/Sqrt_1&quot;\\n  op: &quot;Sqrt&quot;\\n  input: &quot;Adam/update_Variable/ScatterAdd_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/mul_6&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Adam/update_Variable/truediv&quot;\\n  input: &quot;Adam/update_Variable/ScatterAdd&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;Adam/update_Variable/Sqrt_1&quot;\\n  input: &quot;Adam/epsilon&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/truediv_1&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;Adam/update_Variable/mul_6&quot;\\n  input: &quot;Adam/update_Variable/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/AssignSub&quot;\\n  op: &quot;AssignSub&quot;\\n  input: &quot;Variable&quot;\\n  input: &quot;Adam/update_Variable/truediv_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^Adam/update_Variable/AssignSub&quot;\\n  input: &quot;^Adam/update_Variable/ScatterAdd&quot;\\n  input: &quot;^Adam/update_Variable/ScatterAdd_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_bidirectional_rnn/fw/lstm_cell/kernel/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/kernel&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Adam&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Adam_1&quot;\\n  input: &quot;beta1_power/read&quot;\\n  input: &quot;beta2_power/read&quot;\\n  input: &quot;Adam/learning_rate&quot;\\n  input: &quot;Adam/beta1&quot;\\n  input: &quot;Adam/beta2&quot;\\n  input: &quot;Adam/epsilon&quot;\\n  input: &quot;gradients/AddN_16&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_bidirectional_rnn/fw/lstm_cell/bias/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/bias&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/bias/Adam&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/bias/Adam_1&quot;\\n  input: &quot;beta1_power/read&quot;\\n  input: &quot;beta2_power/read&quot;\\n  input: &quot;Adam/learning_rate&quot;\\n  input: &quot;Adam/beta1&quot;\\n  input: &quot;Adam/beta2&quot;\\n  input: &quot;Adam/epsilon&quot;\\n  input: &quot;gradients/AddN_14&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_memory_layer/kernel/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;memory_layer/kernel&quot;\\n  input: &quot;memory_layer/kernel/Adam&quot;\\n  input: &quot;memory_layer/kernel/Adam_1&quot;\\n  input: &quot;beta1_power/read&quot;\\n  input: &quot;beta2_power/read&quot;\\n  input: &quot;Adam/learning_rate&quot;\\n  input: &quot;Adam/beta1&quot;\\n  input: &quot;Adam/beta2&quot;\\n  input: &quot;Adam/epsilon&quot;\\n  input: &quot;gradients/LuongAttention/memory_layer/Tensordot/transpose_1_grad/transpose&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@memory_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_decoder/attention_wrapper/lstm_cell/kernel/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/kernel&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/kernel/Adam&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/kernel/Adam_1&quot;\\n  input: &quot;beta1_power/read&quot;\\n  input: &quot;beta2_power/read&quot;\\n  input: &quot;Adam/learning_rate&quot;\\n  input: &quot;Adam/beta1&quot;\\n  input: &quot;Adam/beta2&quot;\\n  input: &quot;Adam/epsilon&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/b_acc_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_decoder/attention_wrapper/lstm_cell/bias/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/bias&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/bias/Adam&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/bias/Adam_1&quot;\\n  input: &quot;beta1_power/read&quot;\\n  input: &quot;beta2_power/read&quot;\\n  input: &quot;Adam/learning_rate&quot;\\n  input: &quot;Adam/beta1&quot;\\n  input: &quot;Adam/beta2&quot;\\n  input: &quot;Adam/epsilon&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/b_acc_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_decoder/attention_wrapper/attention_layer/kernel/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;decoder/attention_wrapper/attention_layer/kernel&quot;\\n  input: &quot;decoder/attention_wrapper/attention_layer/kernel/Adam&quot;\\n  input: &quot;decoder/attention_wrapper/attention_layer/kernel/Adam_1&quot;\\n  input: &quot;beta1_power/read&quot;\\n  input: &quot;beta2_power/read&quot;\\n  input: &quot;Adam/learning_rate&quot;\\n  input: &quot;Adam/beta1&quot;\\n  input: &quot;Adam/beta2&quot;\\n  input: &quot;Adam/epsilon&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul/Enter_grad/b_acc_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/attention_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_decoder/dense/kernel/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;decoder/dense/kernel&quot;\\n  input: &quot;decoder/dense/kernel/Adam&quot;\\n  input: &quot;decoder/dense/kernel/Adam_1&quot;\\n  input: &quot;beta1_power/read&quot;\\n  input: &quot;beta2_power/read&quot;\\n  input: &quot;Adam/learning_rate&quot;\\n  input: &quot;Adam/beta1&quot;\\n  input: &quot;Adam/beta2&quot;\\n  input: &quot;Adam/epsilon&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul/Enter_grad/b_acc_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_decoder/dense/bias/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;decoder/dense/bias&quot;\\n  input: &quot;decoder/dense/bias/Adam&quot;\\n  input: &quot;decoder/dense/bias/Adam_1&quot;\\n  input: &quot;beta1_power/read&quot;\\n  input: &quot;beta2_power/read&quot;\\n  input: &quot;Adam/learning_rate&quot;\\n  input: &quot;Adam/beta1&quot;\\n  input: &quot;Adam/beta2&quot;\\n  input: &quot;Adam/epsilon&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/BiasAdd/Enter_grad/b_acc_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;beta1_power/read&quot;\\n  input: &quot;Adam/beta1&quot;\\n  input: &quot;^Adam/update_Variable/group_deps&quot;\\n  input: &quot;^Adam/update_bidirectional_rnn/fw/lstm_cell/kernel/ApplyAdam&quot;\\n  input: &quot;^Adam/update_bidirectional_rnn/fw/lstm_cell/bias/ApplyAdam&quot;\\n  input: &quot;^Adam/update_memory_layer/kernel/ApplyAdam&quot;\\n  input: &quot;^Adam/update_decoder/attention_wrapper/lstm_cell/kernel/ApplyAdam&quot;\\n  input: &quot;^Adam/update_decoder/attention_wrapper/lstm_cell/bias/ApplyAdam&quot;\\n  input: &quot;^Adam/update_decoder/attention_wrapper/attention_layer/kernel/ApplyAdam&quot;\\n  input: &quot;^Adam/update_decoder/dense/kernel/ApplyAdam&quot;\\n  input: &quot;^Adam/update_decoder/dense/bias/ApplyAdam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;beta1_power&quot;\\n  input: &quot;Adam/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;beta2_power/read&quot;\\n  input: &quot;Adam/beta2&quot;\\n  input: &quot;^Adam/update_Variable/group_deps&quot;\\n  input: &quot;^Adam/update_bidirectional_rnn/fw/lstm_cell/kernel/ApplyAdam&quot;\\n  input: &quot;^Adam/update_bidirectional_rnn/fw/lstm_cell/bias/ApplyAdam&quot;\\n  input: &quot;^Adam/update_memory_layer/kernel/ApplyAdam&quot;\\n  input: &quot;^Adam/update_decoder/attention_wrapper/lstm_cell/kernel/ApplyAdam&quot;\\n  input: &quot;^Adam/update_decoder/attention_wrapper/lstm_cell/bias/ApplyAdam&quot;\\n  input: &quot;^Adam/update_decoder/attention_wrapper/attention_layer/kernel/ApplyAdam&quot;\\n  input: &quot;^Adam/update_decoder/dense/kernel/ApplyAdam&quot;\\n  input: &quot;^Adam/update_decoder/dense/bias/ApplyAdam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/Assign_1&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;beta2_power&quot;\\n  input: &quot;Adam/mul_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^Adam/update_Variable/group_deps&quot;\\n  input: &quot;^Adam/update_bidirectional_rnn/fw/lstm_cell/kernel/ApplyAdam&quot;\\n  input: &quot;^Adam/update_bidirectional_rnn/fw/lstm_cell/bias/ApplyAdam&quot;\\n  input: &quot;^Adam/update_memory_layer/kernel/ApplyAdam&quot;\\n  input: &quot;^Adam/update_decoder/attention_wrapper/lstm_cell/kernel/ApplyAdam&quot;\\n  input: &quot;^Adam/update_decoder/attention_wrapper/lstm_cell/bias/ApplyAdam&quot;\\n  input: &quot;^Adam/update_decoder/attention_wrapper/attention_layer/kernel/ApplyAdam&quot;\\n  input: &quot;^Adam/update_decoder/dense/kernel/ApplyAdam&quot;\\n  input: &quot;^Adam/update_decoder/dense/bias/ApplyAdam&quot;\\n  input: &quot;^Adam/Assign&quot;\\n  input: &quot;^Adam/Assign_1&quot;\\n}\\nnode {\\n  name: &quot;init&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^Variable/Assign&quot;\\n  input: &quot;^bidirectional_rnn/fw/lstm_cell/kernel/Assign&quot;\\n  input: &quot;^bidirectional_rnn/fw/lstm_cell/bias/Assign&quot;\\n  input: &quot;^memory_layer/kernel/Assign&quot;\\n  input: &quot;^decoder/attention_wrapper/lstm_cell/kernel/Assign&quot;\\n  input: &quot;^decoder/attention_wrapper/lstm_cell/bias/Assign&quot;\\n  input: &quot;^decoder/attention_wrapper/attention_layer/kernel/Assign&quot;\\n  input: &quot;^decoder/dense/kernel/Assign&quot;\\n  input: &quot;^decoder/dense/bias/Assign&quot;\\n  input: &quot;^beta1_power/Assign&quot;\\n  input: &quot;^beta2_power/Assign&quot;\\n  input: &quot;^Variable/Adam/Assign&quot;\\n  input: &quot;^Variable/Adam_1/Assign&quot;\\n  input: &quot;^bidirectional_rnn/fw/lstm_cell/kernel/Adam/Assign&quot;\\n  input: &quot;^bidirectional_rnn/fw/lstm_cell/kernel/Adam_1/Assign&quot;\\n  input: &quot;^bidirectional_rnn/fw/lstm_cell/bias/Adam/Assign&quot;\\n  input: &quot;^bidirectional_rnn/fw/lstm_cell/bias/Adam_1/Assign&quot;\\n  input: &quot;^memory_layer/kernel/Adam/Assign&quot;\\n  input: &quot;^memory_layer/kernel/Adam_1/Assign&quot;\\n  input: &quot;^decoder/attention_wrapper/lstm_cell/kernel/Adam/Assign&quot;\\n  input: &quot;^decoder/attention_wrapper/lstm_cell/kernel/Adam_1/Assign&quot;\\n  input: &quot;^decoder/attention_wrapper/lstm_cell/bias/Adam/Assign&quot;\\n  input: &quot;^decoder/attention_wrapper/lstm_cell/bias/Adam_1/Assign&quot;\\n  input: &quot;^decoder/attention_wrapper/attention_layer/kernel/Adam/Assign&quot;\\n  input: &quot;^decoder/attention_wrapper/attention_layer/kernel/Adam_1/Assign&quot;\\n  input: &quot;^decoder/dense/kernel/Adam/Assign&quot;\\n  input: &quot;^decoder/dense/kernel/Adam_1/Assign&quot;\\n  input: &quot;^decoder/dense/bias/Adam/Assign&quot;\\n  input: &quot;^decoder/dense/bias/Adam_1/Assign&quot;\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.324218408367&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_graph(tf.get_default_graph().as_graph_def())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
