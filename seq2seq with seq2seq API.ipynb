{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "import helpers #for formatting data into batches and generating random sequence data\n",
    "\n",
    "tf.reset_default_graph() #Clears the default graph stack and resets the global default graph.\n",
    "sess = tf.InteractiveSession() #initializes a tensorflow session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.3.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PAD = 0 # padding\n",
    "EOS = 1 # End of sequence\n",
    "\n",
    "vocab_size = 10 # max length of input sequence\n",
    "input_embedding_size = 20 #character length (vector)\n",
    "\n",
    "encoder_hidden_units = 16 #num neurons\n",
    "decoder_hidden_units = encoder_hidden_units * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#input placehodlers\n",
    "encoder_inputs = tf.placeholder(shape=(None, None), dtype=tf.int32, name='encoder_inputs')\n",
    "#contains the lengths for each of the sequence in the batch, we will pad so all the same\n",
    "#if you don't want to pad, check out dynamic memory networks to input variable length sequences\n",
    "encoder_inputs_length = tf.placeholder(shape=(None,), dtype=tf.int32, name='encoder_inputs_length')\n",
    "decoder_targets = tf.placeholder(shape=(None, None), dtype=tf.int32, name='decoder_targets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embeddings = tf.Variable(tf.random_uniform([vocab_size, input_embedding_size], -1.0, 1.0), dtype=tf.float32)\n",
    "\n",
    "#this thing could get huge in a real world application\n",
    "encoder_inputs_embedded = tf.nn.embedding_lookup(embeddings, encoder_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'embedding_lookup:0' shape=(?, ?, 20) dtype=float32>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_inputs_embedded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder\n",
    "Bidirectional encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.ops.rnn_cell import LSTMCell, LSTMStateTuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_cell =  LSTMCell(encoder_hidden_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "((encoder_fw_outputs,\n",
    "  encoder_bw_outputs),\n",
    " (encoder_fw_final_state,\n",
    "  encoder_bw_final_state)) = (\n",
    "    tf.nn.bidirectional_dynamic_rnn(cell_fw=encoder_cell,\n",
    "                                    cell_bw=encoder_cell,\n",
    "                                    inputs=encoder_inputs_embedded,\n",
    "                                    sequence_length=encoder_inputs_length,\n",
    "                                    dtype=tf.float32, time_major=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'bidirectional_rnn/fw/fw/TensorArrayStack/TensorArrayGatherV3:0' shape=(?, ?, 16) dtype=float32>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_fw_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'ReverseSequence:0' shape=(?, ?, 16) dtype=float32>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_bw_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMStateTuple(c=<tf.Tensor 'bidirectional_rnn/fw/fw/while/Exit_2:0' shape=(?, 16) dtype=float32>, h=<tf.Tensor 'bidirectional_rnn/fw/fw/while/Exit_3:0' shape=(?, 16) dtype=float32>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_fw_final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMStateTuple(c=<tf.Tensor 'bidirectional_rnn/bw/bw/while/Exit_2:0' shape=(?, 16) dtype=float32>, h=<tf.Tensor 'bidirectional_rnn/bw/bw/while/Exit_3:0' shape=(?, 16) dtype=float32>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_bw_final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Concatenates tensors along one dimension.\n",
    "encoder_outputs = tf.concat((encoder_fw_outputs, encoder_bw_outputs), 2)\n",
    "\n",
    "#letters h and c are commonly used to denote \"output value\" and \"cell state\". \n",
    "#http://colah.github.io/posts/2015-08-Understanding-LSTMs/ \n",
    "#Those tensors represent combined internal state of the cell, and should be passed together. \n",
    "\n",
    "encoder_final_state_c = tf.concat(\n",
    "    (encoder_fw_final_state.c, encoder_bw_final_state.c), 1)\n",
    "\n",
    "encoder_final_state_h = tf.concat(\n",
    "    (encoder_fw_final_state.h, encoder_bw_final_state.h), 1)\n",
    "\n",
    "#TF Tuple used by LSTM Cells for state_size, zero_state, and output state.\n",
    "encoder_final_state = LSTMStateTuple(\n",
    "    c=encoder_final_state_c,\n",
    "    h=encoder_final_state_h\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMStateTuple(c=<tf.Tensor 'concat_1:0' shape=(?, 32) dtype=float32>, h=<tf.Tensor 'concat_2:0' shape=(?, 32) dtype=float32>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_final_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoder\n",
    "Common part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_cell = LSTMCell(decoder_hidden_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_max_time, batch_size = tf.unstack(tf.shape(encoder_inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_lengths = encoder_inputs_length + 3\n",
    "# +2 additional steps, +1 leading <EOS> token for decoder inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'embedding_lookup_1:0' shape=(?, ?, 20) dtype=float32>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# +2 additional steps, +1 leading <EOS> token for decoder inputs as for decoder_lengths\n",
    "max_length = encoder_max_time + 3\n",
    "\n",
    "decoder_inputs = tf.ones([max_length, batch_size], dtype=tf.int32)\n",
    "decoder_inputs_embedded = tf.nn.embedding_lookup(embeddings, decoder_inputs)\n",
    "decoder_inputs_embedded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic_rnn decoder\n",
    "For comparison purpose (no attention mechanisms)\n",
    "\n",
    "You can jump direclty to the seq2seq decoder part with running those cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "((decoder_outputs),\n",
    " (decoder_state)) = (\n",
    "    tf.nn.dynamic_rnn(cell=decoder_cell,\n",
    "                      inputs=decoder_inputs_embedded,\n",
    "                      sequence_length=decoder_lengths,\n",
    "                      initial_state=encoder_final_state,\n",
    "                      dtype=tf.float32, time_major=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "decoder_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#manually specifying since we are going to implement attention details for the decoder in a sec\n",
    "#weights\n",
    "W = tf.Variable(tf.random_uniform([decoder_hidden_units, vocab_size], -1, 1), dtype=tf.float32)\n",
    "#bias\n",
    "b = tf.Variable(tf.zeros([vocab_size]), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#to convert output to human readable prediction\n",
    "#we will reshape output tensor\n",
    "\n",
    "#Unpacks the given dimension of a rank-R tensor into rank-(R-1) tensors.\n",
    "#reduces dimensionality\n",
    "decoder_max_steps, decoder_batch_size, decoder_dim = tf.unstack(tf.shape(decoder_outputs))\n",
    "#flettened output tensor\n",
    "decoder_outputs_flat = tf.reshape(decoder_outputs, (-1, decoder_dim))\n",
    "#pass flattened tensor through decoder\n",
    "decoder_logits_flat = tf.add(tf.matmul(decoder_outputs_flat, W), b)\n",
    "#prediction vals\n",
    "decoder_logits = tf.reshape(decoder_logits_flat, (decoder_max_steps, decoder_batch_size, vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "decoder_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#final prediction\n",
    "decoder_prediction = tf.argmax(decoder_logits, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seq2seq decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.layers import core as layers_core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# attention_states: [batch_size, max_time, num_units]\n",
    "attention_states = tf.transpose(encoder_outputs, [1, 0, 2])\n",
    "\n",
    "# Create an attention mechanism\n",
    "attention_mechanism = tf.contrib.seq2seq.LuongAttention(\n",
    "    num_units=decoder_hidden_units, \n",
    "    memory=attention_states,\n",
    "    #memory_sequence_length=None # default value\n",
    ")\n",
    "\n",
    "decoder_cell = tf.contrib.seq2seq.AttentionWrapper(\n",
    "    cell=decoder_cell, \n",
    "    attention_mechanism=attention_mechanism,\n",
    "    attention_layer_size=decoder_hidden_units)\n",
    "\n",
    "attention_zero = decoder_cell.zero_state(batch_size=batch_size, dtype=tf.float32)\n",
    "encoder_final_state = attention_zero.clone(cell_state=encoder_final_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "projection_layer = layers_core.Dense(vocab_size, use_bias=True)\n",
    "\n",
    "# Helper\n",
    "helper = tf.contrib.seq2seq.TrainingHelper(\n",
    "    inputs=decoder_inputs_embedded, \n",
    "    sequence_length=decoder_lengths, \n",
    "    time_major=True)\n",
    "\n",
    "# Decoder\n",
    "decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "    cell=decoder_cell, \n",
    "    helper=helper, \n",
    "    initial_state=encoder_final_state,\n",
    "    output_layer=projection_layer)\n",
    "\n",
    "# Dynamic decoding\n",
    "(decoder_outputs, final_state, final_sequence_lengths) = tf.contrib.seq2seq.dynamic_decode(\n",
    "    decoder,\n",
    "    output_time_major=True\n",
    ")\n",
    "decoder_logits = decoder_outputs.rnn_output\n",
    "decoder_prediction = decoder_outputs.sample_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BasicDecoderOutput(rnn_output=<tf.Tensor 'decoder/TensorArrayStack/TensorArrayGatherV3:0' shape=(?, ?, 10) dtype=float32>, sample_id=<tf.Tensor 'decoder/TensorArrayStack_1/TensorArrayGatherV3:0' shape=(?, ?) dtype=int32>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#cross entropy loss\n",
    "#one hot encode the target values so we don't rank just differentiate\n",
    "stepwise_cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "    labels=tf.one_hot(decoder_targets, depth=vocab_size, dtype=tf.float32),\n",
    "    logits=decoder_logits,\n",
    ")\n",
    "\n",
    "#loss function\n",
    "loss = tf.reduce_mean(stepwise_cross_entropy)\n",
    "#train it \n",
    "train_op = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load toy dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head of the batch:\n",
      "[7, 4, 3]\n",
      "[9, 3, 8, 7, 2]\n",
      "[7, 4, 7, 9, 8, 9, 2, 4]\n",
      "[6, 3, 5, 9, 5, 5]\n",
      "[4, 3, 4]\n",
      "[8, 3, 6]\n",
      "[6, 3, 9, 2, 2, 9, 3, 3]\n",
      "[7, 2, 2, 2, 8, 2, 4]\n",
      "[6, 2, 6, 8, 6, 4, 3, 6]\n",
      "[2, 9, 3, 9, 5, 4]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "\n",
    "batches = helpers.random_sequences(length_from=3, length_to=8,\n",
    "                                   vocab_lower=2, vocab_upper=10,\n",
    "                                   batch_size=batch_size)\n",
    "\n",
    "print('head of the batch:')\n",
    "for seq in next(batches)[:10]:\n",
    "    print(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def next_feed():\n",
    "    batch = next(batches)\n",
    "    encoder_inputs_, encoder_input_lengths_ = helpers.batch(batch)\n",
    "    decoder_targets_, _ = helpers.batch(\n",
    "        [(sequence) + [EOS] + [PAD] * 2 for sequence in batch]\n",
    "    )\n",
    "    return {\n",
    "        encoder_inputs: encoder_inputs_,\n",
    "        encoder_inputs_length: encoder_input_lengths_,\n",
    "        decoder_targets: decoder_targets_,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_track = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_batches = 3001\n",
    "batches_in_epoch = 1000\n",
    "\n",
    "def run_model(train=True):\n",
    "    try:\n",
    "        for batch in range(max_batches):\n",
    "            fd = next_feed()\n",
    "            if train:\n",
    "                _, l = sess.run([train_op, loss], fd)\n",
    "                loss_track.append(l)\n",
    "\n",
    "            if batch == 0 or batch % batches_in_epoch == 0:\n",
    "                print('batch {}'.format(batch))\n",
    "                print('  minibatch loss: {}'.format(sess.run(loss, fd)))\n",
    "                predict_ = sess.run(decoder_prediction, fd)\n",
    "                for i, (inp, pred) in enumerate(zip(fd[encoder_inputs].T, predict_.T)):\n",
    "                    print('  sample {}:'.format(i + 1))\n",
    "                    print('    input     > {}'.format(inp))\n",
    "                    print('    predicted > {}'.format(pred))\n",
    "                    if i >= 2:\n",
    "                        break\n",
    "                print\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print('training interrupted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model\n",
    "Possible to skip those cells and load a model checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "run_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Don't forget that the '1' at the end of the sequences is the EOS tag, not a predicted output!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.0009 after 384128 examples (batch_size=128)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEACAYAAABfxaZOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niTj0zcxK5P8DpNAgaO/UA9kAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12a3d19d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_track)\n",
    "print('loss {:.4f} after {} examples (batch_size={})'.format(loss_track[-1], len(loss_track)*batch_size, batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model (create a checkpoint under the 'checkpoints' directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "saver.save(sess, \"checkpoints/seq2seq.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load a checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, \"checkpoints/seq2seq.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0\n",
      "  minibatch loss: 0.000751271436457\n",
      "  sample 1:\n",
      "    input     > [8 9 9 0 0 0 0 0]\n",
      "    predicted > [8 9 9 1 0 0 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [8 2 2 9 4 2 4 0]\n",
      "    predicted > [8 2 2 9 4 2 4 1 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [8 6 2 7 3 9 0 0]\n",
      "    predicted > [8 6 2 7 3 9 1 0 0 0 0]\n",
      "\n",
      "batch 1000\n",
      "  minibatch loss: 0.000858516781591\n",
      "  sample 1:\n",
      "    input     > [9 5 9 8 0 0 0 0]\n",
      "    predicted > [9 5 9 8 1 0 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [9 2 9 8 9 2 3 0]\n",
      "    predicted > [9 2 9 8 9 2 3 1 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [2 3 7 4 5 0 0 0]\n",
      "    predicted > [2 3 7 4 5 1 0 0 0 0 0]\n",
      "\n",
      "batch 2000\n",
      "  minibatch loss: 0.000870944582857\n",
      "  sample 1:\n",
      "    input     > [9 3 7 7 2 3 9 7]\n",
      "    predicted > [9 3 7 7 2 3 9 7 1 0 0]\n",
      "  sample 2:\n",
      "    input     > [6 6 8 4 0 0 0 0]\n",
      "    predicted > [6 6 8 4 1 0 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [7 5 8 4 6 8 0 0]\n",
      "    predicted > [7 5 8 4 6 8 1 0 0 0 0]\n",
      "\n",
      "batch 3000\n",
      "  minibatch loss: 0.00086215644842\n",
      "  sample 1:\n",
      "    input     > [8 7 2 4 9 6 5 0]\n",
      "    predicted > [8 7 2 4 9 6 5 1 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [4 2 2 9 6 4 4 0]\n",
      "    predicted > [4 2 2 9 6 4 4 1 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [8 8 4 8 0 0 0 0]\n",
      "    predicted > [8 8 4 8 1 0 0 0 0 0 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check how the model perform on a toy dataset\n",
    "run_model(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize graph\n",
    "\n",
    "Copying from https://stackoverflow.com/questions/38189119/simple-way-to-visualize-a-tensorflow-graph-in-jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "def strip_consts(graph_def, max_const_size=32):\n",
    "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
    "    strip_def = tf.GraphDef()\n",
    "    for n0 in graph_def.node:\n",
    "        n = strip_def.node.add() \n",
    "        n.MergeFrom(n0)\n",
    "        if n.op == 'Const':\n",
    "            tensor = n.attr['value'].tensor\n",
    "            size = len(tensor.tensor_content)\n",
    "            if size > max_const_size:\n",
    "                tensor.tensor_content = \"<stripped %d bytes>\"%size\n",
    "    return strip_def\n",
    "\n",
    "def show_graph(graph_def, max_const_size=32):\n",
    "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
    "    if hasattr(graph_def, 'as_graph_def'):\n",
    "        graph_def = graph_def.as_graph_def()\n",
    "    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
    "    code = \"\"\"\n",
    "        <script>\n",
    "          function load() {{\n",
    "            document.getElementById(\"{id}\").pbtxt = {data};\n",
    "          }}\n",
    "        </script>\n",
    "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
    "        <div style=\"height:600px\">\n",
    "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
    "        </div>\n",
    "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
    "\n",
    "    iframe = \"\"\"\n",
    "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n",
    "    \"\"\".format(code.replace('\"', '&quot;'))\n",
    "    display(HTML(iframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.324218408367&quot;).pbtxt = 'node {\\n  name: &quot;encoder_inputs&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n        dim {\\n          size: -1\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;encoder_inputs_length&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder_targets&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n        dim {\\n          size: -1\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\n\\\\000\\\\000\\\\000\\\\024\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;random_uniform/max&quot;\\n  input: &quot;random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;random_uniform/RandomUniform&quot;\\n  input: &quot;random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;random_uniform/mul&quot;\\n  input: &quot;random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Variable&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 10\\n        }\\n        dim {\\n          size: 20\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Variable/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Variable&quot;\\n  input: &quot;random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Variable/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Variable&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;embedding_lookup&quot;\\n  op: &quot;Gather&quot;\\n  input: &quot;Variable/read&quot;\\n  input: &quot;encoder_inputs&quot;\\n  attr {\\n    key: &quot;Tindices&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tparams&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_indices&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/sequence_length&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;encoder_inputs_length&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;embedding_lookup&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/strided_slice/stack&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/strided_slice/stack_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/strided_slice/stack_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/strided_slice&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/Shape&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/strided_slice/stack&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/strided_slice/stack_1&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/strided_slice/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/ExpandDims/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/ExpandDims&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/strided_slice&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/ExpandDims/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 16\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/ExpandDims&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/Const&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/ExpandDims_1/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/ExpandDims_1&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/strided_slice&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/ExpandDims_1/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 16\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/zeros/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/zeros&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/concat&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/zeros/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/ExpandDims_2/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/ExpandDims_2&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/strided_slice&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/ExpandDims_2/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/Const_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 16\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/concat_1/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/concat_1&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/ExpandDims_2&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/Const_2&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/concat_1/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/ExpandDims_3/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/ExpandDims_3&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/strided_slice&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/ExpandDims_3/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/Const_3&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 16\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/zeros_1/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/zeros_1&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/concat_1&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/zeros_1/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/fw/sequence_length&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/stack&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/strided_slice&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/Equal&quot;\\n  op: &quot;Equal&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/Shape_1&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/stack&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/All&quot;\\n  op: &quot;All&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/Equal&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/Const&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/Assert/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;Expected shape for Tensor bidirectional_rnn/fw/sequence_length:0 is &quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/Assert/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot; but saw shape: &quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/Assert/Assert/data_0&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;Expected shape for Tensor bidirectional_rnn/fw/sequence_length:0 is &quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/Assert/Assert/data_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot; but saw shape: &quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/Assert/Assert&quot;\\n  op: &quot;Assert&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/All&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/Assert/Assert/data_0&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/stack&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/Assert/Assert/data_2&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      list {\\n        type: DT_STRING\\n        type: DT_INT32\\n        type: DT_STRING\\n        type: DT_INT32\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;summarize&quot;\\n    value {\\n      i: 3\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/CheckSeqLen&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;bidirectional_rnn/fw/sequence_length&quot;\\n  input: &quot;^bidirectional_rnn/fw/fw/Assert/Assert&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/Shape_2&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;embedding_lookup&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/strided_slice_1/stack&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/strided_slice_1/stack_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/strided_slice_1/stack_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/strided_slice_1&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/Shape_2&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/strided_slice_1/stack&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/strided_slice_1/stack_1&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/strided_slice_1/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/Shape_3&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;embedding_lookup&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/strided_slice_2/stack&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/strided_slice_2/stack_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/strided_slice_2/stack_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/strided_slice_2&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/Shape_3&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/strided_slice_2/stack&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/strided_slice_2/stack_1&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/strided_slice_2/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/ExpandDims/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/ExpandDims&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/strided_slice_2&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/ExpandDims/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 16\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/ExpandDims&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/Const_1&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/zeros/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/zeros&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/concat&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/zeros/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/Const_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/Min&quot;\\n  op: &quot;Min&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/CheckSeqLen&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/Const_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/Const_3&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/Max&quot;\\n  op: &quot;Max&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/CheckSeqLen&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/Const_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/time&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/TensorArray&quot;\\n  op: &quot;TensorArrayV3&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/strided_slice_1&quot;\\n  attr {\\n    key: &quot;clear_after_read&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;dynamic_size&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;element_shape&quot;\\n    value {\\n      shape {\\n        unknown_rank: true\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;tensor_array_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/dynamic_rnn/output_0&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/TensorArray_1&quot;\\n  op: &quot;TensorArrayV3&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/strided_slice_1&quot;\\n  attr {\\n    key: &quot;clear_after_read&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;dynamic_size&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;element_shape&quot;\\n    value {\\n      shape {\\n        unknown_rank: true\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;tensor_array_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/dynamic_rnn/input_0&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/TensorArrayUnstack/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;embedding_lookup&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/TensorArrayUnstack/strided_slice/stack&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/TensorArrayUnstack/strided_slice/stack_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/TensorArrayUnstack/strided_slice/stack_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/TensorArrayUnstack/strided_slice&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArrayUnstack/Shape&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArrayUnstack/strided_slice/stack&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArrayUnstack/strided_slice/stack_1&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArrayUnstack/strided_slice/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/TensorArrayUnstack/range/start&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/TensorArrayUnstack/range/delta&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/TensorArrayUnstack/range&quot;\\n  op: &quot;Range&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArrayUnstack/range/start&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArrayUnstack/strided_slice&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArrayUnstack/range/delta&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3&quot;\\n  op: &quot;TensorArrayScatterV3&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArray_1&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArrayUnstack/range&quot;\\n  input: &quot;embedding_lookup&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArray_1:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/time&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/Enter_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArray:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/Enter_2&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/Enter_3&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/zeros_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/Merge&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Enter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/Merge_1&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Enter_1&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/NextIteration_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/Merge_2&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Enter_2&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/NextIteration_2&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/Merge_3&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Enter_3&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/NextIteration_3&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/Less/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/strided_slice_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/Less&quot;\\n  op: &quot;Less&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Merge&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Less/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/LoopCond&quot;\\n  op: &quot;LoopCond&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Less&quot;\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Merge&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/LoopCond&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/Merge&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/Switch_1&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Merge_1&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/LoopCond&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/Merge_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/Switch_2&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Merge_2&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/LoopCond&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/Merge_2&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/Switch_3&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Merge_3&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/LoopCond&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/Merge_3&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/Identity&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Switch:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/Identity_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Switch_1:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/Identity_2&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Switch_2:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/Identity_3&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Switch_3:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArray_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/TensorArrayReadV3&quot;\\n  op: &quot;TensorArrayReadV3&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Identity&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;$\\\\000\\\\000\\\\000@\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.244948968291\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.244948968291\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform/max&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform/mul&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/kernel&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 36\\n        }\\n        dim {\\n          size: 64\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/kernel&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/kernel/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/kernel&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^bidirectional_rnn/fw/fw/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/TensorArrayReadV3&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Identity_3&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/bias/Initializer/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 64\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/bias&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 64\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/bias&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/bias/Initializer/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd&quot;\\n  op: &quot;BiasAdd&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^bidirectional_rnn/fw/fw/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 4\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split/split_dim&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^bidirectional_rnn/fw/fw/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split&quot;\\n  op: &quot;Split&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split/split_dim&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;num_split&quot;\\n    value {\\n      i: 4\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add/y&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^bidirectional_rnn/fw/fw/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split:2&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid&quot;\\n  op: &quot;Sigmoid&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Identity_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid_1&quot;\\n  op: &quot;Sigmoid&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Tanh&quot;\\n  op: &quot;Tanh&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid_1&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Tanh&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid_2&quot;\\n  op: &quot;Sigmoid&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split:3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Tanh_1&quot;\\n  op: &quot;Tanh&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid_2&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Tanh_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/GreaterEqual/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/CheckSeqLen&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/GreaterEqual&quot;\\n  op: &quot;GreaterEqual&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Identity&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/GreaterEqual/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/Select/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/Select&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/GreaterEqual&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Select/Enter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/GreaterEqual_1&quot;\\n  op: &quot;GreaterEqual&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Identity&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/GreaterEqual/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/Select_1&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/GreaterEqual_1&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Identity_2&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/GreaterEqual_2&quot;\\n  op: &quot;GreaterEqual&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Identity&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/GreaterEqual/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/Select_2&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/GreaterEqual_2&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Identity_3&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArray&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3&quot;\\n  op: &quot;TensorArrayWriteV3&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3/Enter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Identity&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Select&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Identity_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/add/y&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^bidirectional_rnn/fw/fw/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Identity&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/add/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/NextIteration_1&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/NextIteration_2&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Select_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/NextIteration_3&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Select_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/Exit&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/Exit_1&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Switch_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/Exit_2&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Switch_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/Exit_3&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Switch_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/TensorArrayStack/TensorArraySizeV3&quot;\\n  op: &quot;TensorArraySizeV3&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArray&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Exit_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/TensorArray&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/TensorArrayStack/range/start&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/TensorArray&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/TensorArrayStack/range/delta&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/TensorArray&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/TensorArrayStack/range&quot;\\n  op: &quot;Range&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArrayStack/range/start&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArrayStack/TensorArraySizeV3&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArrayStack/range/delta&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/TensorArray&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/TensorArrayStack/TensorArrayGatherV3&quot;\\n  op: &quot;TensorArrayGatherV3&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArray&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArrayStack/range&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Exit_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/TensorArray&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;element_shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n        dim {\\n          size: 16\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/Const_4&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 16\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/ReverseSequence&quot;\\n  op: &quot;ReverseSequence&quot;\\n  input: &quot;embedding_lookup&quot;\\n  input: &quot;encoder_inputs_length&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tlen&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;batch_dim&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;seq_dim&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/sequence_length&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;encoder_inputs_length&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/bw/ReverseSequence&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/strided_slice/stack&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/strided_slice/stack_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/strided_slice/stack_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/strided_slice&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/Shape&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/strided_slice/stack&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/strided_slice/stack_1&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/strided_slice/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/ExpandDims/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/ExpandDims&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/strided_slice&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/ExpandDims/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 16\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/ExpandDims&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/Const&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/ExpandDims_1/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/ExpandDims_1&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/strided_slice&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/ExpandDims_1/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 16\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/zeros/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/zeros&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/concat&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/zeros/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/ExpandDims_2/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/ExpandDims_2&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/strided_slice&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/ExpandDims_2/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/Const_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 16\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/concat_1/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/concat_1&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/ExpandDims_2&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/Const_2&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/concat_1/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/ExpandDims_3/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/ExpandDims_3&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/strided_slice&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/ExpandDims_3/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/Const_3&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 16\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/zeros_1/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/zeros_1&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/concat_1&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/zeros_1/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/bw/sequence_length&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/stack&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/strided_slice&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/Equal&quot;\\n  op: &quot;Equal&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/Shape_1&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/stack&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/All&quot;\\n  op: &quot;All&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/Equal&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/Const&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/Assert/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;Expected shape for Tensor bidirectional_rnn/bw/sequence_length:0 is &quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/Assert/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot; but saw shape: &quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/Assert/Assert/data_0&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;Expected shape for Tensor bidirectional_rnn/bw/sequence_length:0 is &quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/Assert/Assert/data_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot; but saw shape: &quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/Assert/Assert&quot;\\n  op: &quot;Assert&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/All&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/Assert/Assert/data_0&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/stack&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/Assert/Assert/data_2&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      list {\\n        type: DT_STRING\\n        type: DT_INT32\\n        type: DT_STRING\\n        type: DT_INT32\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;summarize&quot;\\n    value {\\n      i: 3\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/CheckSeqLen&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;bidirectional_rnn/bw/sequence_length&quot;\\n  input: &quot;^bidirectional_rnn/bw/bw/Assert/Assert&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/Shape_2&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/bw/ReverseSequence&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/strided_slice_1/stack&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/strided_slice_1/stack_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/strided_slice_1/stack_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/strided_slice_1&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/Shape_2&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/strided_slice_1/stack&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/strided_slice_1/stack_1&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/strided_slice_1/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/Shape_3&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/bw/ReverseSequence&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/strided_slice_2/stack&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/strided_slice_2/stack_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/strided_slice_2/stack_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/strided_slice_2&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/Shape_3&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/strided_slice_2/stack&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/strided_slice_2/stack_1&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/strided_slice_2/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/ExpandDims/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/ExpandDims&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/strided_slice_2&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/ExpandDims/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 16\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/ExpandDims&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/Const_1&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/zeros/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/zeros&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/concat&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/zeros/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/Const_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/Min&quot;\\n  op: &quot;Min&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/CheckSeqLen&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/Const_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/Const_3&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/Max&quot;\\n  op: &quot;Max&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/CheckSeqLen&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/Const_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/time&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/TensorArray&quot;\\n  op: &quot;TensorArrayV3&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/strided_slice_1&quot;\\n  attr {\\n    key: &quot;clear_after_read&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;dynamic_size&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;element_shape&quot;\\n    value {\\n      shape {\\n        unknown_rank: true\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;tensor_array_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/dynamic_rnn/output_0&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/TensorArray_1&quot;\\n  op: &quot;TensorArrayV3&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/strided_slice_1&quot;\\n  attr {\\n    key: &quot;clear_after_read&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;dynamic_size&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;element_shape&quot;\\n    value {\\n      shape {\\n        unknown_rank: true\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;tensor_array_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/dynamic_rnn/input_0&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/TensorArrayUnstack/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/bw/ReverseSequence&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/TensorArrayUnstack/strided_slice/stack&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/TensorArrayUnstack/strided_slice/stack_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/TensorArrayUnstack/strided_slice/stack_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/TensorArrayUnstack/strided_slice&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArrayUnstack/Shape&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArrayUnstack/strided_slice/stack&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArrayUnstack/strided_slice/stack_1&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArrayUnstack/strided_slice/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/TensorArrayUnstack/range/start&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/TensorArrayUnstack/range/delta&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/TensorArrayUnstack/range&quot;\\n  op: &quot;Range&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArrayUnstack/range/start&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArrayUnstack/strided_slice&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArrayUnstack/range/delta&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3&quot;\\n  op: &quot;TensorArrayScatterV3&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArray_1&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArrayUnstack/range&quot;\\n  input: &quot;bidirectional_rnn/bw/ReverseSequence&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArray_1:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/ReverseSequence&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/time&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/Enter_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArray:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/Enter_2&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/Enter_3&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/zeros_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/Merge&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Enter&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/Merge_1&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Enter_1&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/NextIteration_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/Merge_2&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Enter_2&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/NextIteration_2&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/Merge_3&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Enter_3&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/NextIteration_3&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/Less/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/strided_slice_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/Less&quot;\\n  op: &quot;Less&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Merge&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Less/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/LoopCond&quot;\\n  op: &quot;LoopCond&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Less&quot;\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Merge&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/LoopCond&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/Merge&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/Switch_1&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Merge_1&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/LoopCond&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/Merge_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/Switch_2&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Merge_2&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/LoopCond&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/Merge_2&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/Switch_3&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Merge_3&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/LoopCond&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/Merge_3&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/Identity&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Switch:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/Identity_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Switch_1:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/Identity_2&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Switch_2:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/Identity_3&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Switch_3:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArray_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/TensorArrayReadV3&quot;\\n  op: &quot;TensorArrayReadV3&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Identity&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^bidirectional_rnn/bw/bw/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/TensorArrayReadV3&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Identity_3&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd&quot;\\n  op: &quot;BiasAdd&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^bidirectional_rnn/bw/bw/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 4\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split/split_dim&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^bidirectional_rnn/bw/bw/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split&quot;\\n  op: &quot;Split&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split/split_dim&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;num_split&quot;\\n    value {\\n      i: 4\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add/y&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^bidirectional_rnn/bw/bw/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split:2&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid&quot;\\n  op: &quot;Sigmoid&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Identity_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid_1&quot;\\n  op: &quot;Sigmoid&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Tanh&quot;\\n  op: &quot;Tanh&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid_1&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Tanh&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid_2&quot;\\n  op: &quot;Sigmoid&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split:3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Tanh_1&quot;\\n  op: &quot;Tanh&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid_2&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Tanh_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/GreaterEqual/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/CheckSeqLen&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/GreaterEqual&quot;\\n  op: &quot;GreaterEqual&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Identity&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/GreaterEqual/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/Select/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/Select&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/GreaterEqual&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Select/Enter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/GreaterEqual_1&quot;\\n  op: &quot;GreaterEqual&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Identity&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/GreaterEqual/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/Select_1&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/GreaterEqual_1&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Identity_2&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/GreaterEqual_2&quot;\\n  op: &quot;GreaterEqual&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Identity&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/GreaterEqual/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/Select_2&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/GreaterEqual_2&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Identity_3&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArray&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3&quot;\\n  op: &quot;TensorArrayWriteV3&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3/Enter&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Identity&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Select&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Identity_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/add/y&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^bidirectional_rnn/bw/bw/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Identity&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/add/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/NextIteration_1&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/NextIteration_2&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Select_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/NextIteration_3&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Select_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/Exit&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/Exit_1&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Switch_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/Exit_2&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Switch_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/Exit_3&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Switch_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/TensorArrayStack/TensorArraySizeV3&quot;\\n  op: &quot;TensorArraySizeV3&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArray&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Exit_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/TensorArray&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/TensorArrayStack/range/start&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/TensorArray&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/TensorArrayStack/range/delta&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/TensorArray&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/TensorArrayStack/range&quot;\\n  op: &quot;Range&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArrayStack/range/start&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArrayStack/TensorArraySizeV3&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArrayStack/range/delta&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/TensorArray&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/TensorArrayStack/TensorArrayGatherV3&quot;\\n  op: &quot;TensorArrayGatherV3&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArray&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArrayStack/range&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Exit_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/TensorArray&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;element_shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n        dim {\\n          size: 16\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/Const_4&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 16\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;ReverseSequence&quot;\\n  op: &quot;ReverseSequence&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArrayStack/TensorArrayGatherV3&quot;\\n  input: &quot;encoder_inputs_length&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tlen&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;batch_dim&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;seq_dim&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;concat/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArrayStack/TensorArrayGatherV3&quot;\\n  input: &quot;ReverseSequence&quot;\\n  input: &quot;concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;concat_1/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;concat_1&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Exit_2&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Exit_2&quot;\\n  input: &quot;concat_1/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;concat_2/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;concat_2&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Exit_3&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Exit_3&quot;\\n  input: &quot;concat_2/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;encoder_inputs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;unstack&quot;\\n  op: &quot;Unpack&quot;\\n  input: &quot;Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;num&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;add/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 3\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;encoder_inputs_length&quot;\\n  input: &quot;add/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;add_1/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 3\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;add_1&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;unstack&quot;\\n  input: &quot;add_1/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;ones/shape&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;add_1&quot;\\n  input: &quot;unstack:1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;ones/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;ones&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;ones/shape&quot;\\n  input: &quot;ones/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;embedding_lookup_1&quot;\\n  op: &quot;Gather&quot;\\n  input: &quot;Variable/read&quot;\\n  input: &quot;ones&quot;\\n  attr {\\n    key: &quot;Tindices&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tparams&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_indices&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;transpose/perm&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 3\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;transpose&quot;\\n  op: &quot;Transpose&quot;\\n  input: &quot;concat&quot;\\n  input: &quot;transpose/perm&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tperm&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/ones&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;transpose&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/strided_slice/stack&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/strided_slice/stack_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/strided_slice/stack_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/strided_slice&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;LuongAttention/Shape&quot;\\n  input: &quot;LuongAttention/strided_slice/stack&quot;\\n  input: &quot;LuongAttention/strided_slice/stack_1&quot;\\n  input: &quot;LuongAttention/strided_slice/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;memory_layer/kernel/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@memory_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot; \\\\000\\\\000\\\\000 \\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;memory_layer/kernel/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@memory_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.306186228991\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;memory_layer/kernel/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@memory_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.306186228991\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;memory_layer/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;memory_layer/kernel/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@memory_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;memory_layer/kernel/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;memory_layer/kernel/Initializer/random_uniform/max&quot;\\n  input: &quot;memory_layer/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@memory_layer/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;memory_layer/kernel/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;memory_layer/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;memory_layer/kernel/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@memory_layer/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;memory_layer/kernel/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;memory_layer/kernel/Initializer/random_uniform/mul&quot;\\n  input: &quot;memory_layer/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@memory_layer/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;memory_layer/kernel&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@memory_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 32\\n        }\\n        dim {\\n          size: 32\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;memory_layer/kernel/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;memory_layer/kernel&quot;\\n  input: &quot;memory_layer/kernel/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@memory_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;memory_layer/kernel/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;memory_layer/kernel&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@memory_layer/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;transpose&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/Rank&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 3\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/axes&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/GreaterEqual/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/GreaterEqual&quot;\\n  op: &quot;GreaterEqual&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/axes&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/GreaterEqual/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/GreaterEqual&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/Cast&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/axes&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/Less/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/Less&quot;\\n  op: &quot;Less&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/axes&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/Less/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/Cast_1&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/Less&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/axes&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/Rank&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/Cast_1&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/add_1&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/mul&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/mul_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/range/start&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/range/delta&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/range&quot;\\n  op: &quot;Range&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/range/start&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/Rank&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/range/delta&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/ListDiff&quot;\\n  op: &quot;ListDiff&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/range&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;out_idx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/Gather&quot;\\n  op: &quot;Gather&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/Shape&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/ListDiff&quot;\\n  attr {\\n    key: &quot;Tindices&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tparams&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_indices&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/Gather_1&quot;\\n  op: &quot;Gather&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/Shape&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/add_1&quot;\\n  attr {\\n    key: &quot;Tindices&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tparams&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_indices&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/Prod&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/Gather&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/Prod_1&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/Gather_1&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/Gather_1&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/Gather&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/concat_1/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/concat_1&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/ListDiff&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/add_1&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/concat_1/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/stack&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/Prod&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/Prod_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/transpose&quot;\\n  op: &quot;Transpose&quot;\\n  input: &quot;transpose&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/concat_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tperm&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/transpose&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/stack&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/transpose_1/perm&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/transpose_1&quot;\\n  op: &quot;Transpose&quot;\\n  input: &quot;memory_layer/kernel/read&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/transpose_1/perm&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tperm&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/Reshape_1/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot; \\\\000\\\\000\\\\000 \\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/transpose_1&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/Reshape_1/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/Reshape&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/Reshape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/Const_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 32\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/concat_2/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/concat_2&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/Gather&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/Const_2&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/concat_2/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/MatMul&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/concat_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/strided_slice_1/stack&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/strided_slice_1/stack_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/strided_slice_1/stack_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/strided_slice_1&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;LuongAttention/Shape_1&quot;\\n  input: &quot;LuongAttention/strided_slice_1/stack&quot;\\n  input: &quot;LuongAttention/strided_slice_1/stack_1&quot;\\n  input: &quot;LuongAttention/strided_slice_1/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/Shape_2&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/strided_slice_2/stack&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/strided_slice_2/stack_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/strided_slice_2/stack_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/strided_slice_2&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;LuongAttention/Shape_2&quot;\\n  input: &quot;LuongAttention/strided_slice_2/stack&quot;\\n  input: &quot;LuongAttention/strided_slice_2/stack_1&quot;\\n  input: &quot;LuongAttention/strided_slice_2/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/LSTMCellZeroState/ExpandDims/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/LSTMCellZeroState/ExpandDims&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;unstack:1&quot;\\n  input: &quot;AttentionWrapperZeroState/LSTMCellZeroState/ExpandDims/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/LSTMCellZeroState/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 32\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/LSTMCellZeroState/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/LSTMCellZeroState/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;AttentionWrapperZeroState/LSTMCellZeroState/ExpandDims&quot;\\n  input: &quot;AttentionWrapperZeroState/LSTMCellZeroState/Const&quot;\\n  input: &quot;AttentionWrapperZeroState/LSTMCellZeroState/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/LSTMCellZeroState/ExpandDims_1/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/LSTMCellZeroState/ExpandDims_1&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;unstack:1&quot;\\n  input: &quot;AttentionWrapperZeroState/LSTMCellZeroState/ExpandDims_1/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/LSTMCellZeroState/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 32\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/LSTMCellZeroState/zeros/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/LSTMCellZeroState/zeros&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;AttentionWrapperZeroState/LSTMCellZeroState/concat&quot;\\n  input: &quot;AttentionWrapperZeroState/LSTMCellZeroState/zeros/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/LSTMCellZeroState/ExpandDims_2/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/LSTMCellZeroState/ExpandDims_2&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;unstack:1&quot;\\n  input: &quot;AttentionWrapperZeroState/LSTMCellZeroState/ExpandDims_2/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/LSTMCellZeroState/Const_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 32\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/LSTMCellZeroState/concat_1/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/LSTMCellZeroState/concat_1&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;AttentionWrapperZeroState/LSTMCellZeroState/ExpandDims_2&quot;\\n  input: &quot;AttentionWrapperZeroState/LSTMCellZeroState/Const_2&quot;\\n  input: &quot;AttentionWrapperZeroState/LSTMCellZeroState/concat_1/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/LSTMCellZeroState/ExpandDims_3/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/LSTMCellZeroState/ExpandDims_3&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;unstack:1&quot;\\n  input: &quot;AttentionWrapperZeroState/LSTMCellZeroState/ExpandDims_3/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/LSTMCellZeroState/Const_3&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 32\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/LSTMCellZeroState/zeros_1/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/LSTMCellZeroState/zeros_1&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;AttentionWrapperZeroState/LSTMCellZeroState/concat_1&quot;\\n  input: &quot;AttentionWrapperZeroState/LSTMCellZeroState/zeros_1/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/assert_equal/Equal&quot;\\n  op: &quot;Equal&quot;\\n  input: &quot;unstack:1&quot;\\n  input: &quot;LuongAttention/strided_slice_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/assert_equal/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/assert_equal/All&quot;\\n  op: &quot;All&quot;\\n  input: &quot;AttentionWrapperZeroState/assert_equal/Equal&quot;\\n  input: &quot;AttentionWrapperZeroState/assert_equal/Const&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/assert_equal/Assert/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;When calling zero_state of AttentionWrapper attention_wrapper: Non-matching batch sizes between the memory (encoder output) and the requested batch size.  Are you using the BeamSearchDecoder?  If so, make sure your encoder output has been tiled to beam_width via tf.contrib.seq2seq.tile_batch, and the batch_size= argument passed to zero_state is batch_size * beam_width.&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/assert_equal/Assert/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;Condition x == y did not hold element-wise:&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/assert_equal/Assert/Const_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;x (unstack:1) = &quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/assert_equal/Assert/Const_3&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;y (LuongAttention/strided_slice_1:0) = &quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/assert_equal/Assert/Assert/data_0&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;When calling zero_state of AttentionWrapper attention_wrapper: Non-matching batch sizes between the memory (encoder output) and the requested batch size.  Are you using the BeamSearchDecoder?  If so, make sure your encoder output has been tiled to beam_width via tf.contrib.seq2seq.tile_batch, and the batch_size= argument passed to zero_state is batch_size * beam_width.&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/assert_equal/Assert/Assert/data_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;Condition x == y did not hold element-wise:&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/assert_equal/Assert/Assert/data_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;x (unstack:1) = &quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/assert_equal/Assert/Assert/data_4&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;y (LuongAttention/strided_slice_1:0) = &quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/assert_equal/Assert/Assert&quot;\\n  op: &quot;Assert&quot;\\n  input: &quot;AttentionWrapperZeroState/assert_equal/All&quot;\\n  input: &quot;AttentionWrapperZeroState/assert_equal/Assert/Assert/data_0&quot;\\n  input: &quot;AttentionWrapperZeroState/assert_equal/Assert/Assert/data_1&quot;\\n  input: &quot;AttentionWrapperZeroState/assert_equal/Assert/Assert/data_2&quot;\\n  input: &quot;unstack:1&quot;\\n  input: &quot;AttentionWrapperZeroState/assert_equal/Assert/Assert/data_4&quot;\\n  input: &quot;LuongAttention/strided_slice_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      list {\\n        type: DT_STRING\\n        type: DT_STRING\\n        type: DT_STRING\\n        type: DT_INT32\\n        type: DT_STRING\\n        type: DT_INT32\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;summarize&quot;\\n    value {\\n      i: 3\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/checked_cell_state&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;AttentionWrapperZeroState/LSTMCellZeroState/zeros&quot;\\n  input: &quot;^AttentionWrapperZeroState/assert_equal/Assert/Assert&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/checked_cell_state_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;AttentionWrapperZeroState/LSTMCellZeroState/zeros_1&quot;\\n  input: &quot;^AttentionWrapperZeroState/assert_equal/Assert/Assert&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/ExpandDims/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/ExpandDims&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;unstack:1&quot;\\n  input: &quot;AttentionWrapperZeroState/ExpandDims/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 32\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;AttentionWrapperZeroState/ExpandDims&quot;\\n  input: &quot;AttentionWrapperZeroState/Const&quot;\\n  input: &quot;AttentionWrapperZeroState/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/ExpandDims_1/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/ExpandDims_1&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;unstack:1&quot;\\n  input: &quot;AttentionWrapperZeroState/ExpandDims_1/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 32\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/zeros_1/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/zeros_1&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;AttentionWrapperZeroState/concat&quot;\\n  input: &quot;AttentionWrapperZeroState/zeros_1/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/ExpandDims_2/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/ExpandDims_2&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;unstack:1&quot;\\n  input: &quot;AttentionWrapperZeroState/ExpandDims_2/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/ExpandDims_3/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/ExpandDims_3&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;LuongAttention/strided_slice_2&quot;\\n  input: &quot;AttentionWrapperZeroState/ExpandDims_3/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/concat_1/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/concat_1&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;AttentionWrapperZeroState/ExpandDims_2&quot;\\n  input: &quot;AttentionWrapperZeroState/ExpandDims_3&quot;\\n  input: &quot;AttentionWrapperZeroState/concat_1/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/ExpandDims_4/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/ExpandDims_4&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;unstack:1&quot;\\n  input: &quot;AttentionWrapperZeroState/ExpandDims_4/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/ExpandDims_5/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/ExpandDims_5&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;LuongAttention/strided_slice_2&quot;\\n  input: &quot;AttentionWrapperZeroState/ExpandDims_5/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/zeros_2/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/zeros_2&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;AttentionWrapperZeroState/concat_1&quot;\\n  input: &quot;AttentionWrapperZeroState/zeros_2/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;TrainingHelper/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;embedding_lookup_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;TrainingHelper/strided_slice/stack&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;TrainingHelper/strided_slice/stack_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;TrainingHelper/strided_slice/stack_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;TrainingHelper/strided_slice&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;TrainingHelper/Shape&quot;\\n  input: &quot;TrainingHelper/strided_slice/stack&quot;\\n  input: &quot;TrainingHelper/strided_slice/stack_1&quot;\\n  input: &quot;TrainingHelper/strided_slice/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;TrainingHelper/TensorArray&quot;\\n  op: &quot;TensorArrayV3&quot;\\n  input: &quot;TrainingHelper/strided_slice&quot;\\n  attr {\\n    key: &quot;clear_after_read&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;dynamic_size&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;element_shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n        dim {\\n          size: 20\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;tensor_array_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;TrainingHelper/TensorArrayUnstack/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;embedding_lookup_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;TrainingHelper/TensorArrayUnstack/strided_slice/stack&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;TrainingHelper/TensorArrayUnstack/strided_slice/stack_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;TrainingHelper/TensorArrayUnstack/strided_slice/stack_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;TrainingHelper/TensorArrayUnstack/strided_slice&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;TrainingHelper/TensorArrayUnstack/Shape&quot;\\n  input: &quot;TrainingHelper/TensorArrayUnstack/strided_slice/stack&quot;\\n  input: &quot;TrainingHelper/TensorArrayUnstack/strided_slice/stack_1&quot;\\n  input: &quot;TrainingHelper/TensorArrayUnstack/strided_slice/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;TrainingHelper/TensorArrayUnstack/range/start&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;TrainingHelper/TensorArrayUnstack/range/delta&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;TrainingHelper/TensorArrayUnstack/range&quot;\\n  op: &quot;Range&quot;\\n  input: &quot;TrainingHelper/TensorArrayUnstack/range/start&quot;\\n  input: &quot;TrainingHelper/TensorArrayUnstack/strided_slice&quot;\\n  input: &quot;TrainingHelper/TensorArrayUnstack/range/delta&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;TrainingHelper/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3&quot;\\n  op: &quot;TensorArrayScatterV3&quot;\\n  input: &quot;TrainingHelper/TensorArray&quot;\\n  input: &quot;TrainingHelper/TensorArrayUnstack/range&quot;\\n  input: &quot;embedding_lookup_1&quot;\\n  input: &quot;TrainingHelper/TensorArray:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;TrainingHelper/strided_slice_1/stack&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;TrainingHelper/strided_slice_1/stack_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;TrainingHelper/strided_slice_1/stack_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;TrainingHelper/strided_slice_1&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;embedding_lookup_1&quot;\\n  input: &quot;TrainingHelper/strided_slice_1/stack&quot;\\n  input: &quot;TrainingHelper/strided_slice_1/stack_1&quot;\\n  input: &quot;TrainingHelper/strided_slice_1/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;TrainingHelper/zeros_like&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;TrainingHelper/strided_slice_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;TrainingHelper/Size&quot;\\n  op: &quot;Size&quot;\\n  input: &quot;add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TrainingHelperInitialize/Equal/x&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TrainingHelperInitialize/Equal&quot;\\n  op: &quot;Equal&quot;\\n  input: &quot;decoder/TrainingHelperInitialize/Equal/x&quot;\\n  input: &quot;add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TrainingHelperInitialize/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TrainingHelperInitialize/All&quot;\\n  op: &quot;All&quot;\\n  input: &quot;decoder/TrainingHelperInitialize/Equal&quot;\\n  input: &quot;decoder/TrainingHelperInitialize/Const&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TrainingHelperInitialize/cond/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;decoder/TrainingHelperInitialize/All&quot;\\n  input: &quot;decoder/TrainingHelperInitialize/All&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TrainingHelperInitialize/cond/switch_t&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/TrainingHelperInitialize/cond/Switch:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TrainingHelperInitialize/cond/switch_f&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/TrainingHelperInitialize/cond/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TrainingHelperInitialize/cond/pred_id&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/TrainingHelperInitialize/All&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TrainingHelperInitialize/cond/Switch_1&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;TrainingHelper/zeros_like&quot;\\n  input: &quot;decoder/TrainingHelperInitialize/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@TrainingHelper/zeros_like&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TrainingHelperInitialize/cond/TensorArrayReadV3/index&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/TrainingHelperInitialize/cond/switch_f&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TrainingHelperInitialize/cond/TensorArrayReadV3/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;TrainingHelper/TensorArray&quot;\\n  input: &quot;decoder/TrainingHelperInitialize/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@TrainingHelper/TensorArray&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TrainingHelperInitialize/cond/TensorArrayReadV3/Switch_1&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;TrainingHelper/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3&quot;\\n  input: &quot;decoder/TrainingHelperInitialize/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TrainingHelperInitialize/cond/TensorArrayReadV3&quot;\\n  op: &quot;TensorArrayReadV3&quot;\\n  input: &quot;decoder/TrainingHelperInitialize/cond/TensorArrayReadV3/Switch&quot;\\n  input: &quot;decoder/TrainingHelperInitialize/cond/TensorArrayReadV3/index&quot;\\n  input: &quot;decoder/TrainingHelperInitialize/cond/TensorArrayReadV3/Switch_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TrainingHelperInitialize/cond/Merge&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;decoder/TrainingHelperInitialize/cond/TensorArrayReadV3&quot;\\n  input: &quot;decoder/TrainingHelperInitialize/cond/Switch_1:1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/zero_suffix_shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 10\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/concat/values_0&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;TrainingHelper/Size&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;decoder/concat/values_0&quot;\\n  input: &quot;decoder/zero_suffix_shape&quot;\\n  input: &quot;decoder/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/zeros/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/zeros&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;decoder/concat&quot;\\n  input: &quot;decoder/zeros/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/zero_suffix_shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/concat_1/values_0&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;TrainingHelper/Size&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/concat_1/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/concat_1&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;decoder/concat_1/values_0&quot;\\n  input: &quot;decoder/zero_suffix_shape_1&quot;\\n  input: &quot;decoder/concat_1/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/zeros_1/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/zeros_1&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;decoder/concat_1&quot;\\n  input: &quot;decoder/zeros_1/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/zeros_like/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;decoder/TrainingHelperInitialize/Equal&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/zeros_like/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/zeros_like&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;decoder/zeros_like/Shape&quot;\\n  input: &quot;decoder/zeros_like/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TensorArray/size&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TensorArray&quot;\\n  op: &quot;TensorArrayV3&quot;\\n  input: &quot;decoder/TensorArray/size&quot;\\n  attr {\\n    key: &quot;clear_after_read&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;dynamic_size&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;element_shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;tensor_array_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TensorArray_1/size&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TensorArray_1&quot;\\n  op: &quot;TensorArrayV3&quot;\\n  input: &quot;decoder/TensorArray_1/size&quot;\\n  attr {\\n    key: &quot;clear_after_read&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dynamic_size&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;element_shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;tensor_array_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;decoder/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Enter_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;decoder/TensorArray:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Enter_2&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;decoder/TensorArray_1:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Enter_3&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;concat_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Enter_4&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;concat_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Enter_5&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;AttentionWrapperZeroState/zeros_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Enter_6&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;AttentionWrapperZeroState/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Enter_7&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;AttentionWrapperZeroState/zeros_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Enter_8&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;decoder/TrainingHelperInitialize/cond/Merge&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Enter_9&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;decoder/TrainingHelperInitialize/Equal&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Enter_10&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;decoder/zeros_like&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Merge&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;decoder/while/Enter&quot;\\n  input: &quot;decoder/while/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Merge_1&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;decoder/while/Enter_1&quot;\\n  input: &quot;decoder/while/NextIteration_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Merge_2&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;decoder/while/Enter_2&quot;\\n  input: &quot;decoder/while/NextIteration_2&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Merge_3&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;decoder/while/Enter_3&quot;\\n  input: &quot;decoder/while/NextIteration_3&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Merge_4&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;decoder/while/Enter_4&quot;\\n  input: &quot;decoder/while/NextIteration_4&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Merge_5&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;decoder/while/Enter_5&quot;\\n  input: &quot;decoder/while/NextIteration_5&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Merge_6&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;decoder/while/Enter_6&quot;\\n  input: &quot;decoder/while/NextIteration_6&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Merge_7&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;decoder/while/Enter_7&quot;\\n  input: &quot;decoder/while/NextIteration_7&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Merge_8&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;decoder/while/Enter_8&quot;\\n  input: &quot;decoder/while/NextIteration_8&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Merge_9&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;decoder/while/Enter_9&quot;\\n  input: &quot;decoder/while/NextIteration_9&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Merge_10&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;decoder/while/Enter_10&quot;\\n  input: &quot;decoder/while/NextIteration_10&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Merge&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/All&quot;\\n  op: &quot;All&quot;\\n  input: &quot;decoder/while/Merge_9&quot;\\n  input: &quot;decoder/while/Const&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/LogicalNot&quot;\\n  op: &quot;LogicalNot&quot;\\n  input: &quot;decoder/while/All&quot;\\n}\\nnode {\\n  name: &quot;decoder/while/LoopCond&quot;\\n  op: &quot;LoopCond&quot;\\n  input: &quot;decoder/while/LogicalNot&quot;\\n}\\nnode {\\n  name: &quot;decoder/while/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;decoder/while/Merge&quot;\\n  input: &quot;decoder/while/LoopCond&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Merge&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Switch_1&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;decoder/while/Merge_1&quot;\\n  input: &quot;decoder/while/LoopCond&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Merge_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Switch_2&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;decoder/while/Merge_2&quot;\\n  input: &quot;decoder/while/LoopCond&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Merge_2&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Switch_3&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;decoder/while/Merge_3&quot;\\n  input: &quot;decoder/while/LoopCond&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Merge_3&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Switch_4&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;decoder/while/Merge_4&quot;\\n  input: &quot;decoder/while/LoopCond&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Merge_4&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Switch_5&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;decoder/while/Merge_5&quot;\\n  input: &quot;decoder/while/LoopCond&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Merge_5&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Switch_6&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;decoder/while/Merge_6&quot;\\n  input: &quot;decoder/while/LoopCond&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Merge_6&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Switch_7&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;decoder/while/Merge_7&quot;\\n  input: &quot;decoder/while/LoopCond&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Merge_7&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Switch_8&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;decoder/while/Merge_8&quot;\\n  input: &quot;decoder/while/LoopCond&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Merge_8&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Switch_9&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;decoder/while/Merge_9&quot;\\n  input: &quot;decoder/while/LoopCond&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Merge_9&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Switch_10&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;decoder/while/Merge_10&quot;\\n  input: &quot;decoder/while/LoopCond&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Merge_10&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Identity&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/while/Switch:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Identity_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/while/Switch_1:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Identity_2&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/while/Switch_2:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Identity_3&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/while/Switch_3:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Identity_4&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/while/Switch_4:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Identity_5&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/while/Switch_5:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Identity_6&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/while/Switch_6:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Identity_7&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/while/Switch_7:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Identity_8&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/while/Switch_8:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Identity_9&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/while/Switch_9:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Identity_10&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/while/Switch_10:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;decoder/while/Identity_8&quot;\\n  input: &quot;decoder/while/Identity_5&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/kernel/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;T\\\\000\\\\000\\\\000\\\\200\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/kernel/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.168231651187\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/kernel/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.168231651187\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/kernel/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/kernel/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/kernel/Initializer/random_uniform/max&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/kernel/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/kernel/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/kernel/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/kernel/Initializer/random_uniform/mul&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/kernel&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 84\\n        }\\n        dim {\\n          size: 128\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/kernel/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/kernel&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/kernel/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/kernel/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/kernel&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat&quot;\\n  input: &quot;decoder/while/Identity_4&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/bias/Initializer/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 128\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/bias&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 128\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/bias&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/bias/Initializer/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd&quot;\\n  op: &quot;BiasAdd&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 4\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split/split_dim&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split&quot;\\n  op: &quot;Split&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split/split_dim&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;num_split&quot;\\n    value {\\n      i: 4\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add/y&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split:2&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid&quot;\\n  op: &quot;Sigmoid&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid&quot;\\n  input: &quot;decoder/while/Identity_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid_1&quot;\\n  op: &quot;Sigmoid&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Tanh&quot;\\n  op: &quot;Tanh&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid_1&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Tanh&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid_2&quot;\\n  op: &quot;Sigmoid&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split:3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Tanh_1&quot;\\n  op: &quot;Tanh&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid_2&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Tanh_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/strided_slice/stack&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/strided_slice/stack_1&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/strided_slice/stack_2&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/strided_slice&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/Shape&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/strided_slice/stack&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/strided_slice/stack_1&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/strided_slice/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/Equal/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;LuongAttention/strided_slice_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/Equal&quot;\\n  op: &quot;Equal&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/strided_slice&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/Equal/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/All&quot;\\n  op: &quot;All&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/Equal&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/Const&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/Assert/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;When applying AttentionWrapper attention_wrapper_1: Non-matching batch sizes between the memory (encoder output) and the query (decoder output).  Are you using the BeamSearchDecoder?  You may need to tile your memory input via the tf.contrib.seq2seq.tile_batch function with argument multiple=beam_width.&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/Assert/Const_1&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;Condition x == y did not hold element-wise:&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/Assert/Const_2&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;x (decoder/while/BasicDecoderStep/decoder/attention_wrapper/strided_slice:0) = &quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/Assert/Const_3&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;y (LuongAttention/strided_slice_1:0) = &quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/Assert/Assert/data_0&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;When applying AttentionWrapper attention_wrapper_1: Non-matching batch sizes between the memory (encoder output) and the query (decoder output).  Are you using the BeamSearchDecoder?  You may need to tile your memory input via the tf.contrib.seq2seq.tile_batch function with argument multiple=beam_width.&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/Assert/Assert/data_1&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;Condition x == y did not hold element-wise:&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/Assert/Assert/data_2&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;x (decoder/while/BasicDecoderStep/decoder/attention_wrapper/strided_slice:0) = &quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/Assert/Assert/data_4&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;y (LuongAttention/strided_slice_1:0) = &quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/Assert/Assert&quot;\\n  op: &quot;Assert&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/All&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/Assert/Assert/data_0&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/Assert/Assert/data_1&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/Assert/Assert/data_2&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/strided_slice&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/Assert/Assert/data_4&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/Equal/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      list {\\n        type: DT_STRING\\n        type: DT_STRING\\n        type: DT_STRING\\n        type: DT_INT32\\n        type: DT_STRING\\n        type: DT_INT32\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;summarize&quot;\\n    value {\\n      i: 3\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/checked_cell_output&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2&quot;\\n  input: &quot;^decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/Assert/Assert&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims/dim&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/checked_cell_output&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul&quot;\\n  op: &quot;BatchMatMul&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;adj_x&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;adj_y&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/Squeeze&quot;\\n  op: &quot;Squeeze&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;squeeze_dims&quot;\\n    value {\\n      list {\\n        i: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax&quot;\\n  op: &quot;Softmax&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/Squeeze&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims/dim&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;transpose&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul&quot;\\n  op: &quot;BatchMatMul&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;adj_x&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;adj_y&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze&quot;\\n  op: &quot;Squeeze&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;squeeze_dims&quot;\\n    value {\\n      list {\\n        i: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1/axis&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/checked_cell_output&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/attention_layer/kernel/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/attention_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;@\\\\000\\\\000\\\\000 \\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/attention_layer/kernel/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/attention_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.25\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/attention_layer/kernel/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/attention_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.25\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/attention_layer/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;decoder/attention_wrapper/attention_layer/kernel/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/attention_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/attention_layer/kernel/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;decoder/attention_wrapper/attention_layer/kernel/Initializer/random_uniform/max&quot;\\n  input: &quot;decoder/attention_wrapper/attention_layer/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/attention_layer/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/attention_layer/kernel/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;decoder/attention_wrapper/attention_layer/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;decoder/attention_wrapper/attention_layer/kernel/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/attention_layer/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/attention_layer/kernel/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;decoder/attention_wrapper/attention_layer/kernel/Initializer/random_uniform/mul&quot;\\n  input: &quot;decoder/attention_wrapper/attention_layer/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/attention_layer/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/attention_layer/kernel&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/attention_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 64\\n        }\\n        dim {\\n          size: 32\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/attention_layer/kernel/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;decoder/attention_wrapper/attention_layer/kernel&quot;\\n  input: &quot;decoder/attention_wrapper/attention_layer/kernel/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/attention_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/attention_layer/kernel/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/attention_wrapper/attention_layer/kernel&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;decoder/attention_wrapper/attention_layer/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_2/concat_dim&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_2&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/add/y&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;decoder/while/Identity_6&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/add/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/kernel/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot; \\\\000\\\\000\\\\000\\\\n\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/kernel/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.37796446681\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/kernel/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.37796446681\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;decoder/dense/kernel/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/kernel/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;decoder/dense/kernel/Initializer/random_uniform/max&quot;\\n  input: &quot;decoder/dense/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/kernel/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;decoder/dense/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;decoder/dense/kernel/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/kernel/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;decoder/dense/kernel/Initializer/random_uniform/mul&quot;\\n  input: &quot;decoder/dense/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/kernel&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 32\\n        }\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/kernel/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;decoder/dense/kernel&quot;\\n  input: &quot;decoder/dense/kernel/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/kernel/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/dense/kernel&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/bias/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 10\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/bias&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;decoder/dense/bias&quot;\\n  input: &quot;decoder/dense/bias/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/dense/bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/dense/MatMul/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;decoder/dense/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/dense/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_2&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/dense/MatMul/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/dense/BiasAdd/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;decoder/dense/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/dense/BiasAdd&quot;\\n  op: &quot;BiasAdd&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/dense/MatMul&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/dense/BiasAdd/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/TrainingHelperSample/ArgMax/dimension&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/TrainingHelperSample/ArgMax&quot;\\n  op: &quot;ArgMax&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/dense/BiasAdd&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperSample/ArgMax/dimension&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;output_type&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/TrainingHelperSample/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperSample/ArgMax&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/add/y&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;decoder/while/Identity&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/add/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/GreaterEqual/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/GreaterEqual&quot;\\n  op: &quot;GreaterEqual&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/add&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/GreaterEqual/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/All&quot;\\n  op: &quot;All&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/GreaterEqual&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/Const&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/All&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/All&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/switch_t&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Switch:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/switch_f&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/pred_id&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/All&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;TrainingHelper/zeros_like&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Switch_1&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Enter&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Enter&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;TrainingHelper/TensorArray&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Enter&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Enter&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Switch_1&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/add&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/TrainingHelperNextInputs/add&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Enter_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;TrainingHelper/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Switch_2&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Enter_1&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Enter_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3&quot;\\n  op: &quot;TensorArrayReadV3&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Switch&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Switch_1&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Switch_2&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Switch_1:1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/LogicalOr&quot;\\n  op: &quot;LogicalOr&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/GreaterEqual&quot;\\n  input: &quot;decoder/while/Identity_9&quot;\\n}\\nnode {\\n  name: &quot;decoder/while/LogicalNot_1&quot;\\n  op: &quot;LogicalNot&quot;\\n  input: &quot;decoder/while/Identity_9&quot;\\n}\\nnode {\\n  name: &quot;decoder/while/LogicalAnd&quot;\\n  op: &quot;LogicalAnd&quot;\\n  input: &quot;decoder/while/LogicalNot_1&quot;\\n  input: &quot;decoder/while/LogicalOr&quot;\\n}\\nnode {\\n  name: &quot;decoder/while/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;decoder/while/Identity_10&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/add/y&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;decoder/while/Identity&quot;\\n  input: &quot;decoder/while/add/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;decoder/while/Shape&quot;\\n  input: &quot;decoder/while/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Select&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;decoder/while/LogicalAnd&quot;\\n  input: &quot;decoder/while/Fill&quot;\\n  input: &quot;decoder/while/Identity_10&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/TensorArrayWrite/TensorArrayWriteV3/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;decoder/TensorArray&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/dense/BiasAdd&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/TensorArrayWrite/TensorArrayWriteV3&quot;\\n  op: &quot;TensorArrayWriteV3&quot;\\n  input: &quot;decoder/while/TensorArrayWrite/TensorArrayWriteV3/Enter&quot;\\n  input: &quot;decoder/while/Identity&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/dense/BiasAdd&quot;\\n  input: &quot;decoder/while/Identity_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/dense/BiasAdd&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;decoder/TensorArray_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/TrainingHelperSample/Cast&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/TensorArrayWrite_1/TensorArrayWriteV3&quot;\\n  op: &quot;TensorArrayWriteV3&quot;\\n  input: &quot;decoder/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter&quot;\\n  input: &quot;decoder/while/Identity&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperSample/Cast&quot;\\n  input: &quot;decoder/while/Identity_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/TrainingHelperSample/Cast&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/add_1/y&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/add_1&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;decoder/while/Identity&quot;\\n  input: &quot;decoder/while/add_1/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;decoder/while/add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/NextIteration_1&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;decoder/while/TensorArrayWrite/TensorArrayWriteV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/NextIteration_2&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;decoder/while/TensorArrayWrite_1/TensorArrayWriteV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/NextIteration_3&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/NextIteration_4&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/NextIteration_5&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/NextIteration_6&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/NextIteration_7&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/NextIteration_8&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/NextIteration_9&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;decoder/while/LogicalOr&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/NextIteration_10&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;decoder/while/Select&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Exit&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;decoder/while/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Exit_1&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;decoder/while/Switch_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Exit_2&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;decoder/while/Switch_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Exit_3&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;decoder/while/Switch_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Exit_4&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;decoder/while/Switch_4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Exit_5&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;decoder/while/Switch_5&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Exit_6&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;decoder/while/Switch_6&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Exit_7&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;decoder/while/Switch_7&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Exit_8&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;decoder/while/Switch_8&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Exit_9&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;decoder/while/Switch_9&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Exit_10&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;decoder/while/Switch_10&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TensorArrayStack/TensorArraySizeV3&quot;\\n  op: &quot;TensorArraySizeV3&quot;\\n  input: &quot;decoder/TensorArray&quot;\\n  input: &quot;decoder/while/Exit_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/TensorArray&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TensorArrayStack/range/start&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/TensorArray&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TensorArrayStack/range/delta&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/TensorArray&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TensorArrayStack/range&quot;\\n  op: &quot;Range&quot;\\n  input: &quot;decoder/TensorArrayStack/range/start&quot;\\n  input: &quot;decoder/TensorArrayStack/TensorArraySizeV3&quot;\\n  input: &quot;decoder/TensorArrayStack/range/delta&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/TensorArray&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TensorArrayStack/TensorArrayGatherV3&quot;\\n  op: &quot;TensorArrayGatherV3&quot;\\n  input: &quot;decoder/TensorArray&quot;\\n  input: &quot;decoder/TensorArrayStack/range&quot;\\n  input: &quot;decoder/while/Exit_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/TensorArray&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;element_shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TensorArrayStack_1/TensorArraySizeV3&quot;\\n  op: &quot;TensorArraySizeV3&quot;\\n  input: &quot;decoder/TensorArray_1&quot;\\n  input: &quot;decoder/while/Exit_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/TensorArray_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TensorArrayStack_1/range/start&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/TensorArray_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TensorArrayStack_1/range/delta&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/TensorArray_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TensorArrayStack_1/range&quot;\\n  op: &quot;Range&quot;\\n  input: &quot;decoder/TensorArrayStack_1/range/start&quot;\\n  input: &quot;decoder/TensorArrayStack_1/TensorArraySizeV3&quot;\\n  input: &quot;decoder/TensorArrayStack_1/range/delta&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/TensorArray_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TensorArrayStack_1/TensorArrayGatherV3&quot;\\n  op: &quot;TensorArrayGatherV3&quot;\\n  input: &quot;decoder/TensorArray_1&quot;\\n  input: &quot;decoder/TensorArrayStack_1/range&quot;\\n  input: &quot;decoder/while/Exit_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/TensorArray_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;element_shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;one_hot/on_value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;one_hot/off_value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;one_hot/depth&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 10\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;one_hot&quot;\\n  op: &quot;OneHot&quot;\\n  input: &quot;decoder_targets&quot;\\n  input: &quot;one_hot/depth&quot;\\n  input: &quot;one_hot/on_value&quot;\\n  input: &quot;one_hot/off_value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;TI&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: -1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Rank&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 3\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;decoder/TensorArrayStack/TensorArrayGatherV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Rank_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 3\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Shape_2&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;decoder/TensorArrayStack/TensorArrayGatherV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Sub/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;Rank_1&quot;\\n  input: &quot;Sub/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Slice/begin&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;Sub&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Slice/size&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Slice&quot;\\n  op: &quot;Slice&quot;\\n  input: &quot;Shape_2&quot;\\n  input: &quot;Slice/begin&quot;\\n  input: &quot;Slice/size&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;concat_3/values_0&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;concat_3/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;concat_3&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;concat_3/values_0&quot;\\n  input: &quot;Slice&quot;\\n  input: &quot;concat_3/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;decoder/TensorArrayStack/TensorArrayGatherV3&quot;\\n  input: &quot;concat_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Rank_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 3\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Shape_3&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;one_hot&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Sub_1/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Sub_1&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;Rank_2&quot;\\n  input: &quot;Sub_1/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Slice_1/begin&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;Sub_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Slice_1/size&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Slice_1&quot;\\n  op: &quot;Slice&quot;\\n  input: &quot;Shape_3&quot;\\n  input: &quot;Slice_1/begin&quot;\\n  input: &quot;Slice_1/size&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;concat_4/values_0&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;concat_4/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;concat_4&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;concat_4/values_0&quot;\\n  input: &quot;Slice_1&quot;\\n  input: &quot;concat_4/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;one_hot&quot;\\n  input: &quot;concat_4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;SoftmaxCrossEntropyWithLogits&quot;\\n  op: &quot;SoftmaxCrossEntropyWithLogits&quot;\\n  input: &quot;Reshape&quot;\\n  input: &quot;Reshape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Sub_2/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Sub_2&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;Rank&quot;\\n  input: &quot;Sub_2/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Slice_2/begin&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Slice_2/size&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;Sub_2&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Slice_2&quot;\\n  op: &quot;Slice&quot;\\n  input: &quot;Shape_1&quot;\\n  input: &quot;Slice_2/begin&quot;\\n  input: &quot;Slice_2/size&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Reshape_2&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;SoftmaxCrossEntropyWithLogits&quot;\\n  input: &quot;Slice_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Mean&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;Reshape_2&quot;\\n  input: &quot;Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape&quot;\\n  input: &quot;gradients/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/f_count&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/f_count_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/f_count&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Merge&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/f_count_1&quot;\\n  input: &quot;gradients/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/Merge&quot;\\n  input: &quot;decoder/while/LoopCond&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Add/y&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;gradients/Switch:1&quot;\\n  input: &quot;gradients/Add/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/Add&quot;\\n  input: &quot;^gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayWrite/TensorArrayWriteV3/f_sync&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/MatMul_1/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/MatMul_1/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/mod/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN/StackPush_1&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze_grad/Reshape/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/MatMul_1/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims_grad/Reshape/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax_grad/mul/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/Squeeze_grad/Reshape/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/MatMul_1/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims_grad/Reshape/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPush_1&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul_1/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPush_1&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPush_1&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul_1/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPush_1&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul_1/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split_grad/concat/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/StackPush_1&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/mod/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN/StackPush_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/f_count_2&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/b_count&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/b_count_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/f_count_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Merge_1&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/b_count_1&quot;\\n  input: &quot;gradients/NextIteration_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/GreaterEqual/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/b_count&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/GreaterEqual&quot;\\n  op: &quot;GreaterEqual&quot;\\n  input: &quot;gradients/Merge_1&quot;\\n  input: &quot;gradients/GreaterEqual/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/b_count_2&quot;\\n  op: &quot;LoopCond&quot;\\n  input: &quot;gradients/GreaterEqual&quot;\\n}\\nnode {\\n  name: &quot;gradients/Switch_1&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/Merge_1&quot;\\n  input: &quot;gradients/b_count_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;gradients/Switch_1:1&quot;\\n  input: &quot;gradients/GreaterEqual/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/NextIteration_1&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/Sub&quot;\\n  input: &quot;^gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/b_sync&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/b_count_3&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/Switch_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/f_count_3&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/f_count_4&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/f_count_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Merge_2&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/f_count_4&quot;\\n  input: &quot;gradients/NextIteration_2&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch_2&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/Merge_2&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/LoopCond&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Add_1/y&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^bidirectional_rnn/fw/fw/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Add_1&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;gradients/Switch_2:1&quot;\\n  input: &quot;gradients/Add_1/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/NextIteration_2&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/Add_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/zeros_like/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/Select/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/zeros_like/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/Select/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Select_grad/Select/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPush_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul_1/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPush_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPush_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/mul_1/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPush_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul_1/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split_grad/concat/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/StackPush&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/f_count_5&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/Switch_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/b_count_4&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/b_count_5&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/f_count_5&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Merge_3&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/b_count_5&quot;\\n  input: &quot;gradients/NextIteration_3&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/GreaterEqual_1/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/b_count_4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/GreaterEqual_1&quot;\\n  op: &quot;GreaterEqual&quot;\\n  input: &quot;gradients/Merge_3&quot;\\n  input: &quot;gradients/GreaterEqual_1/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/b_count_6&quot;\\n  op: &quot;LoopCond&quot;\\n  input: &quot;gradients/GreaterEqual_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/Switch_3&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/Merge_3&quot;\\n  input: &quot;gradients/b_count_6&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Sub_1&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;gradients/Switch_3:1&quot;\\n  input: &quot;gradients/GreaterEqual_1/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/NextIteration_3&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/Sub_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/zeros_like/b_sync&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/b_count_7&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/Switch_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/f_count_6&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/f_count_7&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/f_count_6&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Merge_4&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/f_count_7&quot;\\n  input: &quot;gradients/NextIteration_4&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch_4&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/Merge_4&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/LoopCond&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Add_2/y&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^bidirectional_rnn/bw/bw/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Add_2&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;gradients/Switch_4:1&quot;\\n  input: &quot;gradients/Add_2/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/NextIteration_4&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/Add_2&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/zeros_like/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/Select/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/zeros_like/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/Select/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Select_grad/Select/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs/StackPush_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul_1/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs/StackPush_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs/StackPush_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/mul_1/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs/StackPush_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul_1/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/BroadcastGradientArgs/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split_grad/concat/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/MatMul_1/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/mod/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/ShapeN/StackPush&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/f_count_8&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/Switch_4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/b_count_8&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/b_count_9&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/f_count_8&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Merge_5&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/b_count_9&quot;\\n  input: &quot;gradients/NextIteration_5&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/GreaterEqual_2/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/b_count_8&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/GreaterEqual_2&quot;\\n  op: &quot;GreaterEqual&quot;\\n  input: &quot;gradients/Merge_5&quot;\\n  input: &quot;gradients/GreaterEqual_2/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/b_count_10&quot;\\n  op: &quot;LoopCond&quot;\\n  input: &quot;gradients/GreaterEqual_2&quot;\\n}\\nnode {\\n  name: &quot;gradients/Switch_5&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/Merge_5&quot;\\n  input: &quot;gradients/b_count_10&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Sub_2&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;gradients/Switch_5:1&quot;\\n  input: &quot;gradients/GreaterEqual_2/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/NextIteration_5&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/Sub_2&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/zeros_like/b_sync&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/b_count_11&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/Switch_5&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/Fill&quot;\\n  input: &quot;gradients/Mean_grad/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Reshape_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;gradients/Mean_grad/Reshape&quot;\\n  input: &quot;gradients/Mean_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Reshape_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Shape_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Prod&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;gradients/Mean_grad/Shape_1&quot;\\n  input: &quot;gradients/Mean_grad/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Prod_1&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;gradients/Mean_grad/Shape_2&quot;\\n  input: &quot;gradients/Mean_grad/Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Maximum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Maximum&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;gradients/Mean_grad/Prod_1&quot;\\n  input: &quot;gradients/Mean_grad/Maximum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/floordiv&quot;\\n  op: &quot;FloorDiv&quot;\\n  input: &quot;gradients/Mean_grad/Prod&quot;\\n  input: &quot;gradients/Mean_grad/Maximum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;gradients/Mean_grad/floordiv&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/truediv&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;gradients/Mean_grad/Tile&quot;\\n  input: &quot;gradients/Mean_grad/Cast&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Reshape_2_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;SoftmaxCrossEntropyWithLogits&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Reshape_2_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/Mean_grad/truediv&quot;\\n  input: &quot;gradients/Reshape_2_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;SoftmaxCrossEntropyWithLogits:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/SoftmaxCrossEntropyWithLogits_grad/ExpandDims/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/SoftmaxCrossEntropyWithLogits_grad/ExpandDims&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;gradients/Reshape_2_grad/Reshape&quot;\\n  input: &quot;gradients/SoftmaxCrossEntropyWithLogits_grad/ExpandDims/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/SoftmaxCrossEntropyWithLogits_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/SoftmaxCrossEntropyWithLogits_grad/ExpandDims&quot;\\n  input: &quot;SoftmaxCrossEntropyWithLogits:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Reshape_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;decoder/TensorArrayStack/TensorArrayGatherV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Reshape_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/SoftmaxCrossEntropyWithLogits_grad/mul&quot;\\n  input: &quot;gradients/Reshape_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  op: &quot;TensorArrayGradV3&quot;\\n  input: &quot;decoder/TensorArray&quot;\\n  input: &quot;decoder/while/Exit_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/TensorArray&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;source&quot;\\n    value {\\n      s: &quot;gradients&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayGrad/gradient_flow&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/while/Exit_1&quot;\\n  input: &quot;^gradients/decoder/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/TensorArray&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayScatter/TensorArrayScatterV3&quot;\\n  op: &quot;TensorArrayScatterV3&quot;\\n  input: &quot;gradients/decoder/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  input: &quot;decoder/TensorArrayStack/range&quot;\\n  input: &quot;gradients/Reshape_grad/Reshape&quot;\\n  input: &quot;gradients/decoder/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayGrad/gradient_flow&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_1&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;decoder/while/Exit_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_2&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;decoder/while/Exit_4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_3&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;decoder/while/Exit_5&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_4&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;decoder/while/Exit_7&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_5&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;decoder/while/Exit_8&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Exit_1_grad/b_exit&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/decoder/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayScatter/TensorArrayScatterV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Exit_2_grad/b_exit&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Exit_3_grad/b_exit&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/zeros_like_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Exit_4_grad/b_exit&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/zeros_like_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Exit_5_grad/b_exit&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/zeros_like_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Exit_7_grad/b_exit&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/zeros_like_4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Exit_8_grad/b_exit&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/zeros_like_5&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Switch_1_grad/b_switch&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/decoder/while/Exit_1_grad/b_exit&quot;\\n  input: &quot;gradients/decoder/while/Switch_1_grad_1/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Switch_3_grad/b_switch&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/decoder/while/Exit_3_grad/b_exit&quot;\\n  input: &quot;gradients/decoder/while/Switch_3_grad_1/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Switch_4_grad/b_switch&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/decoder/while/Exit_4_grad/b_exit&quot;\\n  input: &quot;gradients/decoder/while/Switch_4_grad_1/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Switch_5_grad/b_switch&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/decoder/while/Exit_5_grad/b_exit&quot;\\n  input: &quot;gradients/decoder/while/Switch_5_grad_1/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Switch_8_grad/b_switch&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/decoder/while/Exit_8_grad/b_exit&quot;\\n  input: &quot;gradients/decoder/while/Switch_8_grad_1/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Merge_1_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/decoder/while/Switch_1_grad/b_switch&quot;\\n  input: &quot;gradients/b_count_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/Switch_1_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Merge_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/decoder/while/Merge_1_grad/Switch&quot;\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Merge_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/Merge_1_grad/Switch&quot;\\n  input: &quot;^gradients/decoder/while/Merge_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/Switch_1_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Merge_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/Merge_1_grad/Switch:1&quot;\\n  input: &quot;^gradients/decoder/while/Merge_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/Switch_1_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Merge_3_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/decoder/while/Switch_3_grad/b_switch&quot;\\n  input: &quot;gradients/b_count_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/Switch_3_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Merge_3_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/decoder/while/Merge_3_grad/Switch&quot;\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Merge_3_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/Merge_3_grad/Switch&quot;\\n  input: &quot;^gradients/decoder/while/Merge_3_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/Switch_3_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Merge_3_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/Merge_3_grad/Switch:1&quot;\\n  input: &quot;^gradients/decoder/while/Merge_3_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/Switch_3_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Merge_4_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/decoder/while/Switch_4_grad/b_switch&quot;\\n  input: &quot;gradients/b_count_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/Switch_4_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Merge_4_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/decoder/while/Merge_4_grad/Switch&quot;\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Merge_4_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/Merge_4_grad/Switch&quot;\\n  input: &quot;^gradients/decoder/while/Merge_4_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/Switch_4_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Merge_4_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/Merge_4_grad/Switch:1&quot;\\n  input: &quot;^gradients/decoder/while/Merge_4_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/Switch_4_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Merge_5_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/decoder/while/Switch_5_grad/b_switch&quot;\\n  input: &quot;gradients/b_count_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/Switch_5_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Merge_5_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/decoder/while/Merge_5_grad/Switch&quot;\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Merge_5_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/Merge_5_grad/Switch&quot;\\n  input: &quot;^gradients/decoder/while/Merge_5_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/Switch_5_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Merge_5_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/Merge_5_grad/Switch:1&quot;\\n  input: &quot;^gradients/decoder/while/Merge_5_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/Switch_5_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Merge_8_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/decoder/while/Switch_8_grad/b_switch&quot;\\n  input: &quot;gradients/b_count_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/Switch_8_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Merge_8_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/decoder/while/Merge_8_grad/Switch&quot;\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Merge_8_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/Merge_8_grad/Switch&quot;\\n  input: &quot;^gradients/decoder/while/Merge_8_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/Switch_8_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Merge_8_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/Merge_8_grad/Switch:1&quot;\\n  input: &quot;^gradients/decoder/while/Merge_8_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/Switch_8_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Enter_1_grad/Exit&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/decoder/while/Merge_1_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Enter_3_grad/Exit&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/decoder/while/Merge_3_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Enter_4_grad/Exit&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/decoder/while/Merge_4_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Enter_5_grad/Exit&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/decoder/while/Merge_5_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Enter_8_grad/Exit&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/decoder/while/Merge_8_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayGrad/TensorArrayGradV3/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;decoder/TensorArray&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/dense/BiasAdd&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  op: &quot;TensorArrayGradV3&quot;\\n  input: &quot;gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayGrad/TensorArrayGradV3/Enter&quot;\\n  input: &quot;gradients/decoder/while/Merge_1_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/dense/BiasAdd&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;source&quot;\\n    value {\\n      s: &quot;gradients&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayGrad/gradient_flow&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/Merge_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;^gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/dense/BiasAdd&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Identity&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Identity&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/RefEnter&quot;\\n  input: &quot;decoder/while/Identity&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Identity&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Identity&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Identity&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/b_sync&quot;\\n  op: &quot;ControlTrigger&quot;\\n  input: &quot;^gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayWrite/TensorArrayWriteV3/StackPop&quot;\\n  input: &quot;^gradients/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/MatMul_1/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/MatMul_1/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/mod/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN/StackPop_1&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze_grad/Reshape/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/MatMul_1/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims_grad/Reshape/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax_grad/mul/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/Squeeze_grad/Reshape/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/MatMul_1/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims_grad/Reshape/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul_1/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul_1/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul_1/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split_grad/concat/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/StackPop_1&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/mod/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN/StackPop_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3&quot;\\n  op: &quot;TensorArrayReadV3&quot;\\n  input: &quot;gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  input: &quot;gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPop&quot;\\n  input: &quot;gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayGrad/gradient_flow&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/decoder/while/Merge_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;^gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3&quot;\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3&quot;\\n  input: &quot;^gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/Merge_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;^gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/Switch_1_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_1_grad/Rank&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_1_grad/mod&quot;\\n  op: &quot;FloorMod&quot;\\n  input: &quot;concat_1/axis&quot;\\n  input: &quot;gradients/concat_1_grad/Rank&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_1_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Exit_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_1_grad/ShapeN&quot;\\n  op: &quot;ShapeN&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Exit_2&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Exit_2&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_1_grad/ConcatOffset&quot;\\n  op: &quot;ConcatOffset&quot;\\n  input: &quot;gradients/concat_1_grad/mod&quot;\\n  input: &quot;gradients/concat_1_grad/ShapeN&quot;\\n  input: &quot;gradients/concat_1_grad/ShapeN:1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_1_grad/Slice&quot;\\n  op: &quot;Slice&quot;\\n  input: &quot;gradients/decoder/while/Enter_3_grad/Exit&quot;\\n  input: &quot;gradients/concat_1_grad/ConcatOffset&quot;\\n  input: &quot;gradients/concat_1_grad/ShapeN&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_1_grad/Slice_1&quot;\\n  op: &quot;Slice&quot;\\n  input: &quot;gradients/decoder/while/Enter_3_grad/Exit&quot;\\n  input: &quot;gradients/concat_1_grad/ConcatOffset:1&quot;\\n  input: &quot;gradients/concat_1_grad/ShapeN:1&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/concat_1_grad/Slice&quot;\\n  input: &quot;^gradients/concat_1_grad/Slice_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/concat_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/concat_1_grad/Slice&quot;\\n  input: &quot;^gradients/concat_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/concat_1_grad/Slice&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/concat_1_grad/Slice_1&quot;\\n  input: &quot;^gradients/concat_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/concat_1_grad/Slice_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_2_grad/Rank&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_2_grad/mod&quot;\\n  op: &quot;FloorMod&quot;\\n  input: &quot;concat_2/axis&quot;\\n  input: &quot;gradients/concat_2_grad/Rank&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_2_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Exit_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_2_grad/ShapeN&quot;\\n  op: &quot;ShapeN&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Exit_3&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Exit_3&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_2_grad/ConcatOffset&quot;\\n  op: &quot;ConcatOffset&quot;\\n  input: &quot;gradients/concat_2_grad/mod&quot;\\n  input: &quot;gradients/concat_2_grad/ShapeN&quot;\\n  input: &quot;gradients/concat_2_grad/ShapeN:1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_2_grad/Slice&quot;\\n  op: &quot;Slice&quot;\\n  input: &quot;gradients/decoder/while/Enter_4_grad/Exit&quot;\\n  input: &quot;gradients/concat_2_grad/ConcatOffset&quot;\\n  input: &quot;gradients/concat_2_grad/ShapeN&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_2_grad/Slice_1&quot;\\n  op: &quot;Slice&quot;\\n  input: &quot;gradients/decoder/while/Enter_4_grad/Exit&quot;\\n  input: &quot;gradients/concat_2_grad/ConcatOffset:1&quot;\\n  input: &quot;gradients/concat_2_grad/ShapeN:1&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_2_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/concat_2_grad/Slice&quot;\\n  input: &quot;^gradients/concat_2_grad/Slice_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/concat_2_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/concat_2_grad/Slice&quot;\\n  input: &quot;^gradients/concat_2_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/concat_2_grad/Slice&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_2_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/concat_2_grad/Slice_1&quot;\\n  input: &quot;^gradients/concat_2_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/concat_2_grad/Slice_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/TrainingHelperInitialize/cond/Merge_grad/cond_grad&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/decoder/while/Enter_8_grad/Exit&quot;\\n  input: &quot;decoder/TrainingHelperInitialize/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/Enter_8_grad/Exit&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/TrainingHelperInitialize/cond/Merge_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/decoder/TrainingHelperInitialize/cond/Merge_grad/cond_grad&quot;\\n}\\nnode {\\n  name: &quot;gradients/decoder/TrainingHelperInitialize/cond/Merge_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/TrainingHelperInitialize/cond/Merge_grad/cond_grad&quot;\\n  input: &quot;^gradients/decoder/TrainingHelperInitialize/cond/Merge_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/Enter_8_grad/Exit&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/TrainingHelperInitialize/cond/Merge_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/TrainingHelperInitialize/cond/Merge_grad/cond_grad:1&quot;\\n  input: &quot;^gradients/decoder/TrainingHelperInitialize/cond/Merge_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/Enter_8_grad/Exit&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/pred_id&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/pred_id&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/RefEnter&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/pred_id&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/pred_id&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/pred_id&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/pred_id&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/cond_grad&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/decoder/while/Merge_8_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/Switch_8_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/cond_grad&quot;\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/cond_grad&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/Switch_8_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/cond_grad:1&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/Switch_8_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/BiasAdd_grad/BiasAddGrad&quot;\\n  op: &quot;BiasAddGrad&quot;\\n  input: &quot;gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/BiasAdd_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/control_dependency&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/dense/BiasAdd_grad/BiasAddGrad&quot;\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/BiasAdd_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/control_dependency&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/dense/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/BiasAdd_grad/BiasAddGrad&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/dense/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/dense/BiasAdd_grad/BiasAddGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/TrainingHelperInitialize/cond/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  op: &quot;TensorArrayGradV3&quot;\\n  input: &quot;decoder/TrainingHelperInitialize/cond/TensorArrayReadV3/Switch&quot;\\n  input: &quot;decoder/TrainingHelperInitialize/cond/TensorArrayReadV3/Switch_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@TrainingHelper/TensorArray&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;source&quot;\\n    value {\\n      s: &quot;gradients&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/TrainingHelperInitialize/cond/TensorArrayReadV3_grad/TensorArrayGrad/gradient_flow&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/TrainingHelperInitialize/cond/TensorArrayReadV3/Switch_1&quot;\\n  input: &quot;^gradients/decoder/TrainingHelperInitialize/cond/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@TrainingHelper/TensorArray&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/TrainingHelperInitialize/cond/TensorArrayReadV3_grad/TensorArrayWrite/TensorArrayWriteV3&quot;\\n  op: &quot;TensorArrayWriteV3&quot;\\n  input: &quot;gradients/decoder/TrainingHelperInitialize/cond/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  input: &quot;decoder/TrainingHelperInitialize/cond/TensorArrayReadV3/index&quot;\\n  input: &quot;gradients/decoder/TrainingHelperInitialize/cond/Merge_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/decoder/TrainingHelperInitialize/cond/TensorArrayReadV3_grad/TensorArrayGrad/gradient_flow&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch_6&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;TrainingHelper/zeros_like&quot;\\n  input: &quot;decoder/TrainingHelperInitialize/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;gradients/Switch_6&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_1/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_1&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape_1&quot;\\n  input: &quot;gradients/zeros_1/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/TrainingHelperInitialize/cond/Switch_1_grad/cond_grad&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/decoder/TrainingHelperInitialize/cond/Merge_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/zeros_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;TrainingHelper/TensorArray&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Enter&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3/Enter_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;TrainingHelper/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Enter&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  op: &quot;TensorArrayGradV3&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3/Enter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3/Enter_1&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Enter&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;source&quot;\\n    value {\\n      s: &quot;gradients&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayGrad/gradient_flow&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3/Enter_1&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Enter&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayWrite/TensorArrayWriteV3/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/TrainingHelperNextInputs/add&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayWrite/TensorArrayWriteV3/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayWrite/TensorArrayWriteV3/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/TrainingHelperNextInputs/add&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayWrite/TensorArrayWriteV3/StackPush/Switch&quot;\\n  op: &quot;RefSwitch&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayWrite/TensorArrayWriteV3/RefEnter&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/TrainingHelperNextInputs/add&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayWrite/TensorArrayWriteV3/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayWrite/TensorArrayWriteV3/StackPush/Switch&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Switch_1&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/TrainingHelperNextInputs/add&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayWrite/TensorArrayWriteV3/f_sync&quot;\\n  op: &quot;ControlTrigger&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayWrite/TensorArrayWriteV3/StackPush&quot;\\n  input: &quot;^gradients/StackPush&quot;\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayWrite/TensorArrayWriteV3/Switch/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayWrite/TensorArrayWriteV3/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/TrainingHelperNextInputs/add&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayWrite/TensorArrayWriteV3/Switch&quot;\\n  op: &quot;RefSwitch&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayWrite/TensorArrayWriteV3/Switch/RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/TrainingHelperNextInputs/add&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayWrite/TensorArrayWriteV3/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayWrite/TensorArrayWriteV3/Switch&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/TrainingHelperNextInputs/add&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayWrite/TensorArrayWriteV3&quot;\\n  op: &quot;TensorArrayWriteV3&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayWrite/TensorArrayWriteV3/StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayGrad/gradient_flow&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch_7&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Enter&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Enter&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape_2&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;gradients/Switch_7&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Shape_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Shape_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/RefEnter&quot;\\n  input: &quot;gradients/Shape_2&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Shape_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch_8/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Shape_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch_8&quot;\\n  op: &quot;RefSwitch&quot;\\n  input: &quot;gradients/Switch_8/RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Shape_2&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/Switch_8&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Shape_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_2/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_2&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/StackPop&quot;\\n  input: &quot;gradients/zeros_2/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Switch_1_grad/cond_grad&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/zeros_2&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/MatMul/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;decoder/dense/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/BiasAdd_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/MatMul/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/MatMul_1/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/MatMul_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/MatMul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/MatMul_1/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/MatMul_1/RefEnter&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_2&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/MatMul_1/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/MatMul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/MatMul_1/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/MatMul_1/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/MatMul_1/StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/BiasAdd_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/BiasAdd/Enter_grad/b_acc&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 10\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/BiasAdd/Enter_grad/b_acc_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/BiasAdd/Enter_grad/b_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/BiasAdd/Enter_grad/b_acc_2&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/BiasAdd/Enter_grad/b_acc_1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/BiasAdd/Enter_grad/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/BiasAdd/Enter_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/BiasAdd/Enter_grad/b_acc_2&quot;\\n  input: &quot;gradients/b_count_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/BiasAdd/Enter_grad/Add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/BiasAdd/Enter_grad/Switch:1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/BiasAdd/Enter_grad/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/BiasAdd/Enter_grad/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/BiasAdd/Enter_grad/b_acc_3&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/BiasAdd/Enter_grad/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Switch_1_grad_1/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch_9&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;TrainingHelper/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3&quot;\\n  input: &quot;decoder/TrainingHelperInitialize/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape_3&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;gradients/Switch_9:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_3/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_3&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape_3&quot;\\n  input: &quot;gradients/zeros_3/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/TrainingHelperInitialize/cond/TensorArrayReadV3/Switch_1_grad/cond_grad&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/decoder/TrainingHelperInitialize/cond/TensorArrayReadV3_grad/TensorArrayWrite/TensorArrayWriteV3&quot;\\n  input: &quot;gradients/zeros_3&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Const_1&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch_10&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/Const_1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Const_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Switch_2_grad/cond_grad&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayWrite/TensorArrayWriteV3&quot;\\n  input: &quot;gradients/Switch_10:1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Enter_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;TrainingHelper/zeros_like&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Enter_grad/zeros/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Enter_grad/zeros&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Enter_grad/Shape&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Enter_grad/zeros/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Enter_grad/b_acc&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Enter_grad/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Enter_grad/b_acc_1&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Enter_grad/b_acc&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Enter_grad/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Enter_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Enter_grad/b_acc_1&quot;\\n  input: &quot;gradients/b_count_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Enter_grad/Add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Enter_grad/Switch:1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Switch_1_grad/cond_grad&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Enter_grad/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Enter_grad/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Enter_grad/b_acc_2&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Enter_grad/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/decoder/while/Merge_5_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/Switch_5_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul/Enter_grad/b_acc&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 32\\n          }\\n          dim {\\n            size: 10\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul/Enter_grad/b_acc_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul/Enter_grad/b_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul/Enter_grad/b_acc_2&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul/Enter_grad/b_acc_1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul/Enter_grad/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul/Enter_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul/Enter_grad/b_acc_2&quot;\\n  input: &quot;gradients/b_count_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul/Enter_grad/Add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul/Enter_grad/Switch:1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul/Enter_grad/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul/Enter_grad/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul/Enter_grad/b_acc_3&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul/Enter_grad/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Enter_1_grad/b_acc&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Enter_1_grad/b_acc_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Enter_1_grad/b_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Enter_1_grad/b_acc_2&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Enter_1_grad/b_acc_1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Enter_1_grad/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Enter_1_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Enter_1_grad/b_acc_2&quot;\\n  input: &quot;gradients/b_count_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Enter_1_grad/Add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Enter_1_grad/Switch:1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Switch_2_grad/cond_grad&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Enter_1_grad/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Enter_1_grad/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Enter_1_grad/b_acc_3&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Enter_1_grad/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_1&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/decoder/TrainingHelperInitialize/cond/Switch_1_grad/cond_grad&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Enter_grad/b_acc_2&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/TrainingHelperInitialize/cond/Switch_1_grad/cond_grad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/MatMul/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;decoder/attention_wrapper/attention_layer/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradients/AddN&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/MatMul/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/MatMul_1/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/MatMul_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/MatMul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/MatMul_1/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/MatMul_1/RefEnter&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/MatMul_1/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/MatMul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/MatMul_1/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/MatMul_1/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/MatMul_1/StackPop&quot;\\n  input: &quot;gradients/AddN&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_2&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/decoder/TrainingHelperInitialize/cond/TensorArrayReadV3/Switch_1_grad/cond_grad&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Enter_1_grad/b_acc_3&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/TrainingHelperInitialize/cond/TensorArrayReadV3/Switch_1_grad/cond_grad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/TrainingHelper/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  op: &quot;TensorArrayGradV3&quot;\\n  input: &quot;TrainingHelper/TensorArray&quot;\\n  input: &quot;gradients/AddN_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@TrainingHelper/TensorArray&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;source&quot;\\n    value {\\n      s: &quot;gradients&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/TrainingHelper/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGrad/gradient_flow&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/AddN_2&quot;\\n  input: &quot;^gradients/TrainingHelper/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@TrainingHelper/TensorArray&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/TrainingHelper/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGatherV3&quot;\\n  op: &quot;TensorArrayGatherV3&quot;\\n  input: &quot;gradients/TrainingHelper/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  input: &quot;TrainingHelper/TensorArrayUnstack/range&quot;\\n  input: &quot;gradients/TrainingHelper/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGrad/gradient_flow&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;element_shape&quot;\\n    value {\\n      shape {\\n        unknown_rank: true\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/TrainingHelper/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/AddN_2&quot;\\n  input: &quot;^gradients/TrainingHelper/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGatherV3&quot;\\n}\\nnode {\\n  name: &quot;gradients/TrainingHelper/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/TrainingHelper/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGatherV3&quot;\\n  input: &quot;^gradients/TrainingHelper/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/TrainingHelper/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGatherV3&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/TrainingHelper/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/AddN_2&quot;\\n  input: &quot;^gradients/TrainingHelper/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/TrainingHelperInitialize/cond/TensorArrayReadV3/Switch_1_grad/cond_grad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/Rank&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/mod/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1/axis&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/mod/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/mod/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1/axis&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/mod/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/mod/RefEnter&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1/axis&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1/axis&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/mod/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/mod/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1/axis&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/mod/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/mod/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1/axis&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/mod&quot;\\n  op: &quot;FloorMod&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/mod/StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/Rank&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/checked_cell_output&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/checked_cell_output&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/checked_cell_output&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN/RefEnter&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/checked_cell_output&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/checked_cell_output&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/checked_cell_output&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/checked_cell_output&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN/f_acc_1&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN/RefEnter_1&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN/StackPush_1&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN/RefEnter_1&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN/StackPop_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN/StackPop_1&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN/StackPop_1/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN&quot;\\n  op: &quot;ShapeN&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN/StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN/StackPop_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ConcatOffset&quot;\\n  op: &quot;ConcatOffset&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/mod&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN:1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/Slice&quot;\\n  op: &quot;Slice&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ConcatOffset&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/Slice_1&quot;\\n  op: &quot;Slice&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ConcatOffset:1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN:1&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/Slice&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/Slice_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/Slice&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/Slice&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/Slice_1&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/Slice_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul/Enter_grad/b_acc&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 64\\n          }\\n          dim {\\n            size: 32\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul/Enter_grad/b_acc_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul/Enter_grad/b_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul/Enter_grad/b_acc_2&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul/Enter_grad/b_acc_1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul/Enter_grad/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul/Enter_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul/Enter_grad/b_acc_2&quot;\\n  input: &quot;gradients/b_count_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul/Enter_grad/Add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul/Enter_grad/Switch:1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul/Enter_grad/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul/Enter_grad/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul/Enter_grad/b_acc_3&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul/Enter_grad/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze_grad/Reshape/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze_grad/Reshape/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze_grad/Reshape/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze_grad/Reshape/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze_grad/Reshape/RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze_grad/Shape&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze_grad/Reshape/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze_grad/Reshape/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze_grad/Reshape/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze_grad/Reshape/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze_grad/Reshape/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/MatMul/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;transpose&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/MatMul&quot;\\n  op: &quot;BatchMatMul&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze_grad/Reshape&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/MatMul/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;adj_x&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;adj_y&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/MatMul_1/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/MatMul_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/MatMul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/MatMul_1/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/MatMul_1/RefEnter&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/MatMul_1/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/MatMul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/MatMul_1/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/MatMul_1/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/MatMul_1&quot;\\n  op: &quot;BatchMatMul&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/MatMul_1/StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze_grad/Reshape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;adj_x&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;adj_y&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims_grad/Reshape/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims_grad/Reshape/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims_grad/Reshape/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims_grad/Reshape/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims_grad/Reshape/RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims_grad/Shape&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims_grad/Reshape/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims_grad/Reshape/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims_grad/Reshape/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims_grad/Reshape/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims_grad/Reshape/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul/Enter_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;transpose&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul/Enter_grad/zeros/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul/Enter_grad/zeros&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul/Enter_grad/Shape&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul/Enter_grad/zeros/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul/Enter_grad/b_acc&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul/Enter_grad/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul/Enter_grad/b_acc_1&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul/Enter_grad/b_acc&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul/Enter_grad/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul/Enter_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul/Enter_grad/b_acc_1&quot;\\n  input: &quot;gradients/b_count_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul/Enter_grad/Add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul/Enter_grad/Switch:1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul/Enter_grad/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul/Enter_grad/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul/Enter_grad/b_acc_2&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul/Enter_grad/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/embedding_lookup_1_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT64\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\n\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\024\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/embedding_lookup_1_grad/ToInt32&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;gradients/embedding_lookup_1_grad/Shape&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/embedding_lookup_1_grad/Size&quot;\\n  op: &quot;Size&quot;\\n  input: &quot;ones&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/embedding_lookup_1_grad/ExpandDims/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/embedding_lookup_1_grad/ExpandDims&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;gradients/embedding_lookup_1_grad/Size&quot;\\n  input: &quot;gradients/embedding_lookup_1_grad/ExpandDims/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/embedding_lookup_1_grad/strided_slice/stack&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/embedding_lookup_1_grad/strided_slice/stack_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/embedding_lookup_1_grad/strided_slice/stack_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/embedding_lookup_1_grad/strided_slice&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;gradients/embedding_lookup_1_grad/ToInt32&quot;\\n  input: &quot;gradients/embedding_lookup_1_grad/strided_slice/stack&quot;\\n  input: &quot;gradients/embedding_lookup_1_grad/strided_slice/stack_1&quot;\\n  input: &quot;gradients/embedding_lookup_1_grad/strided_slice/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/embedding_lookup_1_grad/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/embedding_lookup_1_grad/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;gradients/embedding_lookup_1_grad/ExpandDims&quot;\\n  input: &quot;gradients/embedding_lookup_1_grad/strided_slice&quot;\\n  input: &quot;gradients/embedding_lookup_1_grad/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/embedding_lookup_1_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/TrainingHelper/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/embedding_lookup_1_grad/concat&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/embedding_lookup_1_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;ones&quot;\\n  input: &quot;gradients/embedding_lookup_1_grad/ExpandDims&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax_grad/mul/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax_grad/mul/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax_grad/mul/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax_grad/mul/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax_grad/mul/RefEnter&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax_grad/mul/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax_grad/mul/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax_grad/mul/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax_grad/mul/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims_grad/Reshape&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax_grad/mul/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax_grad/Sum/reduction_indices&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax_grad/mul&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax_grad/Sum/reduction_indices&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax_grad/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\377\\\\377\\\\377\\\\377\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax_grad/Sum&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax_grad/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax_grad/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims_grad/Reshape&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax_grad/Reshape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax_grad/sub&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax_grad/mul/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/Squeeze_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/Squeeze_grad/Reshape/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/Squeeze_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/Squeeze_grad/Reshape/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/Squeeze_grad/Reshape/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/Squeeze_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/Squeeze_grad/Reshape/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/Squeeze_grad/Reshape/RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/Squeeze_grad/Shape&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/Squeeze_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/Squeeze_grad/Reshape/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/Squeeze_grad/Reshape/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/Squeeze_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/Squeeze_grad/Reshape/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/Squeeze_grad/Reshape/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/Squeeze_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/Squeeze_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax_grad/mul_1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/Squeeze_grad/Reshape/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/MatMul/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/MatMul&quot;\\n  op: &quot;BatchMatMul&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/Squeeze_grad/Reshape&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/MatMul/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;adj_x&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;adj_y&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/MatMul_1/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/MatMul_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/MatMul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/MatMul_1/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/MatMul_1/RefEnter&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/MatMul_1/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/MatMul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/MatMul_1/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/MatMul_1/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/MatMul_1&quot;\\n  op: &quot;BatchMatMul&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/Squeeze_grad/Reshape&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/MatMul_1/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;adj_x&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;adj_y&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/checked_cell_output&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims_grad/Reshape/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims_grad/Reshape/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims_grad/Reshape/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims_grad/Reshape/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims_grad/Reshape/RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims_grad/Shape&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims_grad/Reshape/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims_grad/Reshape/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims_grad/Reshape/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims_grad/Reshape/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims_grad/Reshape/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul/Enter_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul/Enter_grad/zeros/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul/Enter_grad/zeros&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul/Enter_grad/Shape&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul/Enter_grad/zeros/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul/Enter_grad/b_acc&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul/Enter_grad/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul/Enter_grad/b_acc_1&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul/Enter_grad/b_acc&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul/Enter_grad/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul/Enter_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul/Enter_grad/b_acc_1&quot;\\n  input: &quot;gradients/b_count_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul/Enter_grad/Add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul/Enter_grad/Switch:1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul/Enter_grad/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul/Enter_grad/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul/Enter_grad/b_acc_2&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul/Enter_grad/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_3&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims_grad/Reshape&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/Slice&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/LuongAttention/memory_layer/Tensordot_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/MatMul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/LuongAttention/memory_layer/Tensordot_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul/Enter_grad/b_acc_2&quot;\\n  input: &quot;gradients/LuongAttention/memory_layer/Tensordot_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_4&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/decoder/while/Merge_4_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/AddN_3&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/Switch_4_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Tanh_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/Shape&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/RefEnter_1&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPush_1&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/RefEnter_1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/Shape_1&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPop_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPop_1/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Tanh_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Tanh_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul/RefEnter&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Tanh_1&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Tanh_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Tanh_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Tanh_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/AddN_4&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/Sum&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul_1/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul_1/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul_1/RefEnter&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid_2&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul_1/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul_1/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul_1/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul_1/StackPop&quot;\\n  input: &quot;gradients/AddN_4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul_1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/Sum_1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/Reshape&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/Reshape&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/Reshape_1&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/LuongAttention/memory_layer/Tensordot/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradients/LuongAttention/memory_layer/Tensordot_grad/Reshape&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/Reshape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/LuongAttention/memory_layer/Tensordot/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/Reshape&quot;\\n  input: &quot;gradients/LuongAttention/memory_layer/Tensordot_grad/Reshape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/LuongAttention/memory_layer/Tensordot/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/LuongAttention/memory_layer/Tensordot/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/LuongAttention/memory_layer/Tensordot/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/LuongAttention/memory_layer/Tensordot/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/LuongAttention/memory_layer/Tensordot/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/LuongAttention/memory_layer/Tensordot/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/LuongAttention/memory_layer/Tensordot/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/LuongAttention/memory_layer/Tensordot/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/LuongAttention/memory_layer/Tensordot/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^gradients/LuongAttention/memory_layer/Tensordot/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/LuongAttention/memory_layer/Tensordot/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid_2_grad/SigmoidGrad&quot;\\n  op: &quot;SigmoidGrad&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul_1/StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Tanh_1_grad/TanhGrad&quot;\\n  op: &quot;TanhGrad&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul/StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/LuongAttention/memory_layer/Tensordot/Reshape_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/transpose&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/LuongAttention/memory_layer/Tensordot/Reshape_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/LuongAttention/memory_layer/Tensordot/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/LuongAttention/memory_layer/Tensordot/Reshape_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/LuongAttention/memory_layer/Tensordot/Reshape_1_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot; \\\\000\\\\000\\\\000 \\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/LuongAttention/memory_layer/Tensordot/Reshape_1_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/LuongAttention/memory_layer/Tensordot/MatMul_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/LuongAttention/memory_layer/Tensordot/Reshape_1_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_5&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/decoder/while/Merge_3_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Tanh_1_grad/TanhGrad&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/Switch_3_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/Shape&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/RefEnter_1&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPush_1&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/RefEnter_1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/Shape_1&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPop_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPop_1/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/AddN_5&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/Sum&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/AddN_5&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/Sum_1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/Reshape&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/Reshape&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/Reshape_1&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/LuongAttention/memory_layer/Tensordot/transpose_grad/InvertPermutation&quot;\\n  op: &quot;InvertPermutation&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/concat_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/LuongAttention/memory_layer/Tensordot/transpose_grad/transpose&quot;\\n  op: &quot;Transpose&quot;\\n  input: &quot;gradients/LuongAttention/memory_layer/Tensordot/Reshape_grad/Reshape&quot;\\n  input: &quot;gradients/LuongAttention/memory_layer/Tensordot/transpose_grad/InvertPermutation&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tperm&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/LuongAttention/memory_layer/Tensordot/transpose_1_grad/InvertPermutation&quot;\\n  op: &quot;InvertPermutation&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/transpose_1/perm&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/LuongAttention/memory_layer/Tensordot/transpose_1_grad/transpose&quot;\\n  op: &quot;Transpose&quot;\\n  input: &quot;gradients/LuongAttention/memory_layer/Tensordot/Reshape_1_grad/Reshape&quot;\\n  input: &quot;gradients/LuongAttention/memory_layer/Tensordot/transpose_1_grad/InvertPermutation&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tperm&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;decoder/while/Identity_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/Shape&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/RefEnter_1&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPush_1&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/RefEnter_1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/Shape_1&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPop_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPop_1/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Identity_3&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Identity_3&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul/RefEnter&quot;\\n  input: &quot;decoder/while/Identity_3&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Identity_3&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Identity_3&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Identity_3&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/Sum&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul_1/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul_1/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul_1/RefEnter&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul_1/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul_1/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul_1/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul_1/StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul_1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/Sum_1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/Reshape&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/Reshape&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/Reshape_1&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Tanh&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/Shape&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/RefEnter_1&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPush_1&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/RefEnter_1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/Shape_1&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPop_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPop_1/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Tanh&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Tanh&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul/RefEnter&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Tanh&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Tanh&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Tanh&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Tanh&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/Sum&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul_1/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul_1/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul_1/RefEnter&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid_1&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul_1/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul_1/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul_1/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul_1/StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul_1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/Sum_1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/Reshape&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/Reshape&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/Reshape_1&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid_grad/SigmoidGrad&quot;\\n  op: &quot;SigmoidGrad&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul_1/StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid_1_grad/SigmoidGrad&quot;\\n  op: &quot;SigmoidGrad&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul_1/StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Tanh_grad/TanhGrad&quot;\\n  op: &quot;TanhGrad&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul/StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split:2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs/RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/Shape&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid_grad/SigmoidGrad&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/Sum&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid_grad/SigmoidGrad&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/Sum_1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/Reshape&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/Reshape&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/Reshape_1&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Switch_3_grad_1/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split_grad/concat/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split/split_dim&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split_grad/concat/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split_grad/concat/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split/split_dim&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split_grad/concat/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split_grad/concat/RefEnter&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split/split_dim&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split/split_dim&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split_grad/concat/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split_grad/concat/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split/split_dim&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split_grad/concat/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split_grad/concat/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split/split_dim&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split_grad/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid_1_grad/SigmoidGrad&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Tanh_grad/TanhGrad&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid_2_grad/SigmoidGrad&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split_grad/concat/StackPop&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 4\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_6&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul/Enter_grad/b_acc_2&quot;\\n  input: &quot;gradients/LuongAttention/memory_layer/Tensordot/transpose_grad/transpose&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul/Enter_grad/b_acc_2&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/transpose_grad/InvertPermutation&quot;\\n  op: &quot;InvertPermutation&quot;\\n  input: &quot;transpose/perm&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/transpose_grad/transpose&quot;\\n  op: &quot;Transpose&quot;\\n  input: &quot;gradients/AddN_6&quot;\\n  input: &quot;gradients/transpose_grad/InvertPermutation&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tperm&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd_grad/BiasAddGrad&quot;\\n  op: &quot;BiasAddGrad&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split_grad/concat&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split_grad/concat&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd_grad/BiasAddGrad&quot;\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split_grad/concat&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split_grad/concat&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd_grad/BiasAddGrad&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd_grad/BiasAddGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_grad/Rank&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 3\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_grad/mod&quot;\\n  op: &quot;FloorMod&quot;\\n  input: &quot;concat/axis&quot;\\n  input: &quot;gradients/concat_grad/Rank&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArrayStack/TensorArrayGatherV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_grad/ShapeN&quot;\\n  op: &quot;ShapeN&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArrayStack/TensorArrayGatherV3&quot;\\n  input: &quot;ReverseSequence&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_grad/ConcatOffset&quot;\\n  op: &quot;ConcatOffset&quot;\\n  input: &quot;gradients/concat_grad/mod&quot;\\n  input: &quot;gradients/concat_grad/ShapeN&quot;\\n  input: &quot;gradients/concat_grad/ShapeN:1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_grad/Slice&quot;\\n  op: &quot;Slice&quot;\\n  input: &quot;gradients/transpose_grad/transpose&quot;\\n  input: &quot;gradients/concat_grad/ConcatOffset&quot;\\n  input: &quot;gradients/concat_grad/ShapeN&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_grad/Slice_1&quot;\\n  op: &quot;Slice&quot;\\n  input: &quot;gradients/transpose_grad/transpose&quot;\\n  input: &quot;gradients/concat_grad/ConcatOffset:1&quot;\\n  input: &quot;gradients/concat_grad/ShapeN:1&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/concat_grad/Slice&quot;\\n  input: &quot;^gradients/concat_grad/Slice_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/concat_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/concat_grad/Slice&quot;\\n  input: &quot;^gradients/concat_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/concat_grad/Slice&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/concat_grad/Slice_1&quot;\\n  input: &quot;^gradients/concat_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/concat_grad/Slice_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1/RefEnter&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1/StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/b_acc&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 128\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/b_acc_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/b_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/b_acc_2&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/b_acc_1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/b_acc_2&quot;\\n  input: &quot;gradients/b_count_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/Add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/Switch:1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/b_acc_3&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  op: &quot;TensorArrayGradV3&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArray&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Exit_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/TensorArray&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;source&quot;\\n    value {\\n      s: &quot;gradients&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayGrad/gradient_flow&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Exit_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/TensorArray&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayScatter/TensorArrayScatterV3&quot;\\n  op: &quot;TensorArrayScatterV3&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArrayStack/range&quot;\\n  input: &quot;gradients/concat_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayGrad/gradient_flow&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/ReverseSequence_grad/ReverseSequence&quot;\\n  op: &quot;ReverseSequence&quot;\\n  input: &quot;gradients/concat_grad/tuple/control_dependency_1&quot;\\n  input: &quot;encoder_inputs_length&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tlen&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;batch_dim&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;seq_dim&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/Rank&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat/axis&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat/axis&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod/RefEnter&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat/axis&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat/axis&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat/axis&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat/axis&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod&quot;\\n  op: &quot;FloorMod&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod/StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/Rank&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/RefEnter&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/f_acc_1&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Identity_4&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/RefEnter_1&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Identity_4&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/StackPush_1&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/RefEnter_1&quot;\\n  input: &quot;decoder/while/Identity_4&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Identity_4&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/StackPop_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Identity_4&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/StackPop_1&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/StackPop_1/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Identity_4&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN&quot;\\n  op: &quot;ShapeN&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/StackPop_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ConcatOffset&quot;\\n  op: &quot;ConcatOffset&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN:1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/Slice&quot;\\n  op: &quot;Slice&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ConcatOffset&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/Slice_1&quot;\\n  op: &quot;Slice&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ConcatOffset:1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN:1&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/Slice&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/Slice_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/Slice&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/Slice&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/Slice_1&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/Slice_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/b_acc&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 84\\n          }\\n          dim {\\n            size: 128\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/b_acc_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/b_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/b_acc_2&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/b_acc_1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/b_acc_2&quot;\\n  input: &quot;gradients/b_count_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/Add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/Switch:1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/b_acc_3&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  op: &quot;TensorArrayGradV3&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArray&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Exit_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/TensorArray&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;source&quot;\\n    value {\\n      s: &quot;gradients&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayGrad/gradient_flow&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Exit_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/TensorArray&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayScatter/TensorArrayScatterV3&quot;\\n  op: &quot;TensorArrayScatterV3&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArrayStack/range&quot;\\n  input: &quot;gradients/ReverseSequence_grad/ReverseSequence&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayGrad/gradient_flow&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/Rank&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/mod/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat/axis&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/mod/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/mod/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat/axis&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/mod/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/mod/RefEnter&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat/axis&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat/axis&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/mod/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/mod/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat/axis&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/mod/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/mod/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat/axis&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/mod&quot;\\n  op: &quot;FloorMod&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/mod/StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/Rank&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;decoder/while/Identity_8&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Identity_8&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Identity_8&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN/RefEnter&quot;\\n  input: &quot;decoder/while/Identity_8&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Identity_8&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Identity_8&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Identity_8&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN/f_acc_1&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Identity_5&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN/RefEnter_1&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Identity_5&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN/StackPush_1&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN/RefEnter_1&quot;\\n  input: &quot;decoder/while/Identity_5&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Identity_5&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN/StackPop_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Identity_5&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN/StackPop_1&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN/StackPop_1/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Identity_5&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN&quot;\\n  op: &quot;ShapeN&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN/StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN/StackPop_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ConcatOffset&quot;\\n  op: &quot;ConcatOffset&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/mod&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN:1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/Slice&quot;\\n  op: &quot;Slice&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ConcatOffset&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/Slice_1&quot;\\n  op: &quot;Slice&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ConcatOffset:1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN:1&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/Slice&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/Slice_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/Slice&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/Slice&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/Slice_1&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/Slice_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Switch_4_grad_1/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Exit_2_grad/b_exit&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/concat_1_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Exit_3_grad/b_exit&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/concat_2_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Exit_1_grad/b_exit&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayScatter/TensorArrayScatterV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Switch_8_grad_1/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Switch_5_grad_1/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Switch_2_grad/b_switch&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Exit_2_grad/b_exit&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Switch_2_grad_1/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Switch_3_grad/b_switch&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Exit_3_grad/b_exit&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Switch_3_grad_1/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Switch_1_grad/b_switch&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Exit_1_grad/b_exit&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Switch_1_grad_1/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Exit_2_grad/b_exit&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/concat_1_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Exit_3_grad/b_exit&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/concat_2_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Exit_1_grad/b_exit&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayScatter/TensorArrayScatterV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_2_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Switch_2_grad/b_switch&quot;\\n  input: &quot;gradients/b_count_6&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/Switch_2_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_2_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Merge_2_grad/Switch&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_2_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_2_grad/Switch&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Merge_2_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/Switch_2_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_2_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_2_grad/Switch:1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Merge_2_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/Switch_2_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_3_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Switch_3_grad/b_switch&quot;\\n  input: &quot;gradients/b_count_6&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/Switch_3_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_3_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Merge_3_grad/Switch&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_3_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_3_grad/Switch&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Merge_3_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/Switch_3_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_3_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_3_grad/Switch:1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Merge_3_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/Switch_3_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_1_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Switch_1_grad/b_switch&quot;\\n  input: &quot;gradients/b_count_6&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/Switch_1_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Merge_1_grad/Switch&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_1_grad/Switch&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Merge_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/Switch_1_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_1_grad/Switch:1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Merge_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/Switch_1_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Switch_2_grad/b_switch&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Exit_2_grad/b_exit&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Switch_2_grad_1/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Switch_3_grad/b_switch&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Exit_3_grad/b_exit&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Switch_3_grad_1/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Switch_1_grad/b_switch&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Exit_1_grad/b_exit&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Switch_1_grad_1/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Enter_2_grad/Exit&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_2_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Enter_3_grad/Exit&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_3_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Enter_1_grad/Exit&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_1_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_2_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Switch_2_grad/b_switch&quot;\\n  input: &quot;gradients/b_count_10&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/bw/bw/while/Switch_2_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_2_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Merge_2_grad/Switch&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_2_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_2_grad/Switch&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Merge_2_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/bw/bw/while/Switch_2_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_2_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_2_grad/Switch:1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Merge_2_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/bw/bw/while/Switch_2_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_3_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Switch_3_grad/b_switch&quot;\\n  input: &quot;gradients/b_count_10&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/bw/bw/while/Switch_3_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_3_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Merge_3_grad/Switch&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_3_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_3_grad/Switch&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Merge_3_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/bw/bw/while/Switch_3_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_3_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_3_grad/Switch:1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Merge_3_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/bw/bw/while/Switch_3_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_1_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Switch_1_grad/b_switch&quot;\\n  input: &quot;gradients/b_count_10&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/bw/bw/while/Switch_1_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Merge_1_grad/Switch&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_1_grad/Switch&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Merge_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/bw/bw/while/Switch_1_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_1_grad/Switch:1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Merge_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/bw/bw/while/Switch_1_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/LSTMCellZeroState/zeros_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/LSTMCellZeroState/zeros_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Enter_2_grad/Exit&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/LSTMCellZeroState/zeros_grad/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/zeros_like/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/Identity_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/zeros_like/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/zeros_like/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/Identity_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/zeros_like/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/zeros_like/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Identity_2&quot;\\n  input: &quot;^gradients/Add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/Identity_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/zeros_like/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/zeros_like/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/Identity_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/zeros_like/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/zeros_like/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/Identity_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/zeros_like/b_sync&quot;\\n  op: &quot;ControlTrigger&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/zeros_like/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/Select/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/zeros_like/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/Select/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Select_grad/Select/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul_1/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/mul_1/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul_1/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split_grad/concat/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/StackPop&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/zeros_like&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/zeros_like/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/Select/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/GreaterEqual_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/Select/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/Select/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/GreaterEqual_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/Select/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/Select/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/GreaterEqual_1&quot;\\n  input: &quot;^gradients/Add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/GreaterEqual_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/Select/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/Select/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/GreaterEqual_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/Select/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/Select/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/GreaterEqual_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/Select&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/Select/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_2_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/zeros_like&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/Select_1&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/Select/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/zeros_like&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_2_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/Select&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/Select_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/Select&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/Select&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/Select_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/Select_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/LSTMCellZeroState/zeros_1_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/LSTMCellZeroState/zeros_1_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Enter_3_grad/Exit&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/LSTMCellZeroState/zeros_1_grad/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/zeros_like/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/Identity_3&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/zeros_like/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/zeros_like/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/Identity_3&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/zeros_like/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/zeros_like/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Identity_3&quot;\\n  input: &quot;^gradients/Add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/Identity_3&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/zeros_like/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/zeros_like/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/Identity_3&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/zeros_like/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/zeros_like/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/Identity_3&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/zeros_like&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/zeros_like/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/Select/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/GreaterEqual_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/Select/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/Select/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/GreaterEqual_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/Select/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/Select/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/GreaterEqual_2&quot;\\n  input: &quot;^gradients/Add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/GreaterEqual_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/Select/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/Select/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/GreaterEqual_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/Select/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/Select/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/GreaterEqual_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/Select&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/Select/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_3_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/zeros_like&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/Select_1&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/Select/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/zeros_like&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_3_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/Select&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/Select_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/Select&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/Select&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/Select_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/Select_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayGrad/TensorArrayGradV3/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArray&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  op: &quot;TensorArrayGradV3&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayGrad/TensorArrayGradV3/Enter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_1_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;source&quot;\\n    value {\\n      s: &quot;gradients&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayGrad/gradient_flow&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/Identity&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/Identity&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Identity&quot;\\n  input: &quot;^gradients/Add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/Identity&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/Identity&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/Identity&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3&quot;\\n  op: &quot;TensorArrayReadV3&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayGrad/gradient_flow&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Merge_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/Switch_1_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Enter_2_grad/Exit&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_2_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Enter_3_grad/Exit&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_3_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Enter_1_grad/Exit&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_1_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_grad/zeros_like/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_grad/zeros_like&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_grad/zeros_like/Enter&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_grad/Select/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/GreaterEqual&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_grad/Select/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_grad/Select/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/GreaterEqual&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_grad/Select/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_grad/Select/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/GreaterEqual&quot;\\n  input: &quot;^gradients/Add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/GreaterEqual&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_grad/Select/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_grad/Select/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/GreaterEqual&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_grad/Select/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_grad/Select/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/GreaterEqual&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_grad/Select&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_grad/Select/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_grad/zeros_like&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_grad/Select_1&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_grad/Select/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_grad/zeros_like&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Select_grad/Select&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Select_grad/Select_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_grad/Select&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Select_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/Select_grad/Select&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_grad/Select_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Select_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/Select_grad/Select_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/LSTMCellZeroState/zeros_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/LSTMCellZeroState/zeros_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Enter_2_grad/Exit&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/LSTMCellZeroState/zeros_grad/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/zeros_like/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/Identity_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/zeros_like/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/zeros_like/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/Identity_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/zeros_like/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/zeros_like/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Identity_2&quot;\\n  input: &quot;^gradients/Add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/Identity_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/zeros_like/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/zeros_like/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/Identity_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/zeros_like/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/zeros_like/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/Identity_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/zeros_like/b_sync&quot;\\n  op: &quot;ControlTrigger&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/zeros_like/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/Select/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/zeros_like/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/Select/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Select_grad/Select/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul_1/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/mul_1/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul_1/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split_grad/concat/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/MatMul_1/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/mod/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/ShapeN/StackPop&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/zeros_like&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/zeros_like/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/Select/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/GreaterEqual_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/Select/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/Select/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/GreaterEqual_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/Select/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/Select/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/GreaterEqual_1&quot;\\n  input: &quot;^gradients/Add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/GreaterEqual_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/Select/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/Select/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/GreaterEqual_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/Select/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/Select/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/GreaterEqual_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/Select&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/Select/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_2_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/zeros_like&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/Select_1&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/Select/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/zeros_like&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_2_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/Select&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/Select_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/Select&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/Select&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/Select_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/Select_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/LSTMCellZeroState/zeros_1_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/LSTMCellZeroState/zeros_1_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Enter_3_grad/Exit&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/LSTMCellZeroState/zeros_1_grad/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/zeros_like/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/Identity_3&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/zeros_like/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/zeros_like/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/Identity_3&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/zeros_like/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/zeros_like/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Identity_3&quot;\\n  input: &quot;^gradients/Add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/Identity_3&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/zeros_like/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/zeros_like/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/Identity_3&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/zeros_like/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/zeros_like/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/Identity_3&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/zeros_like&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/zeros_like/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/Select/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/GreaterEqual_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/Select/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/Select/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/GreaterEqual_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/Select/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/Select/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/GreaterEqual_2&quot;\\n  input: &quot;^gradients/Add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/GreaterEqual_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/Select/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/Select/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/GreaterEqual_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/Select/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/Select/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/GreaterEqual_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/Select&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/Select/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_3_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/zeros_like&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/Select_1&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/Select/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/zeros_like&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_3_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/Select&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/Select_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/Select&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/Select&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/Select_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/Select_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayGrad/TensorArrayGradV3/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArray&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  op: &quot;TensorArrayGradV3&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayGrad/TensorArrayGradV3/Enter&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_1_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;source&quot;\\n    value {\\n      s: &quot;gradients&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayGrad/gradient_flow&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/Identity&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/Identity&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Identity&quot;\\n  input: &quot;^gradients/Add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/Identity&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/Identity&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/Identity&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3&quot;\\n  op: &quot;TensorArrayReadV3&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayGrad/gradient_flow&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Merge_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/bw/bw/while/Switch_1_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select/Enter_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select/Enter_grad/zeros/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select/Enter_grad/zeros&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select/Enter_grad/Shape&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select/Enter_grad/zeros/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select/Enter_grad/b_acc&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select/Enter_grad/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select/Enter_grad/b_acc_1&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select/Enter_grad/b_acc&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select/Enter_grad/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select/Enter_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select/Enter_grad/b_acc_1&quot;\\n  input: &quot;gradients/b_count_6&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select/Enter_grad/Add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select/Enter_grad/Switch:1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select/Enter_grad/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select/Enter_grad/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select/Enter_grad/b_acc_2&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select/Enter_grad/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_7&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/Select_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Tanh_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/Shape&quot;\\n  input: &quot;^gradients/Add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/RefEnter_1&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPush_1&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/RefEnter_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/Shape_1&quot;\\n  input: &quot;^gradients/Add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPop_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPop_1/RefEnter&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Tanh_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Tanh_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Tanh_1&quot;\\n  input: &quot;^gradients/Add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Tanh_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Tanh_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Tanh_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/AddN_7&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul_1/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul_1/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul_1/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid_2&quot;\\n  input: &quot;^gradients/Add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul_1/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul_1/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul_1/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul_1/StackPop&quot;\\n  input: &quot;gradients/AddN_7&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/Sum_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/Reshape&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/Reshape&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/Reshape_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Switch_1_grad_1/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_grad/zeros_like/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_grad/zeros_like&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_grad/zeros_like/Enter&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_grad/Select/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/GreaterEqual&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_grad/Select/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_grad/Select/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/GreaterEqual&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_grad/Select/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_grad/Select/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/GreaterEqual&quot;\\n  input: &quot;^gradients/Add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/GreaterEqual&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_grad/Select/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_grad/Select/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/GreaterEqual&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_grad/Select/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_grad/Select/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/GreaterEqual&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_grad/Select&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_grad/Select/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_grad/zeros_like&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_grad/Select_1&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_grad/Select/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_grad/zeros_like&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Select_grad/Select&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Select_grad/Select_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_grad/Select&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Select_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/bw/bw/while/Select_grad/Select&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_grad/Select_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Select_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/bw/bw/while/Select_grad/Select_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/zeros_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/zeros_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select/Enter_grad/b_acc_2&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/zeros_grad/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid_2_grad/SigmoidGrad&quot;\\n  op: &quot;SigmoidGrad&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul_1/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Tanh_1_grad/TanhGrad&quot;\\n  op: &quot;TanhGrad&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select/Enter_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select/Enter_grad/zeros/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select/Enter_grad/zeros&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select/Enter_grad/Shape&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select/Enter_grad/zeros/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select/Enter_grad/b_acc&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select/Enter_grad/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select/Enter_grad/b_acc_1&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select/Enter_grad/b_acc&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select/Enter_grad/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select/Enter_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select/Enter_grad/b_acc_1&quot;\\n  input: &quot;gradients/b_count_10&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select/Enter_grad/Add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select/Enter_grad/Switch:1&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select/Enter_grad/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select/Enter_grad/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select/Enter_grad/b_acc_2&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select/Enter_grad/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_8&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/Select_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Tanh_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs/RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/Shape&quot;\\n  input: &quot;^gradients/Add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs/RefEnter_1&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs/StackPush_1&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs/RefEnter_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/Shape_1&quot;\\n  input: &quot;^gradients/Add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs/StackPop_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs/StackPop_1/RefEnter&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Tanh_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Tanh_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Tanh_1&quot;\\n  input: &quot;^gradients/Add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Tanh_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Tanh_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Tanh_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/AddN_8&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul_1/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul_1/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul_1/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid_2&quot;\\n  input: &quot;^gradients/Add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul_1/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul_1/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul_1/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul_1/StackPop&quot;\\n  input: &quot;gradients/AddN_8&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/Sum_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/Reshape&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/Reshape&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/Reshape_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Switch_1_grad_1/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_9&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Tanh_1_grad/TanhGrad&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/Select_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/Shape&quot;\\n  input: &quot;^gradients/Add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/RefEnter_1&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPush_1&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/RefEnter_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/Shape_1&quot;\\n  input: &quot;^gradients/Add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPop_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPop_1/RefEnter&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/AddN_9&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/AddN_9&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/Sum_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/Reshape&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/Reshape&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/Reshape_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/zeros_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/zeros_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select/Enter_grad/b_acc_2&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/zeros_grad/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid_2_grad/SigmoidGrad&quot;\\n  op: &quot;SigmoidGrad&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul_1/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Tanh_1_grad/TanhGrad&quot;\\n  op: &quot;TanhGrad&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Identity_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/Shape&quot;\\n  input: &quot;^gradients/Add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/RefEnter_1&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPush_1&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/RefEnter_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/Shape_1&quot;\\n  input: &quot;^gradients/Add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPop_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPop_1/RefEnter&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/zeros_like/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/mul&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/mul_1/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/mul_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/mul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/mul_1/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/mul_1/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid&quot;\\n  input: &quot;^gradients/Add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/mul_1/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/mul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/mul_1/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/mul_1/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/mul_1/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/mul_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/Sum_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/Reshape&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/Reshape&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/Reshape_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Tanh&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/Shape&quot;\\n  input: &quot;^gradients/Add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/RefEnter_1&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPush_1&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/RefEnter_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/Shape_1&quot;\\n  input: &quot;^gradients/Add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPop_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPop_1/RefEnter&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Tanh&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Tanh&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Tanh&quot;\\n  input: &quot;^gradients/Add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Tanh&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Tanh&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Tanh&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul_1/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul_1/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul_1/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid_1&quot;\\n  input: &quot;^gradients/Add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul_1/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul_1/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul_1/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul_1/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/Sum_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/Reshape&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/Reshape&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/Reshape_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_10&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Tanh_1_grad/TanhGrad&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/Select_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs/RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/Shape&quot;\\n  input: &quot;^gradients/Add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs/RefEnter_1&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs/StackPush_1&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs/RefEnter_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/Shape_1&quot;\\n  input: &quot;^gradients/Add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs/StackPop_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs/StackPop_1/RefEnter&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/AddN_10&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/AddN_10&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/Sum_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/Reshape&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/Reshape&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/Reshape_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid_grad/SigmoidGrad&quot;\\n  op: &quot;SigmoidGrad&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/mul_1/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_11&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/Select&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid_1_grad/SigmoidGrad&quot;\\n  op: &quot;SigmoidGrad&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul_1/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Tanh_grad/TanhGrad&quot;\\n  op: &quot;TanhGrad&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Identity_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs/RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/Shape&quot;\\n  input: &quot;^gradients/Add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs/RefEnter_1&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs/StackPush_1&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs/RefEnter_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/Shape_1&quot;\\n  input: &quot;^gradients/Add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs/StackPop_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs/StackPop_1/RefEnter&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/zeros_like/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/mul&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/mul_1/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/mul_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/mul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/mul_1/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/mul_1/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid&quot;\\n  input: &quot;^gradients/Add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/mul_1/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/mul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/mul_1/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/mul_1/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/mul_1/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/mul_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/Sum_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/Reshape&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/Reshape&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/Reshape_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Tanh&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs/RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/Shape&quot;\\n  input: &quot;^gradients/Add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs/RefEnter_1&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs/StackPush_1&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs/RefEnter_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/Shape_1&quot;\\n  input: &quot;^gradients/Add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs/StackPop_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs/StackPop_1/RefEnter&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Tanh&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Tanh&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Tanh&quot;\\n  input: &quot;^gradients/Add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Tanh&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Tanh&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Tanh&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul_1/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul_1/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul_1/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid_1&quot;\\n  input: &quot;^gradients/Add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul_1/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul_1/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul_1/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul_1/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/Sum_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/Reshape&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/Reshape&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/Reshape_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split:2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs/RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/Shape&quot;\\n  input: &quot;^gradients/Add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid_grad/SigmoidGrad&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid_grad/SigmoidGrad&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/Sum_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/Reshape&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/Reshape&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/Reshape_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Switch_2_grad_1/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/AddN_11&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid_grad/SigmoidGrad&quot;\\n  op: &quot;SigmoidGrad&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/mul_1/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_12&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/Select&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid_1_grad/SigmoidGrad&quot;\\n  op: &quot;SigmoidGrad&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul_1/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Tanh_grad/TanhGrad&quot;\\n  op: &quot;TanhGrad&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split_grad/concat/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split/split_dim&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split_grad/concat/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split_grad/concat/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split/split_dim&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split_grad/concat/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split_grad/concat/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split/split_dim&quot;\\n  input: &quot;^gradients/Add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split/split_dim&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split_grad/concat/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split_grad/concat/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split/split_dim&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split_grad/concat/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split_grad/concat/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split/split_dim&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split_grad/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid_1_grad/SigmoidGrad&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Tanh_grad/TanhGrad&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid_2_grad/SigmoidGrad&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split_grad/concat/StackPop&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 4\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split:2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/BroadcastGradientArgs/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/BroadcastGradientArgs/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/BroadcastGradientArgs/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/BroadcastGradientArgs/RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/Shape&quot;\\n  input: &quot;^gradients/Add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/BroadcastGradientArgs/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid_grad/SigmoidGrad&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/BroadcastGradientArgs/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid_grad/SigmoidGrad&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/Sum_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/Reshape&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/Reshape&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/Reshape_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Switch_2_grad_1/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/AddN_12&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd_grad/BiasAddGrad&quot;\\n  op: &quot;BiasAddGrad&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split_grad/concat&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split_grad/concat&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd_grad/BiasAddGrad&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split_grad/concat&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split_grad/concat&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd_grad/BiasAddGrad&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd_grad/BiasAddGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split_grad/concat/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split/split_dim&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split_grad/concat/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split_grad/concat/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split/split_dim&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split_grad/concat/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split_grad/concat/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split/split_dim&quot;\\n  input: &quot;^gradients/Add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split/split_dim&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split_grad/concat/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split_grad/concat/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split/split_dim&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split_grad/concat/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split_grad/concat/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split/split_dim&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split_grad/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid_1_grad/SigmoidGrad&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Tanh_grad/TanhGrad&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid_2_grad/SigmoidGrad&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split_grad/concat/StackPop&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 4\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat&quot;\\n  input: &quot;^gradients/Add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/b_acc&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 64\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/b_acc_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/b_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/b_acc_2&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/b_acc_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/b_acc_2&quot;\\n  input: &quot;gradients/b_count_6&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/Add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/Switch:1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/b_acc_3&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd_grad/BiasAddGrad&quot;\\n  op: &quot;BiasAddGrad&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split_grad/concat&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split_grad/concat&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd_grad/BiasAddGrad&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split_grad/concat&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split_grad/concat&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd_grad/BiasAddGrad&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd_grad/BiasAddGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/Rank&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat/axis&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat/axis&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat/axis&quot;\\n  input: &quot;^gradients/Add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat/axis&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat/axis&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat/axis&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod&quot;\\n  op: &quot;FloorMod&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/Rank&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/TensorArrayReadV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/TensorArrayReadV3&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/TensorArrayReadV3&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/TensorArrayReadV3&quot;\\n  input: &quot;^gradients/Add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/TensorArrayReadV3&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/TensorArrayReadV3&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/TensorArrayReadV3&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN&quot;\\n  op: &quot;ShapeN&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/zeros_like/StackPop&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/ConcatOffset&quot;\\n  op: &quot;ConcatOffset&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN:1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/Slice&quot;\\n  op: &quot;Slice&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/ConcatOffset&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/Slice_1&quot;\\n  op: &quot;Slice&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/ConcatOffset:1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN:1&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/Slice&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/Slice_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/Slice&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/Slice&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/Slice_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/Slice_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/b_acc&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 36\\n          }\\n          dim {\\n            size: 64\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/b_acc_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/b_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/b_acc_2&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/b_acc_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/b_acc_2&quot;\\n  input: &quot;gradients/b_count_6&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/Add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/Switch:1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/b_acc_3&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/MatMul/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/MatMul/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/MatMul_1/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/MatMul_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/MatMul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/MatMul_1/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/MatMul_1/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat&quot;\\n  input: &quot;^gradients/Add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/MatMul_1/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/MatMul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/MatMul_1/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/MatMul_1/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/MatMul_1/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd/Enter_grad/b_acc&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 64\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd/Enter_grad/b_acc_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd/Enter_grad/b_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd/Enter_grad/b_acc_2&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd/Enter_grad/b_acc_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd/Enter_grad/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd/Enter_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd/Enter_grad/b_acc_2&quot;\\n  input: &quot;gradients/b_count_10&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd/Enter_grad/Add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd/Enter_grad/Switch:1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd/Enter_grad/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd/Enter_grad/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd/Enter_grad/b_acc_3&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd/Enter_grad/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArray_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3/Enter_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  op: &quot;TensorArrayGradV3&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3/Enter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3/Enter_1&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;source&quot;\\n    value {\\n      s: &quot;gradients&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3_grad/TensorArrayGrad/gradient_flow&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3/Enter_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3_grad/TensorArrayWrite/TensorArrayWriteV3&quot;\\n  op: &quot;TensorArrayWriteV3&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3_grad/TensorArrayGrad/gradient_flow&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_13&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/Select&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/Rank&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/mod/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat/axis&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/mod/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/mod/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat/axis&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/mod/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/mod/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat/axis&quot;\\n  input: &quot;^gradients/Add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat/axis&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/mod/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/mod/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat/axis&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/mod/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/mod/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat/axis&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/mod&quot;\\n  op: &quot;FloorMod&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/mod/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/Rank&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/TensorArrayReadV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/ShapeN/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/TensorArrayReadV3&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/ShapeN/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/ShapeN/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/TensorArrayReadV3&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/ShapeN/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/ShapeN/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/TensorArrayReadV3&quot;\\n  input: &quot;^gradients/Add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/TensorArrayReadV3&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/ShapeN/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/ShapeN/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/TensorArrayReadV3&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/ShapeN/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/ShapeN/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/TensorArrayReadV3&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/ShapeN&quot;\\n  op: &quot;ShapeN&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/ShapeN/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/zeros_like/StackPop&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/ConcatOffset&quot;\\n  op: &quot;ConcatOffset&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/mod&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/ShapeN&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/ShapeN:1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/Slice&quot;\\n  op: &quot;Slice&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/ConcatOffset&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/ShapeN&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/Slice_1&quot;\\n  op: &quot;Slice&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/ConcatOffset:1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/ShapeN:1&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/Slice&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/Slice_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/Slice&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/Slice&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/Slice_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/Slice_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul/Enter_grad/b_acc&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 36\\n          }\\n          dim {\\n            size: 64\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul/Enter_grad/b_acc_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul/Enter_grad/b_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul/Enter_grad/b_acc_2&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul/Enter_grad/b_acc_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul/Enter_grad/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul/Enter_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul/Enter_grad/b_acc_2&quot;\\n  input: &quot;gradients/b_count_10&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul/Enter_grad/Add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul/Enter_grad/Switch:1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul/Enter_grad/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul/Enter_grad/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul/Enter_grad/b_acc_3&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul/Enter_grad/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_14&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/b_acc_3&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd/Enter_grad/b_acc_3&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/b_acc_3&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1_grad/b_acc&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1_grad/b_acc_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1_grad/b_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1_grad/b_acc_2&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1_grad/b_acc_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1_grad/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1_grad/b_acc_2&quot;\\n  input: &quot;gradients/b_count_6&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1_grad/Add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1_grad/Switch:1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3_grad/TensorArrayWrite/TensorArrayWriteV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1_grad/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1_grad/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1_grad/b_acc_3&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1_grad/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Switch_3_grad_1/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/AddN_13&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArray_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3/Enter_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  op: &quot;TensorArrayGradV3&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3/Enter&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3/Enter_1&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;source&quot;\\n    value {\\n      s: &quot;gradients&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3_grad/TensorArrayGrad/gradient_flow&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3/Enter_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3_grad/TensorArrayWrite/TensorArrayWriteV3&quot;\\n  op: &quot;TensorArrayWriteV3&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3_grad/TensorArrayGrad/gradient_flow&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_15&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/Select&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_16&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/b_acc_3&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul/Enter_grad/b_acc_3&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/b_acc_3&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  op: &quot;TensorArrayGradV3&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArray_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1_grad/b_acc_3&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/TensorArray_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;source&quot;\\n    value {\\n      s: &quot;gradients&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGrad/gradient_flow&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1_grad/b_acc_3&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/TensorArray_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGatherV3&quot;\\n  op: &quot;TensorArrayGatherV3&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArrayUnstack/range&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGrad/gradient_flow&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;element_shape&quot;\\n    value {\\n      shape {\\n        unknown_rank: true\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1_grad/b_acc_3&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGatherV3&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGatherV3&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGatherV3&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1_grad/b_acc_3&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1_grad/b_acc_3&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter_1_grad/b_acc&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter_1_grad/b_acc_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter_1_grad/b_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter_1_grad/b_acc_2&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter_1_grad/b_acc_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter_1_grad/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter_1_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter_1_grad/b_acc_2&quot;\\n  input: &quot;gradients/b_count_10&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter_1_grad/Add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter_1_grad/Switch:1&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3_grad/TensorArrayWrite/TensorArrayWriteV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter_1_grad/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter_1_grad/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter_1_grad/b_acc_3&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter_1_grad/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Switch_3_grad_1/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/AddN_15&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  op: &quot;TensorArrayGradV3&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArray_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter_1_grad/b_acc_3&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/TensorArray_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;source&quot;\\n    value {\\n      s: &quot;gradients&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGrad/gradient_flow&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter_1_grad/b_acc_3&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/TensorArray_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGatherV3&quot;\\n  op: &quot;TensorArrayGatherV3&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArrayUnstack/range&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGrad/gradient_flow&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;element_shape&quot;\\n    value {\\n      shape {\\n        unknown_rank: true\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter_1_grad/b_acc_3&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGatherV3&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGatherV3&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/bw/bw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGatherV3&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter_1_grad/b_acc_3&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter_1_grad/b_acc_3&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/ReverseSequence_grad/ReverseSequence&quot;\\n  op: &quot;ReverseSequence&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/tuple/control_dependency&quot;\\n  input: &quot;encoder_inputs_length&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tlen&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;batch_dim&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;seq_dim&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_17&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/ReverseSequence_grad/ReverseSequence&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGatherV3&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/embedding_lookup_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT64\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\n\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\024\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/embedding_lookup_grad/ToInt32&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;gradients/embedding_lookup_grad/Shape&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/embedding_lookup_grad/Size&quot;\\n  op: &quot;Size&quot;\\n  input: &quot;encoder_inputs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/embedding_lookup_grad/ExpandDims/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/embedding_lookup_grad/ExpandDims&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;gradients/embedding_lookup_grad/Size&quot;\\n  input: &quot;gradients/embedding_lookup_grad/ExpandDims/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/embedding_lookup_grad/strided_slice/stack&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/embedding_lookup_grad/strided_slice/stack_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/embedding_lookup_grad/strided_slice/stack_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/embedding_lookup_grad/strided_slice&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;gradients/embedding_lookup_grad/ToInt32&quot;\\n  input: &quot;gradients/embedding_lookup_grad/strided_slice/stack&quot;\\n  input: &quot;gradients/embedding_lookup_grad/strided_slice/stack_1&quot;\\n  input: &quot;gradients/embedding_lookup_grad/strided_slice/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/embedding_lookup_grad/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/embedding_lookup_grad/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;gradients/embedding_lookup_grad/ExpandDims&quot;\\n  input: &quot;gradients/embedding_lookup_grad/strided_slice&quot;\\n  input: &quot;gradients/embedding_lookup_grad/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/embedding_lookup_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/AddN_17&quot;\\n  input: &quot;gradients/embedding_lookup_grad/concat&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/embedding_lookup_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;encoder_inputs&quot;\\n  input: &quot;gradients/embedding_lookup_grad/ExpandDims&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;gradients/embedding_lookup_1_grad/Reshape&quot;\\n  input: &quot;gradients/embedding_lookup_grad/Reshape&quot;\\n  input: &quot;gradients/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_1/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_1&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;gradients/embedding_lookup_1_grad/Reshape_1&quot;\\n  input: &quot;gradients/embedding_lookup_grad/Reshape_1&quot;\\n  input: &quot;gradients/concat_1/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;beta1_power/initial_value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.899999976158\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;beta1_power&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;beta1_power/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;beta1_power&quot;\\n  input: &quot;beta1_power/initial_value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;beta1_power/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;beta1_power&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;beta2_power/initial_value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.999000012875\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;beta2_power&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;beta2_power/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;beta2_power&quot;\\n  input: &quot;beta2_power/initial_value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;beta2_power/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;beta2_power&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Variable/Adam/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 10\\n          }\\n          dim {\\n            size: 20\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Variable/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 10\\n        }\\n        dim {\\n          size: 20\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Variable/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Variable/Adam&quot;\\n  input: &quot;Variable/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Variable/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Variable/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Variable/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 10\\n          }\\n          dim {\\n            size: 20\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Variable/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 10\\n        }\\n        dim {\\n          size: 20\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Variable/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Variable/Adam_1&quot;\\n  input: &quot;Variable/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Variable/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Variable/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Adam/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 36\\n          }\\n          dim {\\n            size: 64\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 36\\n        }\\n        dim {\\n          size: 64\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Adam&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 36\\n          }\\n          dim {\\n            size: 64\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 36\\n        }\\n        dim {\\n          size: 64\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Adam_1&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/bias/Adam/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 64\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/bias/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 64\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/bias/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/bias/Adam&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/bias/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/bias/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/bias/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/bias/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 64\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/bias/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 64\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/bias/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/bias/Adam_1&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/bias/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/bias/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/bias/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;memory_layer/kernel/Adam/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@memory_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 32\\n          }\\n          dim {\\n            size: 32\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;memory_layer/kernel/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@memory_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 32\\n        }\\n        dim {\\n          size: 32\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;memory_layer/kernel/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;memory_layer/kernel/Adam&quot;\\n  input: &quot;memory_layer/kernel/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@memory_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;memory_layer/kernel/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;memory_layer/kernel/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@memory_layer/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;memory_layer/kernel/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@memory_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 32\\n          }\\n          dim {\\n            size: 32\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;memory_layer/kernel/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@memory_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 32\\n        }\\n        dim {\\n          size: 32\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;memory_layer/kernel/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;memory_layer/kernel/Adam_1&quot;\\n  input: &quot;memory_layer/kernel/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@memory_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;memory_layer/kernel/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;memory_layer/kernel/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@memory_layer/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/kernel/Adam/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 84\\n          }\\n          dim {\\n            size: 128\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/kernel/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 84\\n        }\\n        dim {\\n          size: 128\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/kernel/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/kernel/Adam&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/kernel/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/kernel/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/kernel/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/kernel/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 84\\n          }\\n          dim {\\n            size: 128\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/kernel/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 84\\n        }\\n        dim {\\n          size: 128\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/kernel/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/kernel/Adam_1&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/kernel/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/kernel/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/kernel/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/bias/Adam/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 128\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/bias/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 128\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/bias/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/bias/Adam&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/bias/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/bias/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/bias/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/bias/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 128\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/bias/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 128\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/bias/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/bias/Adam_1&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/bias/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/bias/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/bias/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/attention_layer/kernel/Adam/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/attention_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 64\\n          }\\n          dim {\\n            size: 32\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/attention_layer/kernel/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/attention_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 64\\n        }\\n        dim {\\n          size: 32\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/attention_layer/kernel/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;decoder/attention_wrapper/attention_layer/kernel/Adam&quot;\\n  input: &quot;decoder/attention_wrapper/attention_layer/kernel/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/attention_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/attention_layer/kernel/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/attention_wrapper/attention_layer/kernel/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/attention_layer/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/attention_layer/kernel/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/attention_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 64\\n          }\\n          dim {\\n            size: 32\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/attention_layer/kernel/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/attention_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 64\\n        }\\n        dim {\\n          size: 32\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/attention_layer/kernel/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;decoder/attention_wrapper/attention_layer/kernel/Adam_1&quot;\\n  input: &quot;decoder/attention_wrapper/attention_layer/kernel/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/attention_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/attention_layer/kernel/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/attention_wrapper/attention_layer/kernel/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/attention_layer/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/kernel/Adam/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 32\\n          }\\n          dim {\\n            size: 10\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/kernel/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 32\\n        }\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/kernel/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;decoder/dense/kernel/Adam&quot;\\n  input: &quot;decoder/dense/kernel/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/kernel/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/dense/kernel/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/kernel/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 32\\n          }\\n          dim {\\n            size: 10\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/kernel/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 32\\n        }\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/kernel/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;decoder/dense/kernel/Adam_1&quot;\\n  input: &quot;decoder/dense/kernel/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/kernel/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/dense/kernel/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/bias/Adam/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 10\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/bias/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/bias/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;decoder/dense/bias/Adam&quot;\\n  input: &quot;decoder/dense/bias/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/bias/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/dense/bias/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/bias/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 10\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/bias/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/bias/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;decoder/dense/bias/Adam_1&quot;\\n  input: &quot;decoder/dense/bias/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/bias/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/dense/bias/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/learning_rate&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0010000000475\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/beta1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.899999976158\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/beta2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.999000012875\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/epsilon&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 9.99999993923e-09\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/Unique&quot;\\n  op: &quot;Unique&quot;\\n  input: &quot;gradients/concat_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;out_idx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Adam/update_Variable/Unique&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/strided_slice/stack&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/strided_slice/stack_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/strided_slice/stack_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/strided_slice&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;Adam/update_Variable/Shape&quot;\\n  input: &quot;Adam/update_Variable/strided_slice/stack&quot;\\n  input: &quot;Adam/update_Variable/strided_slice/stack_1&quot;\\n  input: &quot;Adam/update_Variable/strided_slice/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/UnsortedSegmentSum&quot;\\n  op: &quot;UnsortedSegmentSum&quot;\\n  input: &quot;gradients/concat&quot;\\n  input: &quot;Adam/update_Variable/Unique:1&quot;\\n  input: &quot;Adam/update_Variable/strided_slice&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tindices&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/sub/x&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;Adam/update_Variable/sub/x&quot;\\n  input: &quot;beta2_power/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/Sqrt&quot;\\n  op: &quot;Sqrt&quot;\\n  input: &quot;Adam/update_Variable/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Adam/learning_rate&quot;\\n  input: &quot;Adam/update_Variable/Sqrt&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/sub_1/x&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/sub_1&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;Adam/update_Variable/sub_1/x&quot;\\n  input: &quot;beta1_power/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/truediv&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;Adam/update_Variable/mul&quot;\\n  input: &quot;Adam/update_Variable/sub_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/sub_2/x&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/sub_2&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;Adam/update_Variable/sub_2/x&quot;\\n  input: &quot;Adam/beta1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Adam/update_Variable/UnsortedSegmentSum&quot;\\n  input: &quot;Adam/update_Variable/sub_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/mul_2&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Variable/Adam/read&quot;\\n  input: &quot;Adam/beta1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Variable/Adam&quot;\\n  input: &quot;Adam/update_Variable/mul_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/ScatterAdd&quot;\\n  op: &quot;ScatterAdd&quot;\\n  input: &quot;Variable/Adam&quot;\\n  input: &quot;Adam/update_Variable/Unique&quot;\\n  input: &quot;Adam/update_Variable/mul_1&quot;\\n  input: &quot;^Adam/update_Variable/Assign&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tindices&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/mul_3&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Adam/update_Variable/UnsortedSegmentSum&quot;\\n  input: &quot;Adam/update_Variable/UnsortedSegmentSum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/sub_3/x&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/sub_3&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;Adam/update_Variable/sub_3/x&quot;\\n  input: &quot;Adam/beta2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/mul_4&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Adam/update_Variable/mul_3&quot;\\n  input: &quot;Adam/update_Variable/sub_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/mul_5&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Variable/Adam_1/read&quot;\\n  input: &quot;Adam/beta2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/Assign_1&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Variable/Adam_1&quot;\\n  input: &quot;Adam/update_Variable/mul_5&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/ScatterAdd_1&quot;\\n  op: &quot;ScatterAdd&quot;\\n  input: &quot;Variable/Adam_1&quot;\\n  input: &quot;Adam/update_Variable/Unique&quot;\\n  input: &quot;Adam/update_Variable/mul_4&quot;\\n  input: &quot;^Adam/update_Variable/Assign_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tindices&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/Sqrt_1&quot;\\n  op: &quot;Sqrt&quot;\\n  input: &quot;Adam/update_Variable/ScatterAdd_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/mul_6&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Adam/update_Variable/truediv&quot;\\n  input: &quot;Adam/update_Variable/ScatterAdd&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;Adam/update_Variable/Sqrt_1&quot;\\n  input: &quot;Adam/epsilon&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/truediv_1&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;Adam/update_Variable/mul_6&quot;\\n  input: &quot;Adam/update_Variable/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/AssignSub&quot;\\n  op: &quot;AssignSub&quot;\\n  input: &quot;Variable&quot;\\n  input: &quot;Adam/update_Variable/truediv_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^Adam/update_Variable/AssignSub&quot;\\n  input: &quot;^Adam/update_Variable/ScatterAdd&quot;\\n  input: &quot;^Adam/update_Variable/ScatterAdd_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_bidirectional_rnn/fw/lstm_cell/kernel/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/kernel&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Adam&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Adam_1&quot;\\n  input: &quot;beta1_power/read&quot;\\n  input: &quot;beta2_power/read&quot;\\n  input: &quot;Adam/learning_rate&quot;\\n  input: &quot;Adam/beta1&quot;\\n  input: &quot;Adam/beta2&quot;\\n  input: &quot;Adam/epsilon&quot;\\n  input: &quot;gradients/AddN_16&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_bidirectional_rnn/fw/lstm_cell/bias/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/bias&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/bias/Adam&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/bias/Adam_1&quot;\\n  input: &quot;beta1_power/read&quot;\\n  input: &quot;beta2_power/read&quot;\\n  input: &quot;Adam/learning_rate&quot;\\n  input: &quot;Adam/beta1&quot;\\n  input: &quot;Adam/beta2&quot;\\n  input: &quot;Adam/epsilon&quot;\\n  input: &quot;gradients/AddN_14&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_memory_layer/kernel/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;memory_layer/kernel&quot;\\n  input: &quot;memory_layer/kernel/Adam&quot;\\n  input: &quot;memory_layer/kernel/Adam_1&quot;\\n  input: &quot;beta1_power/read&quot;\\n  input: &quot;beta2_power/read&quot;\\n  input: &quot;Adam/learning_rate&quot;\\n  input: &quot;Adam/beta1&quot;\\n  input: &quot;Adam/beta2&quot;\\n  input: &quot;Adam/epsilon&quot;\\n  input: &quot;gradients/LuongAttention/memory_layer/Tensordot/transpose_1_grad/transpose&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@memory_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_decoder/attention_wrapper/lstm_cell/kernel/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/kernel&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/kernel/Adam&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/kernel/Adam_1&quot;\\n  input: &quot;beta1_power/read&quot;\\n  input: &quot;beta2_power/read&quot;\\n  input: &quot;Adam/learning_rate&quot;\\n  input: &quot;Adam/beta1&quot;\\n  input: &quot;Adam/beta2&quot;\\n  input: &quot;Adam/epsilon&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/b_acc_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_decoder/attention_wrapper/lstm_cell/bias/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/bias&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/bias/Adam&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/bias/Adam_1&quot;\\n  input: &quot;beta1_power/read&quot;\\n  input: &quot;beta2_power/read&quot;\\n  input: &quot;Adam/learning_rate&quot;\\n  input: &quot;Adam/beta1&quot;\\n  input: &quot;Adam/beta2&quot;\\n  input: &quot;Adam/epsilon&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/b_acc_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_decoder/attention_wrapper/attention_layer/kernel/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;decoder/attention_wrapper/attention_layer/kernel&quot;\\n  input: &quot;decoder/attention_wrapper/attention_layer/kernel/Adam&quot;\\n  input: &quot;decoder/attention_wrapper/attention_layer/kernel/Adam_1&quot;\\n  input: &quot;beta1_power/read&quot;\\n  input: &quot;beta2_power/read&quot;\\n  input: &quot;Adam/learning_rate&quot;\\n  input: &quot;Adam/beta1&quot;\\n  input: &quot;Adam/beta2&quot;\\n  input: &quot;Adam/epsilon&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul/Enter_grad/b_acc_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/attention_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_decoder/dense/kernel/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;decoder/dense/kernel&quot;\\n  input: &quot;decoder/dense/kernel/Adam&quot;\\n  input: &quot;decoder/dense/kernel/Adam_1&quot;\\n  input: &quot;beta1_power/read&quot;\\n  input: &quot;beta2_power/read&quot;\\n  input: &quot;Adam/learning_rate&quot;\\n  input: &quot;Adam/beta1&quot;\\n  input: &quot;Adam/beta2&quot;\\n  input: &quot;Adam/epsilon&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul/Enter_grad/b_acc_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_decoder/dense/bias/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;decoder/dense/bias&quot;\\n  input: &quot;decoder/dense/bias/Adam&quot;\\n  input: &quot;decoder/dense/bias/Adam_1&quot;\\n  input: &quot;beta1_power/read&quot;\\n  input: &quot;beta2_power/read&quot;\\n  input: &quot;Adam/learning_rate&quot;\\n  input: &quot;Adam/beta1&quot;\\n  input: &quot;Adam/beta2&quot;\\n  input: &quot;Adam/epsilon&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/BiasAdd/Enter_grad/b_acc_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;beta1_power/read&quot;\\n  input: &quot;Adam/beta1&quot;\\n  input: &quot;^Adam/update_Variable/group_deps&quot;\\n  input: &quot;^Adam/update_bidirectional_rnn/fw/lstm_cell/kernel/ApplyAdam&quot;\\n  input: &quot;^Adam/update_bidirectional_rnn/fw/lstm_cell/bias/ApplyAdam&quot;\\n  input: &quot;^Adam/update_memory_layer/kernel/ApplyAdam&quot;\\n  input: &quot;^Adam/update_decoder/attention_wrapper/lstm_cell/kernel/ApplyAdam&quot;\\n  input: &quot;^Adam/update_decoder/attention_wrapper/lstm_cell/bias/ApplyAdam&quot;\\n  input: &quot;^Adam/update_decoder/attention_wrapper/attention_layer/kernel/ApplyAdam&quot;\\n  input: &quot;^Adam/update_decoder/dense/kernel/ApplyAdam&quot;\\n  input: &quot;^Adam/update_decoder/dense/bias/ApplyAdam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;beta1_power&quot;\\n  input: &quot;Adam/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;beta2_power/read&quot;\\n  input: &quot;Adam/beta2&quot;\\n  input: &quot;^Adam/update_Variable/group_deps&quot;\\n  input: &quot;^Adam/update_bidirectional_rnn/fw/lstm_cell/kernel/ApplyAdam&quot;\\n  input: &quot;^Adam/update_bidirectional_rnn/fw/lstm_cell/bias/ApplyAdam&quot;\\n  input: &quot;^Adam/update_memory_layer/kernel/ApplyAdam&quot;\\n  input: &quot;^Adam/update_decoder/attention_wrapper/lstm_cell/kernel/ApplyAdam&quot;\\n  input: &quot;^Adam/update_decoder/attention_wrapper/lstm_cell/bias/ApplyAdam&quot;\\n  input: &quot;^Adam/update_decoder/attention_wrapper/attention_layer/kernel/ApplyAdam&quot;\\n  input: &quot;^Adam/update_decoder/dense/kernel/ApplyAdam&quot;\\n  input: &quot;^Adam/update_decoder/dense/bias/ApplyAdam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/Assign_1&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;beta2_power&quot;\\n  input: &quot;Adam/mul_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^Adam/update_Variable/group_deps&quot;\\n  input: &quot;^Adam/update_bidirectional_rnn/fw/lstm_cell/kernel/ApplyAdam&quot;\\n  input: &quot;^Adam/update_bidirectional_rnn/fw/lstm_cell/bias/ApplyAdam&quot;\\n  input: &quot;^Adam/update_memory_layer/kernel/ApplyAdam&quot;\\n  input: &quot;^Adam/update_decoder/attention_wrapper/lstm_cell/kernel/ApplyAdam&quot;\\n  input: &quot;^Adam/update_decoder/attention_wrapper/lstm_cell/bias/ApplyAdam&quot;\\n  input: &quot;^Adam/update_decoder/attention_wrapper/attention_layer/kernel/ApplyAdam&quot;\\n  input: &quot;^Adam/update_decoder/dense/kernel/ApplyAdam&quot;\\n  input: &quot;^Adam/update_decoder/dense/bias/ApplyAdam&quot;\\n  input: &quot;^Adam/Assign&quot;\\n  input: &quot;^Adam/Assign_1&quot;\\n}\\nnode {\\n  name: &quot;init&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^Variable/Assign&quot;\\n  input: &quot;^bidirectional_rnn/fw/lstm_cell/kernel/Assign&quot;\\n  input: &quot;^bidirectional_rnn/fw/lstm_cell/bias/Assign&quot;\\n  input: &quot;^memory_layer/kernel/Assign&quot;\\n  input: &quot;^decoder/attention_wrapper/lstm_cell/kernel/Assign&quot;\\n  input: &quot;^decoder/attention_wrapper/lstm_cell/bias/Assign&quot;\\n  input: &quot;^decoder/attention_wrapper/attention_layer/kernel/Assign&quot;\\n  input: &quot;^decoder/dense/kernel/Assign&quot;\\n  input: &quot;^decoder/dense/bias/Assign&quot;\\n  input: &quot;^beta1_power/Assign&quot;\\n  input: &quot;^beta2_power/Assign&quot;\\n  input: &quot;^Variable/Adam/Assign&quot;\\n  input: &quot;^Variable/Adam_1/Assign&quot;\\n  input: &quot;^bidirectional_rnn/fw/lstm_cell/kernel/Adam/Assign&quot;\\n  input: &quot;^bidirectional_rnn/fw/lstm_cell/kernel/Adam_1/Assign&quot;\\n  input: &quot;^bidirectional_rnn/fw/lstm_cell/bias/Adam/Assign&quot;\\n  input: &quot;^bidirectional_rnn/fw/lstm_cell/bias/Adam_1/Assign&quot;\\n  input: &quot;^memory_layer/kernel/Adam/Assign&quot;\\n  input: &quot;^memory_layer/kernel/Adam_1/Assign&quot;\\n  input: &quot;^decoder/attention_wrapper/lstm_cell/kernel/Adam/Assign&quot;\\n  input: &quot;^decoder/attention_wrapper/lstm_cell/kernel/Adam_1/Assign&quot;\\n  input: &quot;^decoder/attention_wrapper/lstm_cell/bias/Adam/Assign&quot;\\n  input: &quot;^decoder/attention_wrapper/lstm_cell/bias/Adam_1/Assign&quot;\\n  input: &quot;^decoder/attention_wrapper/attention_layer/kernel/Adam/Assign&quot;\\n  input: &quot;^decoder/attention_wrapper/attention_layer/kernel/Adam_1/Assign&quot;\\n  input: &quot;^decoder/dense/kernel/Adam/Assign&quot;\\n  input: &quot;^decoder/dense/kernel/Adam_1/Assign&quot;\\n  input: &quot;^decoder/dense/bias/Adam/Assign&quot;\\n  input: &quot;^decoder/dense/bias/Adam_1/Assign&quot;\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.324218408367&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_graph(tf.get_default_graph().as_graph_def())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
