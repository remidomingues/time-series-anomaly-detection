{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM auto-encoder with bidirectional encoder and seq2seq decoder with attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "import helpers #for formatting data into batches and generating random sequence data\n",
    "\n",
    "tf.reset_default_graph() #Clears the default graph stack and resets the global default graph.\n",
    "sess = tf.InteractiveSession() #initializes a tensorflow session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.3.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PAD = 0 # padding\n",
    "BOS = 1 # Begin of sequence\n",
    "EOS = 2 # End of sequence\n",
    "\n",
    "vocab_size = 10 # max length of input sequence\n",
    "input_embedding_size = 20 # character length (vector)\n",
    "\n",
    "encoder_hidden_units = 16 # num neurons\n",
    "decoder_hidden_units = encoder_hidden_units * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#input placehodlers\n",
    "encoder_inputs = tf.placeholder(shape=(None, None), dtype=tf.int32, name='encoder_inputs')\n",
    "#contains the lengths for each of the sequence in the batch, we will pad so all the same\n",
    "#if you don't want to pad, check out dynamic memory networks to input variable length sequences\n",
    "encoder_inputs_length = tf.placeholder(shape=(None,), dtype=tf.int32, name='encoder_inputs_length')\n",
    "decoder_targets = tf.placeholder(shape=(None, None), dtype=tf.int32, name='decoder_targets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embeddings = tf.Variable(tf.random_uniform([vocab_size, input_embedding_size], -1.0, 1.0), dtype=tf.float32)\n",
    "\n",
    "#this thing could get huge in a real world application\n",
    "encoder_inputs_embedded = tf.nn.embedding_lookup(embeddings, encoder_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'embedding_lookup:0' shape=(?, ?, 20) dtype=float32>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_inputs_embedded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder\n",
    "Bidirectional encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.ops.rnn_cell import LSTMCell, LSTMStateTuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_cell =  LSTMCell(encoder_hidden_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "((encoder_fw_outputs,\n",
    "  encoder_bw_outputs),\n",
    " (encoder_fw_final_state,\n",
    "  encoder_bw_final_state)) = (\n",
    "    tf.nn.bidirectional_dynamic_rnn(cell_fw=encoder_cell,\n",
    "                                    cell_bw=encoder_cell,\n",
    "                                    inputs=encoder_inputs_embedded,\n",
    "                                    sequence_length=encoder_inputs_length,\n",
    "                                    dtype=tf.float32, time_major=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'bidirectional_rnn/fw/fw/TensorArrayStack/TensorArrayGatherV3:0' shape=(?, ?, 16) dtype=float32>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_fw_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'ReverseSequence:0' shape=(?, ?, 16) dtype=float32>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_bw_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMStateTuple(c=<tf.Tensor 'bidirectional_rnn/fw/fw/while/Exit_2:0' shape=(?, 16) dtype=float32>, h=<tf.Tensor 'bidirectional_rnn/fw/fw/while/Exit_3:0' shape=(?, 16) dtype=float32>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_fw_final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMStateTuple(c=<tf.Tensor 'bidirectional_rnn/bw/bw/while/Exit_2:0' shape=(?, 16) dtype=float32>, h=<tf.Tensor 'bidirectional_rnn/bw/bw/while/Exit_3:0' shape=(?, 16) dtype=float32>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_bw_final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Concatenates tensors along one dimension.\n",
    "encoder_outputs = tf.concat((encoder_fw_outputs, encoder_bw_outputs), 2)\n",
    "\n",
    "#letters h and c are commonly used to denote \"output value\" and \"cell state\". \n",
    "#http://colah.github.io/posts/2015-08-Understanding-LSTMs/ \n",
    "#Those tensors represent combined internal state of the cell, and should be passed together. \n",
    "\n",
    "encoder_final_state_c = tf.concat(\n",
    "    (encoder_fw_final_state.c, encoder_bw_final_state.c), 1)\n",
    "\n",
    "encoder_final_state_h = tf.concat(\n",
    "    (encoder_fw_final_state.h, encoder_bw_final_state.h), 1)\n",
    "\n",
    "#TF Tuple used by LSTM Cells for state_size, zero_state, and output state.\n",
    "encoder_final_state = LSTMStateTuple(\n",
    "    c=encoder_final_state_c,\n",
    "    h=encoder_final_state_h\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concat:0' shape=(?, ?, 32) dtype=float32>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMStateTuple(c=<tf.Tensor 'concat_1:0' shape=(?, 32) dtype=float32>, h=<tf.Tensor 'concat_2:0' shape=(?, 32) dtype=float32>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_final_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoder\n",
    "Common part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_cell = LSTMCell(decoder_hidden_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_max_time, batch_size = tf.unstack(tf.shape(encoder_inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_lengths = encoder_inputs_length + 2\n",
    "# +2 additional steps (PAD token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'embedding_lookup_1:0' shape=(?, ?, 20) dtype=float32>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length = encoder_max_time + 2\n",
    "\n",
    "decoder_inputs = tf.ones([max_length, batch_size], dtype=tf.int32)\n",
    "decoder_inputs_embedded = tf.nn.embedding_lookup(embeddings, decoder_inputs)\n",
    "decoder_inputs_embedded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic_rnn decoder\n",
    "For comparison purpose (no attention mechanisms)\n",
    "\n",
    "You can jump direclty to the seq2seq decoder part without running those cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "((decoder_outputs),\n",
    " (decoder_state)) = (\n",
    "    tf.nn.dynamic_rnn(cell=decoder_cell,\n",
    "                      inputs=decoder_inputs_embedded, # Make sense for training but how to infer?\n",
    "                      sequence_length=decoder_lengths,\n",
    "                      initial_state=encoder_final_state,\n",
    "                      dtype=tf.float32, time_major=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "decoder_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#manually specifying since we are going to implement attention details for the decoder in a sec\n",
    "#weights\n",
    "W = tf.Variable(tf.random_uniform([decoder_hidden_units, vocab_size], -1, 1), dtype=tf.float32)\n",
    "#bias\n",
    "b = tf.Variable(tf.zeros([vocab_size]), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#to convert output to human readable prediction\n",
    "#we will reshape output tensor\n",
    "\n",
    "#Unpacks the given dimension of a rank-R tensor into rank-(R-1) tensors.\n",
    "#reduces dimensionality\n",
    "decoder_max_steps, decoder_batch_size, decoder_dim = tf.unstack(tf.shape(decoder_outputs))\n",
    "#flettened output tensor\n",
    "decoder_outputs_flat = tf.reshape(decoder_outputs, (-1, decoder_dim))\n",
    "#pass flattened tensor through decoder\n",
    "decoder_logits_flat = tf.add(tf.matmul(decoder_outputs_flat, W), b)\n",
    "#prediction vals\n",
    "decoder_logits = tf.reshape(decoder_logits_flat, (decoder_max_steps, decoder_batch_size, vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "decoder_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#final prediction\n",
    "decoder_prediction = tf.argmax(decoder_logits, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seq2seq decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.layers import core as layers_core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# attention_states: [batch_size, max_time, num_units]\n",
    "attention_states = tf.transpose(encoder_outputs, [1, 0, 2])\n",
    "\n",
    "# Create an attention mechanism\n",
    "attention_mechanism = tf.contrib.seq2seq.LuongAttention(\n",
    "    num_units=decoder_hidden_units, \n",
    "    memory=attention_states,\n",
    "    #memory_sequence_length=None # default value\n",
    ")\n",
    "\n",
    "decoder_cell = tf.contrib.seq2seq.AttentionWrapper(\n",
    "    cell=decoder_cell, \n",
    "    attention_mechanism=attention_mechanism,\n",
    "    attention_layer_size=decoder_hidden_units)\n",
    "\n",
    "attention_zero = decoder_cell.zero_state(batch_size=batch_size, dtype=tf.float32)\n",
    "encoder_final_state_attention = attention_zero.clone(cell_state=encoder_final_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dropout wrapper prototype, use in case of overfitting\n",
    "# https://www.tensorflow.org/versions/r1.3/api_docs/python/tf/contrib/rnn/DropoutWrapper\n",
    "tf.contrib.rnn.DropoutWrapper(\n",
    "    cell,\n",
    "    input_keep_prob=1.0,\n",
    "    output_keep_prob=1.0,\n",
    "    state_keep_prob=1.0,\n",
    "    variational_recurrent=False,\n",
    "    input_size=None,\n",
    "    dtype=None,\n",
    "    seed=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "projection_layer = layers_core.Dense(vocab_size, use_bias=True)\n",
    "\n",
    "mode = 'infer'\n",
    "\n",
    "# Helper\n",
    "if mode == 'train':\n",
    "    helper = tf.contrib.seq2seq.TrainingHelper(\n",
    "        inputs=decoder_inputs_embedded, \n",
    "        sequence_length=decoder_lengths, \n",
    "        time_major=True)\n",
    "\n",
    "elif mode == 'infer':\n",
    "    helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(\n",
    "          embedding=embeddings,\n",
    "          start_tokens=tf.tile([BOS], [batch_size]),\n",
    "          end_token=EOS)\n",
    "\n",
    "# Decoder\n",
    "decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "    cell=decoder_cell, \n",
    "    helper=helper, \n",
    "    initial_state=encoder_final_state_attention, # to use without attention change to 'encoder_final_state'\n",
    "    output_layer=projection_layer)\n",
    "\n",
    "# Dynamic decoding\n",
    "(decoder_outputs, final_state, final_sequence_lengths) = tf.contrib.seq2seq.dynamic_decode(\n",
    "    decoder,\n",
    "    output_time_major=True\n",
    ")\n",
    "decoder_logits = decoder_outputs.rnn_output\n",
    "decoder_prediction = decoder_outputs.sample_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BasicDecoderOutput(rnn_output=<tf.Tensor 'decoder/TensorArrayStack/TensorArrayGatherV3:0' shape=(?, ?, 10) dtype=float32>, sample_id=<tf.Tensor 'decoder/TensorArrayStack_1/TensorArrayGatherV3:0' shape=(?, ?) dtype=int32>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#cross entropy loss\n",
    "#one hot encode the target values so we don't rank just differentiate\n",
    "stepwise_cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "    labels=tf.one_hot(decoder_targets, depth=vocab_size, dtype=tf.float32),\n",
    "    logits=decoder_logits,\n",
    ")\n",
    "\n",
    "#loss function\n",
    "loss = tf.reduce_mean(stepwise_cross_entropy)\n",
    "#train it \n",
    "train_op = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load toy dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head of the batch:\n",
      "[6, 6, 9, 5, 4, 4]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "\n",
    "batches = helpers.random_sequences(length_from=3, length_to=8,\n",
    "                                   vocab_lower=3, vocab_upper=10,\n",
    "                                   batch_size=batch_size)\n",
    "\n",
    "print('Head of the batch:')\n",
    "for seq in next(batches)[:10]:\n",
    "    print(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def next_feed():\n",
    "    batch = next(batches)\n",
    "    encoder_inputs_, encoder_input_lengths_ = helpers.batch(\n",
    "        [[BOS] + (sequence) + [EOS] for sequence in batch]\n",
    "    )\n",
    "    decoder_targets_, _ = helpers.batch(\n",
    "        [[BOS] + (sequence) + [EOS] + [PAD] * 2 for sequence in batch]\n",
    "    )\n",
    "    return {\n",
    "        encoder_inputs: encoder_inputs_,\n",
    "        encoder_inputs_length: encoder_input_lengths_,\n",
    "        decoder_targets: decoder_targets_,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_track = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_model(max_batches=2001, batches_in_epoch=500):\n",
    "    try:\n",
    "        for batch in range(max_batches):\n",
    "            fd = next_feed()\n",
    "            _, l = sess.run([train_op, loss], fd)\n",
    "            loss_track.append(l)\n",
    "\n",
    "            if batch == 0 or batch % batches_in_epoch == 0:\n",
    "                predict_, l = sess.run([decoder_prediction, loss], fd)\n",
    "                print('batch {}'.format(batch))\n",
    "                print('  minibatch loss: {}'.format(l))\n",
    "                for i, (inp, pred) in enumerate(zip(fd[encoder_inputs].T, predict_.T)):\n",
    "                    print('  sample {}:'.format(i + 1))\n",
    "                    print('    input     > {}'.format(inp))\n",
    "                    print('    predicted > {}'.format(pred))\n",
    "                    if i >= 2:\n",
    "                        break\n",
    "                print\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print('training interrupted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model\n",
    "Possible to skip those cells and load a model checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0\n",
      "  minibatch loss: 2.26522660255\n",
      "  sample 1:\n",
      "    input     > [1 9 4 8 9 4 5 8 6 2]\n",
      "    predicted > [9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "  sample 2:\n",
      "    input     > [1 7 5 9 2 0 0 0 0 0]\n",
      "    predicted > [9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "  sample 3:\n",
      "    input     > [1 8 5 6 7 4 8 7 7 2]\n",
      "    predicted > [7 9 9 9 9 9 9 9 9 9 9 9]\n",
      "\n",
      "batch 500\n",
      "  minibatch loss: 0.0741452649236\n",
      "  sample 1:\n",
      "    input     > [1 9 5 9 6 5 2 0 0 0]\n",
      "    predicted > [1 9 5 9 6 5 2 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [1 6 9 4 6 6 5 2 0 0]\n",
      "    predicted > [1 6 9 4 6 6 5 2 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [1 9 4 8 5 7 8 5 5 2]\n",
      "    predicted > [1 9 4 8 5 7 8 5 5 2 0 0]\n",
      "\n",
      "batch 1000\n",
      "  minibatch loss: 0.00243589351885\n",
      "  sample 1:\n",
      "    input     > [1 9 9 3 7 8 2 0 0 0]\n",
      "    predicted > [1 9 9 3 7 8 2 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [1 5 7 3 9 2 0 0 0 0]\n",
      "    predicted > [1 5 7 3 9 2 0 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [1 4 6 4 9 4 4 9 3 2]\n",
      "    predicted > [1 4 6 4 9 4 4 9 3 2 0 0]\n",
      "\n",
      "batch 1500\n",
      "  minibatch loss: 0.000884695269633\n",
      "  sample 1:\n",
      "    input     > [1 7 5 7 3 8 2 0 0 0]\n",
      "    predicted > [1 7 5 7 3 8 2 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [1 4 3 3 5 7 2 0 0 0]\n",
      "    predicted > [1 4 3 3 5 7 2 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [1 8 9 8 3 7 9 6 2 0]\n",
      "    predicted > [1 8 9 8 3 7 9 6 2 0 0 0]\n",
      "\n",
      "batch 2000\n",
      "  minibatch loss: 0.000712240871508\n",
      "  sample 1:\n",
      "    input     > [1 3 9 3 5 7 3 7 2 0]\n",
      "    predicted > [1 3 9 3 5 7 3 7 2 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [1 9 6 3 6 8 2 0 0 0]\n",
      "    predicted > [1 9 6 3 6 8 2 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [1 7 4 8 4 7 8 4 2 0]\n",
      "    predicted > [1 7 4 8 4 7 8 4 2 0 0 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Remember that '1' is the BOS tag and '2' the EOS tag, not predicted outputs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.0009 after 128064 examples (batch_size=64)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAECCAYAAAAciLtvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x122c282d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.yscale('log')\n",
    "plt.plot(loss_track)\n",
    "print('loss {:.4f} after {} examples (batch_size={})'.format(loss_track[-1], len(loss_track)*batch_size, batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model (create a checkpoint under the 'checkpoints' directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'checkpoints/seq2seq.ckpt'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "saver.save(sess, \"checkpoints/seq2seq.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load a checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/seq2seq.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/seq2seq.ckpt\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, \"checkpoints/seq2seq.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'encoder_inputs:0' shape=(?, ?) dtype=int32>, <tf.Tensor 'encoder_inputs_length:0' shape=(?,) dtype=int32>]\n"
     ]
    }
   ],
   "source": [
    "fd = next_feed()\n",
    "fd.pop(decoder_targets, None)\n",
    "print(fd.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 3 8 5 6 3 5 2]\n",
      "[1 3 8 5 5 6 3 3 5 2]\n"
     ]
    }
   ],
   "source": [
    "# Just a simple test\n",
    "fd = next_feed()\n",
    "fd.pop(decoder_targets, None)\n",
    "\n",
    "pred = sess.run(decoder_prediction, fd)\n",
    "f = fd[encoder_inputs].T\n",
    "\n",
    "print(f[0])\n",
    "print(pred.T[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstruction accuracy 85.7143 %\n"
     ]
    }
   ],
   "source": [
    "# Simple reconstruction accuracy\n",
    "import difflib\n",
    "\n",
    "def reconstruction_accurary(target, prediction):\n",
    "    target = \"\".join(str(x) for x in target[1:-1].tolist()) # Discard BOS and EOS\n",
    "    prediction = \"\".join(str(x) for x in prediction[1:-1].tolist())\n",
    "    seq = difflib.SequenceMatcher(None, target, prediction)\n",
    "    return seq.ratio()*100\n",
    "    print('Reconstruction accuracy {:.4f} %'.format(seq.ratio()*100))\n",
    "    \n",
    "print('Reconstruction accuracy {:.4f} %'.format(reconstruction_accurary(f[0], pred.T[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fds, enc_outs, dec_embs, preds = [], [], [], []\n",
    "\n",
    "for i in range(10):\n",
    "    fd = next_feed()\n",
    "    fd.pop(decoder_targets, None)\n",
    "    fds.append(fd[encoder_inputs].T[0])\n",
    "\n",
    "    enc_out, dec_emb, pred = sess.run([encoder_outputs, decoder_inputs_embedded, decoder_prediction], fd)\n",
    "    enc_outs.append(enc_out)\n",
    "    dec_embs.append(dec_emb)\n",
    "    preds.append(pred.T[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0:\n",
      "[1 9 9 8 5 3 9 9 2]\n",
      "[1 9 9 8 5 5 3 9 9 9 2]\n",
      "Reconstruction accuracy 87.5000 %\n",
      "(9, 1, 32)\n",
      "(11, 1, 20)\n",
      "\n",
      "Sample 1:\n",
      "[1 9 5 9 5 8 2]\n",
      "[1 9 5 9 9 8 8 2]\n",
      "Reconstruction accuracy 72.7273 %\n",
      "(7, 1, 32)\n",
      "(9, 1, 20)\n",
      "\n",
      "Sample 2:\n",
      "[1 5 9 5 2]\n",
      "[1 5 9 5 2]\n",
      "Reconstruction accuracy 100.0000 %\n",
      "(5, 1, 32)\n",
      "(7, 1, 20)\n",
      "\n",
      "Sample 3:\n",
      "[1 4 5 4 7 6 9 6 2]\n",
      "[1 4 4 4 4 7 6 9 6 6 2]\n",
      "Reconstruction accuracy 75.0000 %\n",
      "(9, 1, 32)\n",
      "(11, 1, 20)\n",
      "\n",
      "Sample 4:\n",
      "[1 5 5 4 2]\n",
      "[1 5 5 4 4 2]\n",
      "Reconstruction accuracy 85.7143 %\n",
      "(5, 1, 32)\n",
      "(7, 1, 20)\n",
      "\n",
      "Sample 5:\n",
      "[1 3 8 4 4 9 4 2]\n",
      "[1 3 8 4 4 4 9 4 2]\n",
      "Reconstruction accuracy 92.3077 %\n",
      "(8, 1, 32)\n",
      "(10, 1, 20)\n",
      "\n",
      "Sample 6:\n",
      "[1 5 8 3 5 7 5 2]\n",
      "[1 5 8 8 3 5 7 5 5 2]\n",
      "Reconstruction accuracy 85.7143 %\n",
      "(8, 1, 32)\n",
      "(10, 1, 20)\n",
      "\n",
      "Sample 7:\n",
      "[1 6 5 5 9 7 9 8 6 2]\n",
      "[1 6 5 5 9 7 7 9 8 6 6 6 2]\n",
      "Reconstruction accuracy 84.2105 %\n",
      "(10, 1, 32)\n",
      "(12, 1, 20)\n",
      "\n",
      "Sample 8:\n",
      "[1 5 6 4 4 8 9 4 4 2]\n",
      "[1 5 6 4 4 8 8 4 4 4 4 4 2]\n",
      "Reconstruction accuracy 73.6842 %\n",
      "(10, 1, 32)\n",
      "(12, 1, 20)\n",
      "\n",
      "Sample 9:\n",
      "[1 9 6 4 5 8 7 7 5 2]\n",
      "[1 9 6 4 5 8 8 7 7 5 5 2]\n",
      "Reconstruction accuracy 88.8889 %\n",
      "(10, 1, 32)\n",
      "(12, 1, 20)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(preds)):\n",
    "    print(\"Sample \" + str(i) + \":\")\n",
    "    print(fds[i])\n",
    "    print(preds[i])\n",
    "    print('Reconstruction accuracy {:.4f} %'.format(reconstruction_accurary(fds[i], preds[i])))\n",
    "    print(enc_outs[i].shape) # With BOS and EOS\n",
    "    print(dec_embs[i].shape) # With BOS, EOS and PAD\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# The decoder inputs embedding is the same despite the different sequence, can't be used for vizualisation\n",
    "print(np.all([np.all(np.isclose(dec_embs[0][0], dec_embs[0][i])) for i in range(1, len(dec_embs[0]))]))\n",
    "  \n",
    "# As the opposite the encoder outputs are different\n",
    "print(np.all([np.all(np.isclose(enc_outs[0][0], enc_outs[0][i])) for i in range(1, len(enc_outs[0]))]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize graph\n",
    "\n",
    "Copy from https://stackoverflow.com/questions/38189119/simple-way-to-visualize-a-tensorflow-graph-in-jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "def strip_consts(graph_def, max_const_size=32):\n",
    "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
    "    strip_def = tf.GraphDef()\n",
    "    for n0 in graph_def.node:\n",
    "        n = strip_def.node.add() \n",
    "        n.MergeFrom(n0)\n",
    "        if n.op == 'Const':\n",
    "            tensor = n.attr['value'].tensor\n",
    "            size = len(tensor.tensor_content)\n",
    "            if size > max_const_size:\n",
    "                tensor.tensor_content = \"<stripped %d bytes>\"%size\n",
    "    return strip_def\n",
    "\n",
    "def show_graph(graph_def, max_const_size=32):\n",
    "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
    "    if hasattr(graph_def, 'as_graph_def'):\n",
    "        graph_def = graph_def.as_graph_def()\n",
    "    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
    "    code = \"\"\"\n",
    "        <script>\n",
    "          function load() {{\n",
    "            document.getElementById(\"{id}\").pbtxt = {data};\n",
    "          }}\n",
    "        </script>\n",
    "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
    "        <div style=\"height:600px\">\n",
    "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
    "        </div>\n",
    "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
    "\n",
    "    iframe = \"\"\"\n",
    "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n",
    "    \"\"\".format(code.replace('\"', '&quot;'))\n",
    "    display(HTML(iframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.324218408367&quot;).pbtxt = 'node {\\n  name: &quot;encoder_inputs&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n        dim {\\n          size: -1\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;encoder_inputs_length&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder_targets&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n        dim {\\n          size: -1\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\n\\\\000\\\\000\\\\000\\\\024\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;random_uniform/max&quot;\\n  input: &quot;random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;random_uniform/RandomUniform&quot;\\n  input: &quot;random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;random_uniform/mul&quot;\\n  input: &quot;random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Variable&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 10\\n        }\\n        dim {\\n          size: 20\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Variable/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Variable&quot;\\n  input: &quot;random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Variable/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Variable&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;embedding_lookup&quot;\\n  op: &quot;Gather&quot;\\n  input: &quot;Variable/read&quot;\\n  input: &quot;encoder_inputs&quot;\\n  attr {\\n    key: &quot;Tindices&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tparams&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_indices&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/sequence_length&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;encoder_inputs_length&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;embedding_lookup&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/strided_slice/stack&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/strided_slice/stack_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/strided_slice/stack_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/strided_slice&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/Shape&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/strided_slice/stack&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/strided_slice/stack_1&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/strided_slice/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/ExpandDims/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/ExpandDims&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/strided_slice&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/ExpandDims/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 16\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/ExpandDims&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/Const&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/ExpandDims_1/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/ExpandDims_1&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/strided_slice&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/ExpandDims_1/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 16\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/zeros/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/zeros&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/concat&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/zeros/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/ExpandDims_2/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/ExpandDims_2&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/strided_slice&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/ExpandDims_2/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/Const_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 16\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/concat_1/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/concat_1&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/ExpandDims_2&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/Const_2&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/concat_1/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/ExpandDims_3/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/ExpandDims_3&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/strided_slice&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/ExpandDims_3/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/Const_3&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 16\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/zeros_1/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/zeros_1&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/concat_1&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/zeros_1/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/fw/sequence_length&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/stack&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/strided_slice&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/Equal&quot;\\n  op: &quot;Equal&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/Shape_1&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/stack&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/All&quot;\\n  op: &quot;All&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/Equal&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/Const&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/Assert/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;Expected shape for Tensor bidirectional_rnn/fw/sequence_length:0 is &quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/Assert/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot; but saw shape: &quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/Assert/Assert/data_0&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;Expected shape for Tensor bidirectional_rnn/fw/sequence_length:0 is &quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/Assert/Assert/data_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot; but saw shape: &quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/Assert/Assert&quot;\\n  op: &quot;Assert&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/All&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/Assert/Assert/data_0&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/stack&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/Assert/Assert/data_2&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      list {\\n        type: DT_STRING\\n        type: DT_INT32\\n        type: DT_STRING\\n        type: DT_INT32\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;summarize&quot;\\n    value {\\n      i: 3\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/CheckSeqLen&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;bidirectional_rnn/fw/sequence_length&quot;\\n  input: &quot;^bidirectional_rnn/fw/fw/Assert/Assert&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/Shape_2&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;embedding_lookup&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/strided_slice_1/stack&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/strided_slice_1/stack_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/strided_slice_1/stack_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/strided_slice_1&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/Shape_2&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/strided_slice_1/stack&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/strided_slice_1/stack_1&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/strided_slice_1/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/Shape_3&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;embedding_lookup&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/strided_slice_2/stack&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/strided_slice_2/stack_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/strided_slice_2/stack_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/strided_slice_2&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/Shape_3&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/strided_slice_2/stack&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/strided_slice_2/stack_1&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/strided_slice_2/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/ExpandDims/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/ExpandDims&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/strided_slice_2&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/ExpandDims/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 16\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/ExpandDims&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/Const_1&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/zeros/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/zeros&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/concat&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/zeros/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/Const_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/Min&quot;\\n  op: &quot;Min&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/CheckSeqLen&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/Const_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/Const_3&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/Max&quot;\\n  op: &quot;Max&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/CheckSeqLen&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/Const_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/time&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/TensorArray&quot;\\n  op: &quot;TensorArrayV3&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/strided_slice_1&quot;\\n  attr {\\n    key: &quot;clear_after_read&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;dynamic_size&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;element_shape&quot;\\n    value {\\n      shape {\\n        unknown_rank: true\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;tensor_array_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/dynamic_rnn/output_0&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/TensorArray_1&quot;\\n  op: &quot;TensorArrayV3&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/strided_slice_1&quot;\\n  attr {\\n    key: &quot;clear_after_read&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;dynamic_size&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;element_shape&quot;\\n    value {\\n      shape {\\n        unknown_rank: true\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;tensor_array_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/dynamic_rnn/input_0&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/TensorArrayUnstack/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;embedding_lookup&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/TensorArrayUnstack/strided_slice/stack&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/TensorArrayUnstack/strided_slice/stack_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/TensorArrayUnstack/strided_slice/stack_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/TensorArrayUnstack/strided_slice&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArrayUnstack/Shape&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArrayUnstack/strided_slice/stack&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArrayUnstack/strided_slice/stack_1&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArrayUnstack/strided_slice/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/TensorArrayUnstack/range/start&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/TensorArrayUnstack/range/delta&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/TensorArrayUnstack/range&quot;\\n  op: &quot;Range&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArrayUnstack/range/start&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArrayUnstack/strided_slice&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArrayUnstack/range/delta&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3&quot;\\n  op: &quot;TensorArrayScatterV3&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArray_1&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArrayUnstack/range&quot;\\n  input: &quot;embedding_lookup&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArray_1:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/time&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/Enter_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArray:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/Enter_2&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/Enter_3&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/LSTMCellZeroState/zeros_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/Merge&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Enter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/Merge_1&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Enter_1&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/NextIteration_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/Merge_2&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Enter_2&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/NextIteration_2&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/Merge_3&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Enter_3&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/NextIteration_3&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/Less/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/strided_slice_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/Less&quot;\\n  op: &quot;Less&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Merge&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Less/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/LoopCond&quot;\\n  op: &quot;LoopCond&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Less&quot;\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Merge&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/LoopCond&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/Merge&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/Switch_1&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Merge_1&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/LoopCond&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/Merge_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/Switch_2&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Merge_2&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/LoopCond&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/Merge_2&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/Switch_3&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Merge_3&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/LoopCond&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/Merge_3&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/Identity&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Switch:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/Identity_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Switch_1:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/Identity_2&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Switch_2:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/Identity_3&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Switch_3:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArray_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/TensorArrayReadV3&quot;\\n  op: &quot;TensorArrayReadV3&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Identity&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;$\\\\000\\\\000\\\\000@\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.244948968291\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.244948968291\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform/max&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform/mul&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/kernel&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 36\\n        }\\n        dim {\\n          size: 64\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/kernel&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/kernel/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/kernel&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^bidirectional_rnn/fw/fw/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/TensorArrayReadV3&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Identity_3&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/bias/Initializer/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 64\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/bias&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 64\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/bias&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/bias/Initializer/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd&quot;\\n  op: &quot;BiasAdd&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^bidirectional_rnn/fw/fw/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 4\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split/split_dim&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^bidirectional_rnn/fw/fw/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split&quot;\\n  op: &quot;Split&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split/split_dim&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;num_split&quot;\\n    value {\\n      i: 4\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add/y&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^bidirectional_rnn/fw/fw/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split:2&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid&quot;\\n  op: &quot;Sigmoid&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Identity_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid_1&quot;\\n  op: &quot;Sigmoid&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Tanh&quot;\\n  op: &quot;Tanh&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid_1&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Tanh&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid_2&quot;\\n  op: &quot;Sigmoid&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split:3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Tanh_1&quot;\\n  op: &quot;Tanh&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid_2&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Tanh_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/GreaterEqual/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/CheckSeqLen&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/GreaterEqual&quot;\\n  op: &quot;GreaterEqual&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Identity&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/GreaterEqual/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/Select/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/Select&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/GreaterEqual&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Select/Enter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/GreaterEqual_1&quot;\\n  op: &quot;GreaterEqual&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Identity&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/GreaterEqual/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/Select_1&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/GreaterEqual_1&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Identity_2&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/GreaterEqual_2&quot;\\n  op: &quot;GreaterEqual&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Identity&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/GreaterEqual/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/Select_2&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/GreaterEqual_2&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Identity_3&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArray&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3&quot;\\n  op: &quot;TensorArrayWriteV3&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3/Enter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Identity&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Select&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Identity_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/add/y&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^bidirectional_rnn/fw/fw/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Identity&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/add/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/NextIteration_1&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/NextIteration_2&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Select_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/NextIteration_3&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Select_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/Exit&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/Exit_1&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Switch_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/Exit_2&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Switch_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/Exit_3&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Switch_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/TensorArrayStack/TensorArraySizeV3&quot;\\n  op: &quot;TensorArraySizeV3&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArray&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Exit_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/TensorArray&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/TensorArrayStack/range/start&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/TensorArray&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/TensorArrayStack/range/delta&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/TensorArray&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/TensorArrayStack/range&quot;\\n  op: &quot;Range&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArrayStack/range/start&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArrayStack/TensorArraySizeV3&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArrayStack/range/delta&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/TensorArray&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/TensorArrayStack/TensorArrayGatherV3&quot;\\n  op: &quot;TensorArrayGatherV3&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArray&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArrayStack/range&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Exit_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/TensorArray&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;element_shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n        dim {\\n          size: 16\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/Const_4&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 16\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/ReverseSequence&quot;\\n  op: &quot;ReverseSequence&quot;\\n  input: &quot;embedding_lookup&quot;\\n  input: &quot;encoder_inputs_length&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tlen&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;batch_dim&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;seq_dim&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/sequence_length&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;encoder_inputs_length&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/bw/ReverseSequence&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/strided_slice/stack&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/strided_slice/stack_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/strided_slice/stack_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/strided_slice&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/Shape&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/strided_slice/stack&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/strided_slice/stack_1&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/strided_slice/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/ExpandDims/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/ExpandDims&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/strided_slice&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/ExpandDims/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 16\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/ExpandDims&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/Const&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/ExpandDims_1/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/ExpandDims_1&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/strided_slice&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/ExpandDims_1/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 16\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/zeros/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/zeros&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/concat&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/zeros/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/ExpandDims_2/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/ExpandDims_2&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/strided_slice&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/ExpandDims_2/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/Const_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 16\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/concat_1/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/concat_1&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/ExpandDims_2&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/Const_2&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/concat_1/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/ExpandDims_3/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/ExpandDims_3&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/strided_slice&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/ExpandDims_3/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/Const_3&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 16\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/zeros_1/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/zeros_1&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/concat_1&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/zeros_1/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/bw/sequence_length&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/stack&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/strided_slice&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/Equal&quot;\\n  op: &quot;Equal&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/Shape_1&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/stack&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/All&quot;\\n  op: &quot;All&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/Equal&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/Const&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/Assert/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;Expected shape for Tensor bidirectional_rnn/bw/sequence_length:0 is &quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/Assert/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot; but saw shape: &quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/Assert/Assert/data_0&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;Expected shape for Tensor bidirectional_rnn/bw/sequence_length:0 is &quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/Assert/Assert/data_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot; but saw shape: &quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/Assert/Assert&quot;\\n  op: &quot;Assert&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/All&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/Assert/Assert/data_0&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/stack&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/Assert/Assert/data_2&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      list {\\n        type: DT_STRING\\n        type: DT_INT32\\n        type: DT_STRING\\n        type: DT_INT32\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;summarize&quot;\\n    value {\\n      i: 3\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/CheckSeqLen&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;bidirectional_rnn/bw/sequence_length&quot;\\n  input: &quot;^bidirectional_rnn/bw/bw/Assert/Assert&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/Shape_2&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/bw/ReverseSequence&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/strided_slice_1/stack&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/strided_slice_1/stack_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/strided_slice_1/stack_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/strided_slice_1&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/Shape_2&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/strided_slice_1/stack&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/strided_slice_1/stack_1&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/strided_slice_1/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/Shape_3&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/bw/ReverseSequence&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/strided_slice_2/stack&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/strided_slice_2/stack_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/strided_slice_2/stack_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/strided_slice_2&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/Shape_3&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/strided_slice_2/stack&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/strided_slice_2/stack_1&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/strided_slice_2/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/ExpandDims/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/ExpandDims&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/strided_slice_2&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/ExpandDims/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 16\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/ExpandDims&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/Const_1&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/zeros/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/zeros&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/concat&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/zeros/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/Const_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/Min&quot;\\n  op: &quot;Min&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/CheckSeqLen&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/Const_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/Const_3&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/Max&quot;\\n  op: &quot;Max&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/CheckSeqLen&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/Const_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/time&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/TensorArray&quot;\\n  op: &quot;TensorArrayV3&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/strided_slice_1&quot;\\n  attr {\\n    key: &quot;clear_after_read&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;dynamic_size&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;element_shape&quot;\\n    value {\\n      shape {\\n        unknown_rank: true\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;tensor_array_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/dynamic_rnn/output_0&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/TensorArray_1&quot;\\n  op: &quot;TensorArrayV3&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/strided_slice_1&quot;\\n  attr {\\n    key: &quot;clear_after_read&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;dynamic_size&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;element_shape&quot;\\n    value {\\n      shape {\\n        unknown_rank: true\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;tensor_array_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/dynamic_rnn/input_0&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/TensorArrayUnstack/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/bw/ReverseSequence&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/TensorArrayUnstack/strided_slice/stack&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/TensorArrayUnstack/strided_slice/stack_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/TensorArrayUnstack/strided_slice/stack_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/TensorArrayUnstack/strided_slice&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArrayUnstack/Shape&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArrayUnstack/strided_slice/stack&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArrayUnstack/strided_slice/stack_1&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArrayUnstack/strided_slice/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/TensorArrayUnstack/range/start&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/TensorArrayUnstack/range/delta&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/TensorArrayUnstack/range&quot;\\n  op: &quot;Range&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArrayUnstack/range/start&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArrayUnstack/strided_slice&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArrayUnstack/range/delta&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3&quot;\\n  op: &quot;TensorArrayScatterV3&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArray_1&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArrayUnstack/range&quot;\\n  input: &quot;bidirectional_rnn/bw/ReverseSequence&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArray_1:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/ReverseSequence&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/time&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/Enter_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArray:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/Enter_2&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/Enter_3&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/LSTMCellZeroState/zeros_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/Merge&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Enter&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/Merge_1&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Enter_1&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/NextIteration_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/Merge_2&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Enter_2&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/NextIteration_2&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/Merge_3&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Enter_3&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/NextIteration_3&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/Less/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/strided_slice_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/Less&quot;\\n  op: &quot;Less&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Merge&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Less/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/LoopCond&quot;\\n  op: &quot;LoopCond&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Less&quot;\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Merge&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/LoopCond&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/Merge&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/Switch_1&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Merge_1&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/LoopCond&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/Merge_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/Switch_2&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Merge_2&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/LoopCond&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/Merge_2&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/Switch_3&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Merge_3&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/LoopCond&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/Merge_3&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/Identity&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Switch:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/Identity_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Switch_1:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/Identity_2&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Switch_2:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/Identity_3&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Switch_3:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArray_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/TensorArrayReadV3&quot;\\n  op: &quot;TensorArrayReadV3&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Identity&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^bidirectional_rnn/bw/bw/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/TensorArrayReadV3&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Identity_3&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd&quot;\\n  op: &quot;BiasAdd&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^bidirectional_rnn/bw/bw/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 4\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split/split_dim&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^bidirectional_rnn/bw/bw/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split&quot;\\n  op: &quot;Split&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split/split_dim&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;num_split&quot;\\n    value {\\n      i: 4\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add/y&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^bidirectional_rnn/bw/bw/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split:2&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid&quot;\\n  op: &quot;Sigmoid&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Identity_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid_1&quot;\\n  op: &quot;Sigmoid&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Tanh&quot;\\n  op: &quot;Tanh&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid_1&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Tanh&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid_2&quot;\\n  op: &quot;Sigmoid&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split:3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Tanh_1&quot;\\n  op: &quot;Tanh&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid_2&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Tanh_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/GreaterEqual/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/CheckSeqLen&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/GreaterEqual&quot;\\n  op: &quot;GreaterEqual&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Identity&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/GreaterEqual/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/Select/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/Select&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/GreaterEqual&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Select/Enter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/GreaterEqual_1&quot;\\n  op: &quot;GreaterEqual&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Identity&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/GreaterEqual/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/Select_1&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/GreaterEqual_1&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Identity_2&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/GreaterEqual_2&quot;\\n  op: &quot;GreaterEqual&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Identity&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/GreaterEqual/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/Select_2&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/GreaterEqual_2&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Identity_3&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArray&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3&quot;\\n  op: &quot;TensorArrayWriteV3&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3/Enter&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Identity&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Select&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Identity_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/add/y&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^bidirectional_rnn/bw/bw/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Identity&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/add/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/NextIteration_1&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/NextIteration_2&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Select_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/NextIteration_3&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Select_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/Exit&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/Exit_1&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Switch_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/Exit_2&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Switch_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/while/Exit_3&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Switch_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/TensorArrayStack/TensorArraySizeV3&quot;\\n  op: &quot;TensorArraySizeV3&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArray&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Exit_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/TensorArray&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/TensorArrayStack/range/start&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/TensorArray&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/TensorArrayStack/range/delta&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/TensorArray&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/TensorArrayStack/range&quot;\\n  op: &quot;Range&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArrayStack/range/start&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArrayStack/TensorArraySizeV3&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArrayStack/range/delta&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/TensorArray&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/TensorArrayStack/TensorArrayGatherV3&quot;\\n  op: &quot;TensorArrayGatherV3&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArray&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArrayStack/range&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Exit_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/TensorArray&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;element_shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n        dim {\\n          size: 16\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/bw/bw/Const_4&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 16\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;ReverseSequence&quot;\\n  op: &quot;ReverseSequence&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArrayStack/TensorArrayGatherV3&quot;\\n  input: &quot;encoder_inputs_length&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tlen&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;batch_dim&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;seq_dim&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;concat/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArrayStack/TensorArrayGatherV3&quot;\\n  input: &quot;ReverseSequence&quot;\\n  input: &quot;concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;concat_1/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;concat_1&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Exit_2&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Exit_2&quot;\\n  input: &quot;concat_1/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;concat_2/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;concat_2&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Exit_3&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Exit_3&quot;\\n  input: &quot;concat_2/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;encoder_inputs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;unstack&quot;\\n  op: &quot;Unpack&quot;\\n  input: &quot;Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;num&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;add/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 3\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;encoder_inputs_length&quot;\\n  input: &quot;add/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;add_1/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 3\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;add_1&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;unstack&quot;\\n  input: &quot;add_1/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;ones/shape&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;add_1&quot;\\n  input: &quot;unstack:1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;ones/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;ones&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;ones/shape&quot;\\n  input: &quot;ones/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;embedding_lookup_1&quot;\\n  op: &quot;Gather&quot;\\n  input: &quot;Variable/read&quot;\\n  input: &quot;ones&quot;\\n  attr {\\n    key: &quot;Tindices&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tparams&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_indices&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;transpose/perm&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 3\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;transpose&quot;\\n  op: &quot;Transpose&quot;\\n  input: &quot;concat&quot;\\n  input: &quot;transpose/perm&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tperm&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/ones&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;transpose&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/strided_slice/stack&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/strided_slice/stack_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/strided_slice/stack_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/strided_slice&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;LuongAttention/Shape&quot;\\n  input: &quot;LuongAttention/strided_slice/stack&quot;\\n  input: &quot;LuongAttention/strided_slice/stack_1&quot;\\n  input: &quot;LuongAttention/strided_slice/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;memory_layer/kernel/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@memory_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot; \\\\000\\\\000\\\\000 \\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;memory_layer/kernel/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@memory_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.306186228991\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;memory_layer/kernel/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@memory_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.306186228991\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;memory_layer/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;memory_layer/kernel/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@memory_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;memory_layer/kernel/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;memory_layer/kernel/Initializer/random_uniform/max&quot;\\n  input: &quot;memory_layer/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@memory_layer/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;memory_layer/kernel/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;memory_layer/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;memory_layer/kernel/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@memory_layer/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;memory_layer/kernel/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;memory_layer/kernel/Initializer/random_uniform/mul&quot;\\n  input: &quot;memory_layer/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@memory_layer/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;memory_layer/kernel&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@memory_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 32\\n        }\\n        dim {\\n          size: 32\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;memory_layer/kernel/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;memory_layer/kernel&quot;\\n  input: &quot;memory_layer/kernel/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@memory_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;memory_layer/kernel/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;memory_layer/kernel&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@memory_layer/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;transpose&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/Rank&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 3\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/axes&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/GreaterEqual/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/GreaterEqual&quot;\\n  op: &quot;GreaterEqual&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/axes&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/GreaterEqual/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/GreaterEqual&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/Cast&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/axes&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/Less/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/Less&quot;\\n  op: &quot;Less&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/axes&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/Less/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/Cast_1&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/Less&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/axes&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/Rank&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/Cast_1&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/add_1&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/mul&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/mul_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/range/start&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/range/delta&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/range&quot;\\n  op: &quot;Range&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/range/start&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/Rank&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/range/delta&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/ListDiff&quot;\\n  op: &quot;ListDiff&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/range&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;out_idx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/Gather&quot;\\n  op: &quot;Gather&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/Shape&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/ListDiff&quot;\\n  attr {\\n    key: &quot;Tindices&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tparams&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_indices&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/Gather_1&quot;\\n  op: &quot;Gather&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/Shape&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/add_1&quot;\\n  attr {\\n    key: &quot;Tindices&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tparams&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_indices&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/Prod&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/Gather&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/Prod_1&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/Gather_1&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/Gather_1&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/Gather&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/concat_1/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/concat_1&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/ListDiff&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/add_1&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/concat_1/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/stack&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/Prod&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/Prod_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/transpose&quot;\\n  op: &quot;Transpose&quot;\\n  input: &quot;transpose&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/concat_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tperm&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/transpose&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/stack&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/transpose_1/perm&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/transpose_1&quot;\\n  op: &quot;Transpose&quot;\\n  input: &quot;memory_layer/kernel/read&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/transpose_1/perm&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tperm&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/Reshape_1/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot; \\\\000\\\\000\\\\000 \\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/transpose_1&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/Reshape_1/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/Reshape&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/Reshape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/Const_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 32\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/concat_2/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot/concat_2&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/Gather&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/Const_2&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/concat_2/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/memory_layer/Tensordot&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/MatMul&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/concat_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/strided_slice_1/stack&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/strided_slice_1/stack_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/strided_slice_1/stack_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/strided_slice_1&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;LuongAttention/Shape_1&quot;\\n  input: &quot;LuongAttention/strided_slice_1/stack&quot;\\n  input: &quot;LuongAttention/strided_slice_1/stack_1&quot;\\n  input: &quot;LuongAttention/strided_slice_1/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/Shape_2&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/strided_slice_2/stack&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/strided_slice_2/stack_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/strided_slice_2/stack_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;LuongAttention/strided_slice_2&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;LuongAttention/Shape_2&quot;\\n  input: &quot;LuongAttention/strided_slice_2/stack&quot;\\n  input: &quot;LuongAttention/strided_slice_2/stack_1&quot;\\n  input: &quot;LuongAttention/strided_slice_2/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/LSTMCellZeroState/ExpandDims/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/LSTMCellZeroState/ExpandDims&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;unstack:1&quot;\\n  input: &quot;AttentionWrapperZeroState/LSTMCellZeroState/ExpandDims/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/LSTMCellZeroState/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 32\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/LSTMCellZeroState/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/LSTMCellZeroState/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;AttentionWrapperZeroState/LSTMCellZeroState/ExpandDims&quot;\\n  input: &quot;AttentionWrapperZeroState/LSTMCellZeroState/Const&quot;\\n  input: &quot;AttentionWrapperZeroState/LSTMCellZeroState/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/LSTMCellZeroState/ExpandDims_1/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/LSTMCellZeroState/ExpandDims_1&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;unstack:1&quot;\\n  input: &quot;AttentionWrapperZeroState/LSTMCellZeroState/ExpandDims_1/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/LSTMCellZeroState/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 32\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/LSTMCellZeroState/zeros/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/LSTMCellZeroState/zeros&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;AttentionWrapperZeroState/LSTMCellZeroState/concat&quot;\\n  input: &quot;AttentionWrapperZeroState/LSTMCellZeroState/zeros/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/LSTMCellZeroState/ExpandDims_2/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/LSTMCellZeroState/ExpandDims_2&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;unstack:1&quot;\\n  input: &quot;AttentionWrapperZeroState/LSTMCellZeroState/ExpandDims_2/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/LSTMCellZeroState/Const_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 32\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/LSTMCellZeroState/concat_1/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/LSTMCellZeroState/concat_1&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;AttentionWrapperZeroState/LSTMCellZeroState/ExpandDims_2&quot;\\n  input: &quot;AttentionWrapperZeroState/LSTMCellZeroState/Const_2&quot;\\n  input: &quot;AttentionWrapperZeroState/LSTMCellZeroState/concat_1/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/LSTMCellZeroState/ExpandDims_3/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/LSTMCellZeroState/ExpandDims_3&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;unstack:1&quot;\\n  input: &quot;AttentionWrapperZeroState/LSTMCellZeroState/ExpandDims_3/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/LSTMCellZeroState/Const_3&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 32\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/LSTMCellZeroState/zeros_1/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/LSTMCellZeroState/zeros_1&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;AttentionWrapperZeroState/LSTMCellZeroState/concat_1&quot;\\n  input: &quot;AttentionWrapperZeroState/LSTMCellZeroState/zeros_1/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/assert_equal/Equal&quot;\\n  op: &quot;Equal&quot;\\n  input: &quot;unstack:1&quot;\\n  input: &quot;LuongAttention/strided_slice_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/assert_equal/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/assert_equal/All&quot;\\n  op: &quot;All&quot;\\n  input: &quot;AttentionWrapperZeroState/assert_equal/Equal&quot;\\n  input: &quot;AttentionWrapperZeroState/assert_equal/Const&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/assert_equal/Assert/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;When calling zero_state of AttentionWrapper attention_wrapper: Non-matching batch sizes between the memory (encoder output) and the requested batch size.  Are you using the BeamSearchDecoder?  If so, make sure your encoder output has been tiled to beam_width via tf.contrib.seq2seq.tile_batch, and the batch_size= argument passed to zero_state is batch_size * beam_width.&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/assert_equal/Assert/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;Condition x == y did not hold element-wise:&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/assert_equal/Assert/Const_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;x (unstack:1) = &quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/assert_equal/Assert/Const_3&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;y (LuongAttention/strided_slice_1:0) = &quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/assert_equal/Assert/Assert/data_0&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;When calling zero_state of AttentionWrapper attention_wrapper: Non-matching batch sizes between the memory (encoder output) and the requested batch size.  Are you using the BeamSearchDecoder?  If so, make sure your encoder output has been tiled to beam_width via tf.contrib.seq2seq.tile_batch, and the batch_size= argument passed to zero_state is batch_size * beam_width.&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/assert_equal/Assert/Assert/data_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;Condition x == y did not hold element-wise:&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/assert_equal/Assert/Assert/data_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;x (unstack:1) = &quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/assert_equal/Assert/Assert/data_4&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;y (LuongAttention/strided_slice_1:0) = &quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/assert_equal/Assert/Assert&quot;\\n  op: &quot;Assert&quot;\\n  input: &quot;AttentionWrapperZeroState/assert_equal/All&quot;\\n  input: &quot;AttentionWrapperZeroState/assert_equal/Assert/Assert/data_0&quot;\\n  input: &quot;AttentionWrapperZeroState/assert_equal/Assert/Assert/data_1&quot;\\n  input: &quot;AttentionWrapperZeroState/assert_equal/Assert/Assert/data_2&quot;\\n  input: &quot;unstack:1&quot;\\n  input: &quot;AttentionWrapperZeroState/assert_equal/Assert/Assert/data_4&quot;\\n  input: &quot;LuongAttention/strided_slice_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      list {\\n        type: DT_STRING\\n        type: DT_STRING\\n        type: DT_STRING\\n        type: DT_INT32\\n        type: DT_STRING\\n        type: DT_INT32\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;summarize&quot;\\n    value {\\n      i: 3\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/checked_cell_state&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;AttentionWrapperZeroState/LSTMCellZeroState/zeros&quot;\\n  input: &quot;^AttentionWrapperZeroState/assert_equal/Assert/Assert&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/checked_cell_state_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;AttentionWrapperZeroState/LSTMCellZeroState/zeros_1&quot;\\n  input: &quot;^AttentionWrapperZeroState/assert_equal/Assert/Assert&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/ExpandDims/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/ExpandDims&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;unstack:1&quot;\\n  input: &quot;AttentionWrapperZeroState/ExpandDims/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 32\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;AttentionWrapperZeroState/ExpandDims&quot;\\n  input: &quot;AttentionWrapperZeroState/Const&quot;\\n  input: &quot;AttentionWrapperZeroState/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/ExpandDims_1/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/ExpandDims_1&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;unstack:1&quot;\\n  input: &quot;AttentionWrapperZeroState/ExpandDims_1/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 32\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/zeros_1/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/zeros_1&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;AttentionWrapperZeroState/concat&quot;\\n  input: &quot;AttentionWrapperZeroState/zeros_1/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/ExpandDims_2/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/ExpandDims_2&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;unstack:1&quot;\\n  input: &quot;AttentionWrapperZeroState/ExpandDims_2/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/ExpandDims_3/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/ExpandDims_3&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;LuongAttention/strided_slice_2&quot;\\n  input: &quot;AttentionWrapperZeroState/ExpandDims_3/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/concat_1/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/concat_1&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;AttentionWrapperZeroState/ExpandDims_2&quot;\\n  input: &quot;AttentionWrapperZeroState/ExpandDims_3&quot;\\n  input: &quot;AttentionWrapperZeroState/concat_1/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/ExpandDims_4/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/ExpandDims_4&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;unstack:1&quot;\\n  input: &quot;AttentionWrapperZeroState/ExpandDims_4/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/ExpandDims_5/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/ExpandDims_5&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;LuongAttention/strided_slice_2&quot;\\n  input: &quot;AttentionWrapperZeroState/ExpandDims_5/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/zeros_2/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AttentionWrapperZeroState/zeros_2&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;AttentionWrapperZeroState/concat_1&quot;\\n  input: &quot;AttentionWrapperZeroState/zeros_2/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;TrainingHelper/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;embedding_lookup_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;TrainingHelper/strided_slice/stack&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;TrainingHelper/strided_slice/stack_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;TrainingHelper/strided_slice/stack_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;TrainingHelper/strided_slice&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;TrainingHelper/Shape&quot;\\n  input: &quot;TrainingHelper/strided_slice/stack&quot;\\n  input: &quot;TrainingHelper/strided_slice/stack_1&quot;\\n  input: &quot;TrainingHelper/strided_slice/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;TrainingHelper/TensorArray&quot;\\n  op: &quot;TensorArrayV3&quot;\\n  input: &quot;TrainingHelper/strided_slice&quot;\\n  attr {\\n    key: &quot;clear_after_read&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;dynamic_size&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;element_shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n        dim {\\n          size: 20\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;tensor_array_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;TrainingHelper/TensorArrayUnstack/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;embedding_lookup_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;TrainingHelper/TensorArrayUnstack/strided_slice/stack&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;TrainingHelper/TensorArrayUnstack/strided_slice/stack_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;TrainingHelper/TensorArrayUnstack/strided_slice/stack_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;TrainingHelper/TensorArrayUnstack/strided_slice&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;TrainingHelper/TensorArrayUnstack/Shape&quot;\\n  input: &quot;TrainingHelper/TensorArrayUnstack/strided_slice/stack&quot;\\n  input: &quot;TrainingHelper/TensorArrayUnstack/strided_slice/stack_1&quot;\\n  input: &quot;TrainingHelper/TensorArrayUnstack/strided_slice/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;TrainingHelper/TensorArrayUnstack/range/start&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;TrainingHelper/TensorArrayUnstack/range/delta&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;TrainingHelper/TensorArrayUnstack/range&quot;\\n  op: &quot;Range&quot;\\n  input: &quot;TrainingHelper/TensorArrayUnstack/range/start&quot;\\n  input: &quot;TrainingHelper/TensorArrayUnstack/strided_slice&quot;\\n  input: &quot;TrainingHelper/TensorArrayUnstack/range/delta&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;TrainingHelper/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3&quot;\\n  op: &quot;TensorArrayScatterV3&quot;\\n  input: &quot;TrainingHelper/TensorArray&quot;\\n  input: &quot;TrainingHelper/TensorArrayUnstack/range&quot;\\n  input: &quot;embedding_lookup_1&quot;\\n  input: &quot;TrainingHelper/TensorArray:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;TrainingHelper/strided_slice_1/stack&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;TrainingHelper/strided_slice_1/stack_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;TrainingHelper/strided_slice_1/stack_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;TrainingHelper/strided_slice_1&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;embedding_lookup_1&quot;\\n  input: &quot;TrainingHelper/strided_slice_1/stack&quot;\\n  input: &quot;TrainingHelper/strided_slice_1/stack_1&quot;\\n  input: &quot;TrainingHelper/strided_slice_1/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;TrainingHelper/zeros_like&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;TrainingHelper/strided_slice_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;TrainingHelper/Size&quot;\\n  op: &quot;Size&quot;\\n  input: &quot;add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TrainingHelperInitialize/Equal/x&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TrainingHelperInitialize/Equal&quot;\\n  op: &quot;Equal&quot;\\n  input: &quot;decoder/TrainingHelperInitialize/Equal/x&quot;\\n  input: &quot;add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TrainingHelperInitialize/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TrainingHelperInitialize/All&quot;\\n  op: &quot;All&quot;\\n  input: &quot;decoder/TrainingHelperInitialize/Equal&quot;\\n  input: &quot;decoder/TrainingHelperInitialize/Const&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TrainingHelperInitialize/cond/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;decoder/TrainingHelperInitialize/All&quot;\\n  input: &quot;decoder/TrainingHelperInitialize/All&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TrainingHelperInitialize/cond/switch_t&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/TrainingHelperInitialize/cond/Switch:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TrainingHelperInitialize/cond/switch_f&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/TrainingHelperInitialize/cond/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TrainingHelperInitialize/cond/pred_id&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/TrainingHelperInitialize/All&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TrainingHelperInitialize/cond/Switch_1&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;TrainingHelper/zeros_like&quot;\\n  input: &quot;decoder/TrainingHelperInitialize/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@TrainingHelper/zeros_like&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TrainingHelperInitialize/cond/TensorArrayReadV3/index&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/TrainingHelperInitialize/cond/switch_f&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TrainingHelperInitialize/cond/TensorArrayReadV3/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;TrainingHelper/TensorArray&quot;\\n  input: &quot;decoder/TrainingHelperInitialize/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@TrainingHelper/TensorArray&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TrainingHelperInitialize/cond/TensorArrayReadV3/Switch_1&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;TrainingHelper/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3&quot;\\n  input: &quot;decoder/TrainingHelperInitialize/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TrainingHelperInitialize/cond/TensorArrayReadV3&quot;\\n  op: &quot;TensorArrayReadV3&quot;\\n  input: &quot;decoder/TrainingHelperInitialize/cond/TensorArrayReadV3/Switch&quot;\\n  input: &quot;decoder/TrainingHelperInitialize/cond/TensorArrayReadV3/index&quot;\\n  input: &quot;decoder/TrainingHelperInitialize/cond/TensorArrayReadV3/Switch_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TrainingHelperInitialize/cond/Merge&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;decoder/TrainingHelperInitialize/cond/TensorArrayReadV3&quot;\\n  input: &quot;decoder/TrainingHelperInitialize/cond/Switch_1:1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/zero_suffix_shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 10\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/concat/values_0&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;TrainingHelper/Size&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;decoder/concat/values_0&quot;\\n  input: &quot;decoder/zero_suffix_shape&quot;\\n  input: &quot;decoder/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/zeros/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/zeros&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;decoder/concat&quot;\\n  input: &quot;decoder/zeros/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/zero_suffix_shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/concat_1/values_0&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;TrainingHelper/Size&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/concat_1/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/concat_1&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;decoder/concat_1/values_0&quot;\\n  input: &quot;decoder/zero_suffix_shape_1&quot;\\n  input: &quot;decoder/concat_1/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/zeros_1/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/zeros_1&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;decoder/concat_1&quot;\\n  input: &quot;decoder/zeros_1/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/zeros_like/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;decoder/TrainingHelperInitialize/Equal&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/zeros_like/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/zeros_like&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;decoder/zeros_like/Shape&quot;\\n  input: &quot;decoder/zeros_like/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TensorArray/size&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TensorArray&quot;\\n  op: &quot;TensorArrayV3&quot;\\n  input: &quot;decoder/TensorArray/size&quot;\\n  attr {\\n    key: &quot;clear_after_read&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;dynamic_size&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;element_shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;tensor_array_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TensorArray_1/size&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TensorArray_1&quot;\\n  op: &quot;TensorArrayV3&quot;\\n  input: &quot;decoder/TensorArray_1/size&quot;\\n  attr {\\n    key: &quot;clear_after_read&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dynamic_size&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;element_shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;tensor_array_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;decoder/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Enter_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;decoder/TensorArray:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Enter_2&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;decoder/TensorArray_1:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Enter_3&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;concat_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Enter_4&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;concat_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Enter_5&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;AttentionWrapperZeroState/zeros_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Enter_6&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;AttentionWrapperZeroState/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Enter_7&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;AttentionWrapperZeroState/zeros_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Enter_8&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;decoder/TrainingHelperInitialize/cond/Merge&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Enter_9&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;decoder/TrainingHelperInitialize/Equal&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Enter_10&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;decoder/zeros_like&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Merge&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;decoder/while/Enter&quot;\\n  input: &quot;decoder/while/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Merge_1&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;decoder/while/Enter_1&quot;\\n  input: &quot;decoder/while/NextIteration_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Merge_2&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;decoder/while/Enter_2&quot;\\n  input: &quot;decoder/while/NextIteration_2&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Merge_3&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;decoder/while/Enter_3&quot;\\n  input: &quot;decoder/while/NextIteration_3&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Merge_4&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;decoder/while/Enter_4&quot;\\n  input: &quot;decoder/while/NextIteration_4&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Merge_5&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;decoder/while/Enter_5&quot;\\n  input: &quot;decoder/while/NextIteration_5&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Merge_6&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;decoder/while/Enter_6&quot;\\n  input: &quot;decoder/while/NextIteration_6&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Merge_7&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;decoder/while/Enter_7&quot;\\n  input: &quot;decoder/while/NextIteration_7&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Merge_8&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;decoder/while/Enter_8&quot;\\n  input: &quot;decoder/while/NextIteration_8&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Merge_9&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;decoder/while/Enter_9&quot;\\n  input: &quot;decoder/while/NextIteration_9&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Merge_10&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;decoder/while/Enter_10&quot;\\n  input: &quot;decoder/while/NextIteration_10&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Merge&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/All&quot;\\n  op: &quot;All&quot;\\n  input: &quot;decoder/while/Merge_9&quot;\\n  input: &quot;decoder/while/Const&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/LogicalNot&quot;\\n  op: &quot;LogicalNot&quot;\\n  input: &quot;decoder/while/All&quot;\\n}\\nnode {\\n  name: &quot;decoder/while/LoopCond&quot;\\n  op: &quot;LoopCond&quot;\\n  input: &quot;decoder/while/LogicalNot&quot;\\n}\\nnode {\\n  name: &quot;decoder/while/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;decoder/while/Merge&quot;\\n  input: &quot;decoder/while/LoopCond&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Merge&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Switch_1&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;decoder/while/Merge_1&quot;\\n  input: &quot;decoder/while/LoopCond&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Merge_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Switch_2&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;decoder/while/Merge_2&quot;\\n  input: &quot;decoder/while/LoopCond&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Merge_2&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Switch_3&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;decoder/while/Merge_3&quot;\\n  input: &quot;decoder/while/LoopCond&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Merge_3&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Switch_4&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;decoder/while/Merge_4&quot;\\n  input: &quot;decoder/while/LoopCond&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Merge_4&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Switch_5&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;decoder/while/Merge_5&quot;\\n  input: &quot;decoder/while/LoopCond&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Merge_5&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Switch_6&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;decoder/while/Merge_6&quot;\\n  input: &quot;decoder/while/LoopCond&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Merge_6&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Switch_7&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;decoder/while/Merge_7&quot;\\n  input: &quot;decoder/while/LoopCond&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Merge_7&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Switch_8&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;decoder/while/Merge_8&quot;\\n  input: &quot;decoder/while/LoopCond&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Merge_8&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Switch_9&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;decoder/while/Merge_9&quot;\\n  input: &quot;decoder/while/LoopCond&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Merge_9&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Switch_10&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;decoder/while/Merge_10&quot;\\n  input: &quot;decoder/while/LoopCond&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Merge_10&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Identity&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/while/Switch:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Identity_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/while/Switch_1:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Identity_2&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/while/Switch_2:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Identity_3&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/while/Switch_3:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Identity_4&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/while/Switch_4:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Identity_5&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/while/Switch_5:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Identity_6&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/while/Switch_6:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Identity_7&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/while/Switch_7:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Identity_8&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/while/Switch_8:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Identity_9&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/while/Switch_9:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Identity_10&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/while/Switch_10:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;decoder/while/Identity_8&quot;\\n  input: &quot;decoder/while/Identity_5&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/kernel/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;T\\\\000\\\\000\\\\000\\\\200\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/kernel/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.168231651187\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/kernel/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.168231651187\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/kernel/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/kernel/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/kernel/Initializer/random_uniform/max&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/kernel/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/kernel/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/kernel/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/kernel/Initializer/random_uniform/mul&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/kernel&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 84\\n        }\\n        dim {\\n          size: 128\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/kernel/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/kernel&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/kernel/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/kernel/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/kernel&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat&quot;\\n  input: &quot;decoder/while/Identity_4&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/bias/Initializer/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 128\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/bias&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 128\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/bias&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/bias/Initializer/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd&quot;\\n  op: &quot;BiasAdd&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 4\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split/split_dim&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split&quot;\\n  op: &quot;Split&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split/split_dim&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;num_split&quot;\\n    value {\\n      i: 4\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add/y&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split:2&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid&quot;\\n  op: &quot;Sigmoid&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid&quot;\\n  input: &quot;decoder/while/Identity_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid_1&quot;\\n  op: &quot;Sigmoid&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Tanh&quot;\\n  op: &quot;Tanh&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid_1&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Tanh&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid_2&quot;\\n  op: &quot;Sigmoid&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split:3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Tanh_1&quot;\\n  op: &quot;Tanh&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid_2&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Tanh_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/strided_slice/stack&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/strided_slice/stack_1&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/strided_slice/stack_2&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/strided_slice&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/Shape&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/strided_slice/stack&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/strided_slice/stack_1&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/strided_slice/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/Equal/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;LuongAttention/strided_slice_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/Equal&quot;\\n  op: &quot;Equal&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/strided_slice&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/Equal/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/All&quot;\\n  op: &quot;All&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/Equal&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/Const&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/Assert/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;When applying AttentionWrapper attention_wrapper_1: Non-matching batch sizes between the memory (encoder output) and the query (decoder output).  Are you using the BeamSearchDecoder?  You may need to tile your memory input via the tf.contrib.seq2seq.tile_batch function with argument multiple=beam_width.&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/Assert/Const_1&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;Condition x == y did not hold element-wise:&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/Assert/Const_2&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;x (decoder/while/BasicDecoderStep/decoder/attention_wrapper/strided_slice:0) = &quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/Assert/Const_3&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;y (LuongAttention/strided_slice_1:0) = &quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/Assert/Assert/data_0&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;When applying AttentionWrapper attention_wrapper_1: Non-matching batch sizes between the memory (encoder output) and the query (decoder output).  Are you using the BeamSearchDecoder?  You may need to tile your memory input via the tf.contrib.seq2seq.tile_batch function with argument multiple=beam_width.&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/Assert/Assert/data_1&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;Condition x == y did not hold element-wise:&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/Assert/Assert/data_2&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;x (decoder/while/BasicDecoderStep/decoder/attention_wrapper/strided_slice:0) = &quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/Assert/Assert/data_4&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;y (LuongAttention/strided_slice_1:0) = &quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/Assert/Assert&quot;\\n  op: &quot;Assert&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/All&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/Assert/Assert/data_0&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/Assert/Assert/data_1&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/Assert/Assert/data_2&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/strided_slice&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/Assert/Assert/data_4&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/Equal/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      list {\\n        type: DT_STRING\\n        type: DT_STRING\\n        type: DT_STRING\\n        type: DT_INT32\\n        type: DT_STRING\\n        type: DT_INT32\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;summarize&quot;\\n    value {\\n      i: 3\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/checked_cell_output&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2&quot;\\n  input: &quot;^decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/Assert/Assert&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims/dim&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/checked_cell_output&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul&quot;\\n  op: &quot;BatchMatMul&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;adj_x&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;adj_y&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/Squeeze&quot;\\n  op: &quot;Squeeze&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;squeeze_dims&quot;\\n    value {\\n      list {\\n        i: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax&quot;\\n  op: &quot;Softmax&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/Squeeze&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims/dim&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;transpose&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul&quot;\\n  op: &quot;BatchMatMul&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;adj_x&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;adj_y&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze&quot;\\n  op: &quot;Squeeze&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;squeeze_dims&quot;\\n    value {\\n      list {\\n        i: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1/axis&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/checked_cell_output&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/attention_layer/kernel/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/attention_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;@\\\\000\\\\000\\\\000 \\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/attention_layer/kernel/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/attention_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.25\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/attention_layer/kernel/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/attention_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.25\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/attention_layer/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;decoder/attention_wrapper/attention_layer/kernel/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/attention_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/attention_layer/kernel/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;decoder/attention_wrapper/attention_layer/kernel/Initializer/random_uniform/max&quot;\\n  input: &quot;decoder/attention_wrapper/attention_layer/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/attention_layer/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/attention_layer/kernel/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;decoder/attention_wrapper/attention_layer/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;decoder/attention_wrapper/attention_layer/kernel/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/attention_layer/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/attention_layer/kernel/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;decoder/attention_wrapper/attention_layer/kernel/Initializer/random_uniform/mul&quot;\\n  input: &quot;decoder/attention_wrapper/attention_layer/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/attention_layer/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/attention_layer/kernel&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/attention_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 64\\n        }\\n        dim {\\n          size: 32\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/attention_layer/kernel/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;decoder/attention_wrapper/attention_layer/kernel&quot;\\n  input: &quot;decoder/attention_wrapper/attention_layer/kernel/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/attention_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/attention_layer/kernel/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/attention_wrapper/attention_layer/kernel&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;decoder/attention_wrapper/attention_layer/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_2/concat_dim&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_2&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/add/y&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;decoder/while/Identity_6&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/add/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/kernel/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot; \\\\000\\\\000\\\\000\\\\n\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/kernel/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.37796446681\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/kernel/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.37796446681\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;decoder/dense/kernel/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/kernel/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;decoder/dense/kernel/Initializer/random_uniform/max&quot;\\n  input: &quot;decoder/dense/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/kernel/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;decoder/dense/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;decoder/dense/kernel/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/kernel/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;decoder/dense/kernel/Initializer/random_uniform/mul&quot;\\n  input: &quot;decoder/dense/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/kernel&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 32\\n        }\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/kernel/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;decoder/dense/kernel&quot;\\n  input: &quot;decoder/dense/kernel/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/kernel/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/dense/kernel&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/bias/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 10\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/bias&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;decoder/dense/bias&quot;\\n  input: &quot;decoder/dense/bias/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/dense/bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/dense/MatMul/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;decoder/dense/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/dense/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_2&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/dense/MatMul/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/dense/BiasAdd/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;decoder/dense/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/dense/BiasAdd&quot;\\n  op: &quot;BiasAdd&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/dense/MatMul&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/dense/BiasAdd/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/TrainingHelperSample/ArgMax/dimension&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/TrainingHelperSample/ArgMax&quot;\\n  op: &quot;ArgMax&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/dense/BiasAdd&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperSample/ArgMax/dimension&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;output_type&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/TrainingHelperSample/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperSample/ArgMax&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/add/y&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;decoder/while/Identity&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/add/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/GreaterEqual/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/GreaterEqual&quot;\\n  op: &quot;GreaterEqual&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/add&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/GreaterEqual/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/All&quot;\\n  op: &quot;All&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/GreaterEqual&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/Const&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/All&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/All&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/switch_t&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Switch:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/switch_f&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/pred_id&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/All&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;TrainingHelper/zeros_like&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Switch_1&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Enter&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Enter&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;TrainingHelper/TensorArray&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Enter&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Enter&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Switch_1&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/add&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/TrainingHelperNextInputs/add&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Enter_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;TrainingHelper/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Switch_2&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Enter_1&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Enter_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3&quot;\\n  op: &quot;TensorArrayReadV3&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Switch&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Switch_1&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Switch_2&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Switch_1:1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/LogicalOr&quot;\\n  op: &quot;LogicalOr&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/GreaterEqual&quot;\\n  input: &quot;decoder/while/Identity_9&quot;\\n}\\nnode {\\n  name: &quot;decoder/while/LogicalNot_1&quot;\\n  op: &quot;LogicalNot&quot;\\n  input: &quot;decoder/while/Identity_9&quot;\\n}\\nnode {\\n  name: &quot;decoder/while/LogicalAnd&quot;\\n  op: &quot;LogicalAnd&quot;\\n  input: &quot;decoder/while/LogicalNot_1&quot;\\n  input: &quot;decoder/while/LogicalOr&quot;\\n}\\nnode {\\n  name: &quot;decoder/while/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;decoder/while/Identity_10&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/add/y&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;decoder/while/Identity&quot;\\n  input: &quot;decoder/while/add/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;decoder/while/Shape&quot;\\n  input: &quot;decoder/while/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Select&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;decoder/while/LogicalAnd&quot;\\n  input: &quot;decoder/while/Fill&quot;\\n  input: &quot;decoder/while/Identity_10&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/TensorArrayWrite/TensorArrayWriteV3/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;decoder/TensorArray&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/dense/BiasAdd&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/TensorArrayWrite/TensorArrayWriteV3&quot;\\n  op: &quot;TensorArrayWriteV3&quot;\\n  input: &quot;decoder/while/TensorArrayWrite/TensorArrayWriteV3/Enter&quot;\\n  input: &quot;decoder/while/Identity&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/dense/BiasAdd&quot;\\n  input: &quot;decoder/while/Identity_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/dense/BiasAdd&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;decoder/TensorArray_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/TrainingHelperSample/Cast&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/TensorArrayWrite_1/TensorArrayWriteV3&quot;\\n  op: &quot;TensorArrayWriteV3&quot;\\n  input: &quot;decoder/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter&quot;\\n  input: &quot;decoder/while/Identity&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperSample/Cast&quot;\\n  input: &quot;decoder/while/Identity_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/TrainingHelperSample/Cast&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/add_1/y&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/add_1&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;decoder/while/Identity&quot;\\n  input: &quot;decoder/while/add_1/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;decoder/while/add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/NextIteration_1&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;decoder/while/TensorArrayWrite/TensorArrayWriteV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/NextIteration_2&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;decoder/while/TensorArrayWrite_1/TensorArrayWriteV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/NextIteration_3&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/NextIteration_4&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/NextIteration_5&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/NextIteration_6&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/NextIteration_7&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/NextIteration_8&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/NextIteration_9&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;decoder/while/LogicalOr&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/NextIteration_10&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;decoder/while/Select&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Exit&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;decoder/while/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Exit_1&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;decoder/while/Switch_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Exit_2&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;decoder/while/Switch_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Exit_3&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;decoder/while/Switch_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Exit_4&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;decoder/while/Switch_4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Exit_5&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;decoder/while/Switch_5&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Exit_6&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;decoder/while/Switch_6&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Exit_7&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;decoder/while/Switch_7&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Exit_8&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;decoder/while/Switch_8&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Exit_9&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;decoder/while/Switch_9&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/while/Exit_10&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;decoder/while/Switch_10&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TensorArrayStack/TensorArraySizeV3&quot;\\n  op: &quot;TensorArraySizeV3&quot;\\n  input: &quot;decoder/TensorArray&quot;\\n  input: &quot;decoder/while/Exit_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/TensorArray&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TensorArrayStack/range/start&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/TensorArray&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TensorArrayStack/range/delta&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/TensorArray&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TensorArrayStack/range&quot;\\n  op: &quot;Range&quot;\\n  input: &quot;decoder/TensorArrayStack/range/start&quot;\\n  input: &quot;decoder/TensorArrayStack/TensorArraySizeV3&quot;\\n  input: &quot;decoder/TensorArrayStack/range/delta&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/TensorArray&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TensorArrayStack/TensorArrayGatherV3&quot;\\n  op: &quot;TensorArrayGatherV3&quot;\\n  input: &quot;decoder/TensorArray&quot;\\n  input: &quot;decoder/TensorArrayStack/range&quot;\\n  input: &quot;decoder/while/Exit_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/TensorArray&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;element_shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TensorArrayStack_1/TensorArraySizeV3&quot;\\n  op: &quot;TensorArraySizeV3&quot;\\n  input: &quot;decoder/TensorArray_1&quot;\\n  input: &quot;decoder/while/Exit_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/TensorArray_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TensorArrayStack_1/range/start&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/TensorArray_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TensorArrayStack_1/range/delta&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/TensorArray_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TensorArrayStack_1/range&quot;\\n  op: &quot;Range&quot;\\n  input: &quot;decoder/TensorArrayStack_1/range/start&quot;\\n  input: &quot;decoder/TensorArrayStack_1/TensorArraySizeV3&quot;\\n  input: &quot;decoder/TensorArrayStack_1/range/delta&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/TensorArray_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/TensorArrayStack_1/TensorArrayGatherV3&quot;\\n  op: &quot;TensorArrayGatherV3&quot;\\n  input: &quot;decoder/TensorArray_1&quot;\\n  input: &quot;decoder/TensorArrayStack_1/range&quot;\\n  input: &quot;decoder/while/Exit_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/TensorArray_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;element_shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;one_hot/on_value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;one_hot/off_value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;one_hot/depth&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 10\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;one_hot&quot;\\n  op: &quot;OneHot&quot;\\n  input: &quot;decoder_targets&quot;\\n  input: &quot;one_hot/depth&quot;\\n  input: &quot;one_hot/on_value&quot;\\n  input: &quot;one_hot/off_value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;TI&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: -1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Rank&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 3\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;decoder/TensorArrayStack/TensorArrayGatherV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Rank_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 3\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Shape_2&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;decoder/TensorArrayStack/TensorArrayGatherV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Sub/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;Rank_1&quot;\\n  input: &quot;Sub/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Slice/begin&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;Sub&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Slice/size&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Slice&quot;\\n  op: &quot;Slice&quot;\\n  input: &quot;Shape_2&quot;\\n  input: &quot;Slice/begin&quot;\\n  input: &quot;Slice/size&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;concat_3/values_0&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;concat_3/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;concat_3&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;concat_3/values_0&quot;\\n  input: &quot;Slice&quot;\\n  input: &quot;concat_3/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;decoder/TensorArrayStack/TensorArrayGatherV3&quot;\\n  input: &quot;concat_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Rank_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 3\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Shape_3&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;one_hot&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Sub_1/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Sub_1&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;Rank_2&quot;\\n  input: &quot;Sub_1/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Slice_1/begin&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;Sub_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Slice_1/size&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Slice_1&quot;\\n  op: &quot;Slice&quot;\\n  input: &quot;Shape_3&quot;\\n  input: &quot;Slice_1/begin&quot;\\n  input: &quot;Slice_1/size&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;concat_4/values_0&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;concat_4/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;concat_4&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;concat_4/values_0&quot;\\n  input: &quot;Slice_1&quot;\\n  input: &quot;concat_4/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;one_hot&quot;\\n  input: &quot;concat_4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;SoftmaxCrossEntropyWithLogits&quot;\\n  op: &quot;SoftmaxCrossEntropyWithLogits&quot;\\n  input: &quot;Reshape&quot;\\n  input: &quot;Reshape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Sub_2/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Sub_2&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;Rank&quot;\\n  input: &quot;Sub_2/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Slice_2/begin&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Slice_2/size&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;Sub_2&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Slice_2&quot;\\n  op: &quot;Slice&quot;\\n  input: &quot;Shape_1&quot;\\n  input: &quot;Slice_2/begin&quot;\\n  input: &quot;Slice_2/size&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Reshape_2&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;SoftmaxCrossEntropyWithLogits&quot;\\n  input: &quot;Slice_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Mean&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;Reshape_2&quot;\\n  input: &quot;Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape&quot;\\n  input: &quot;gradients/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/f_count&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/f_count_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/f_count&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Merge&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/f_count_1&quot;\\n  input: &quot;gradients/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/Merge&quot;\\n  input: &quot;decoder/while/LoopCond&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Add/y&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^decoder/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;gradients/Switch:1&quot;\\n  input: &quot;gradients/Add/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/Add&quot;\\n  input: &quot;^gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayWrite/TensorArrayWriteV3/f_sync&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/MatMul_1/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/MatMul_1/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/mod/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN/StackPush_1&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze_grad/Reshape/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/MatMul_1/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims_grad/Reshape/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax_grad/mul/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/Squeeze_grad/Reshape/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/MatMul_1/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims_grad/Reshape/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPush_1&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul_1/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPush_1&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPush_1&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul_1/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPush_1&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul_1/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split_grad/concat/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/StackPush_1&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/mod/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN/StackPush&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN/StackPush_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/f_count_2&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/b_count&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/b_count_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/f_count_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Merge_1&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/b_count_1&quot;\\n  input: &quot;gradients/NextIteration_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/GreaterEqual/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/b_count&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/GreaterEqual&quot;\\n  op: &quot;GreaterEqual&quot;\\n  input: &quot;gradients/Merge_1&quot;\\n  input: &quot;gradients/GreaterEqual/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/b_count_2&quot;\\n  op: &quot;LoopCond&quot;\\n  input: &quot;gradients/GreaterEqual&quot;\\n}\\nnode {\\n  name: &quot;gradients/Switch_1&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/Merge_1&quot;\\n  input: &quot;gradients/b_count_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;gradients/Switch_1:1&quot;\\n  input: &quot;gradients/GreaterEqual/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/NextIteration_1&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/Sub&quot;\\n  input: &quot;^gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/b_sync&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/b_count_3&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/Switch_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/f_count_3&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/f_count_4&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/f_count_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Merge_2&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/f_count_4&quot;\\n  input: &quot;gradients/NextIteration_2&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch_2&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/Merge_2&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/LoopCond&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Add_1/y&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^bidirectional_rnn/fw/fw/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Add_1&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;gradients/Switch_2:1&quot;\\n  input: &quot;gradients/Add_1/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/NextIteration_2&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/Add_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/zeros_like/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/Select/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/zeros_like/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/Select/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Select_grad/Select/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPush_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul_1/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPush_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPush_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/mul_1/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPush_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul_1/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split_grad/concat/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/StackPush&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/f_count_5&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/Switch_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/b_count_4&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/b_count_5&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/f_count_5&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Merge_3&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/b_count_5&quot;\\n  input: &quot;gradients/NextIteration_3&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/GreaterEqual_1/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/b_count_4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/GreaterEqual_1&quot;\\n  op: &quot;GreaterEqual&quot;\\n  input: &quot;gradients/Merge_3&quot;\\n  input: &quot;gradients/GreaterEqual_1/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/b_count_6&quot;\\n  op: &quot;LoopCond&quot;\\n  input: &quot;gradients/GreaterEqual_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/Switch_3&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/Merge_3&quot;\\n  input: &quot;gradients/b_count_6&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Sub_1&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;gradients/Switch_3:1&quot;\\n  input: &quot;gradients/GreaterEqual_1/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/NextIteration_3&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/Sub_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/zeros_like/b_sync&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/b_count_7&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/Switch_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/f_count_6&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/f_count_7&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/f_count_6&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Merge_4&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/f_count_7&quot;\\n  input: &quot;gradients/NextIteration_4&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch_4&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/Merge_4&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/LoopCond&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Add_2/y&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^bidirectional_rnn/bw/bw/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Add_2&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;gradients/Switch_4:1&quot;\\n  input: &quot;gradients/Add_2/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/NextIteration_4&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/Add_2&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/zeros_like/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/Select/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/zeros_like/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/Select/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Select_grad/Select/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs/StackPush_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul_1/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs/StackPush_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs/StackPush_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/mul_1/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs/StackPush_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul_1/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/BroadcastGradientArgs/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split_grad/concat/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/MatMul_1/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/mod/StackPush&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/ShapeN/StackPush&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/f_count_8&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/Switch_4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/b_count_8&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/b_count_9&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/f_count_8&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Merge_5&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/b_count_9&quot;\\n  input: &quot;gradients/NextIteration_5&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/GreaterEqual_2/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/b_count_8&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/GreaterEqual_2&quot;\\n  op: &quot;GreaterEqual&quot;\\n  input: &quot;gradients/Merge_5&quot;\\n  input: &quot;gradients/GreaterEqual_2/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/b_count_10&quot;\\n  op: &quot;LoopCond&quot;\\n  input: &quot;gradients/GreaterEqual_2&quot;\\n}\\nnode {\\n  name: &quot;gradients/Switch_5&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/Merge_5&quot;\\n  input: &quot;gradients/b_count_10&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Sub_2&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;gradients/Switch_5:1&quot;\\n  input: &quot;gradients/GreaterEqual_2/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/NextIteration_5&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/Sub_2&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/zeros_like/b_sync&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/b_count_11&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/Switch_5&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/Fill&quot;\\n  input: &quot;gradients/Mean_grad/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Reshape_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;gradients/Mean_grad/Reshape&quot;\\n  input: &quot;gradients/Mean_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Reshape_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Shape_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Prod&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;gradients/Mean_grad/Shape_1&quot;\\n  input: &quot;gradients/Mean_grad/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Prod_1&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;gradients/Mean_grad/Shape_2&quot;\\n  input: &quot;gradients/Mean_grad/Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Maximum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Maximum&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;gradients/Mean_grad/Prod_1&quot;\\n  input: &quot;gradients/Mean_grad/Maximum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/floordiv&quot;\\n  op: &quot;FloorDiv&quot;\\n  input: &quot;gradients/Mean_grad/Prod&quot;\\n  input: &quot;gradients/Mean_grad/Maximum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;gradients/Mean_grad/floordiv&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/truediv&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;gradients/Mean_grad/Tile&quot;\\n  input: &quot;gradients/Mean_grad/Cast&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Reshape_2_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;SoftmaxCrossEntropyWithLogits&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Reshape_2_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/Mean_grad/truediv&quot;\\n  input: &quot;gradients/Reshape_2_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;SoftmaxCrossEntropyWithLogits:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/SoftmaxCrossEntropyWithLogits_grad/ExpandDims/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/SoftmaxCrossEntropyWithLogits_grad/ExpandDims&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;gradients/Reshape_2_grad/Reshape&quot;\\n  input: &quot;gradients/SoftmaxCrossEntropyWithLogits_grad/ExpandDims/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/SoftmaxCrossEntropyWithLogits_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/SoftmaxCrossEntropyWithLogits_grad/ExpandDims&quot;\\n  input: &quot;SoftmaxCrossEntropyWithLogits:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Reshape_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;decoder/TensorArrayStack/TensorArrayGatherV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Reshape_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/SoftmaxCrossEntropyWithLogits_grad/mul&quot;\\n  input: &quot;gradients/Reshape_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  op: &quot;TensorArrayGradV3&quot;\\n  input: &quot;decoder/TensorArray&quot;\\n  input: &quot;decoder/while/Exit_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/TensorArray&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;source&quot;\\n    value {\\n      s: &quot;gradients&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayGrad/gradient_flow&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/while/Exit_1&quot;\\n  input: &quot;^gradients/decoder/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/TensorArray&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayScatter/TensorArrayScatterV3&quot;\\n  op: &quot;TensorArrayScatterV3&quot;\\n  input: &quot;gradients/decoder/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  input: &quot;decoder/TensorArrayStack/range&quot;\\n  input: &quot;gradients/Reshape_grad/Reshape&quot;\\n  input: &quot;gradients/decoder/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayGrad/gradient_flow&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_1&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;decoder/while/Exit_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_2&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;decoder/while/Exit_4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_3&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;decoder/while/Exit_5&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_4&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;decoder/while/Exit_7&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_5&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;decoder/while/Exit_8&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Exit_1_grad/b_exit&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/decoder/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayScatter/TensorArrayScatterV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Exit_2_grad/b_exit&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Exit_3_grad/b_exit&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/zeros_like_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Exit_4_grad/b_exit&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/zeros_like_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Exit_5_grad/b_exit&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/zeros_like_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Exit_7_grad/b_exit&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/zeros_like_4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Exit_8_grad/b_exit&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/zeros_like_5&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Switch_1_grad/b_switch&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/decoder/while/Exit_1_grad/b_exit&quot;\\n  input: &quot;gradients/decoder/while/Switch_1_grad_1/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Switch_3_grad/b_switch&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/decoder/while/Exit_3_grad/b_exit&quot;\\n  input: &quot;gradients/decoder/while/Switch_3_grad_1/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Switch_4_grad/b_switch&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/decoder/while/Exit_4_grad/b_exit&quot;\\n  input: &quot;gradients/decoder/while/Switch_4_grad_1/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Switch_5_grad/b_switch&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/decoder/while/Exit_5_grad/b_exit&quot;\\n  input: &quot;gradients/decoder/while/Switch_5_grad_1/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Switch_8_grad/b_switch&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/decoder/while/Exit_8_grad/b_exit&quot;\\n  input: &quot;gradients/decoder/while/Switch_8_grad_1/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Merge_1_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/decoder/while/Switch_1_grad/b_switch&quot;\\n  input: &quot;gradients/b_count_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/Switch_1_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Merge_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/decoder/while/Merge_1_grad/Switch&quot;\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Merge_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/Merge_1_grad/Switch&quot;\\n  input: &quot;^gradients/decoder/while/Merge_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/Switch_1_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Merge_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/Merge_1_grad/Switch:1&quot;\\n  input: &quot;^gradients/decoder/while/Merge_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/Switch_1_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Merge_3_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/decoder/while/Switch_3_grad/b_switch&quot;\\n  input: &quot;gradients/b_count_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/Switch_3_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Merge_3_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/decoder/while/Merge_3_grad/Switch&quot;\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Merge_3_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/Merge_3_grad/Switch&quot;\\n  input: &quot;^gradients/decoder/while/Merge_3_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/Switch_3_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Merge_3_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/Merge_3_grad/Switch:1&quot;\\n  input: &quot;^gradients/decoder/while/Merge_3_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/Switch_3_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Merge_4_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/decoder/while/Switch_4_grad/b_switch&quot;\\n  input: &quot;gradients/b_count_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/Switch_4_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Merge_4_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/decoder/while/Merge_4_grad/Switch&quot;\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Merge_4_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/Merge_4_grad/Switch&quot;\\n  input: &quot;^gradients/decoder/while/Merge_4_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/Switch_4_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Merge_4_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/Merge_4_grad/Switch:1&quot;\\n  input: &quot;^gradients/decoder/while/Merge_4_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/Switch_4_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Merge_5_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/decoder/while/Switch_5_grad/b_switch&quot;\\n  input: &quot;gradients/b_count_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/Switch_5_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Merge_5_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/decoder/while/Merge_5_grad/Switch&quot;\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Merge_5_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/Merge_5_grad/Switch&quot;\\n  input: &quot;^gradients/decoder/while/Merge_5_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/Switch_5_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Merge_5_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/Merge_5_grad/Switch:1&quot;\\n  input: &quot;^gradients/decoder/while/Merge_5_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/Switch_5_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Merge_8_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/decoder/while/Switch_8_grad/b_switch&quot;\\n  input: &quot;gradients/b_count_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/Switch_8_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Merge_8_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/decoder/while/Merge_8_grad/Switch&quot;\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Merge_8_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/Merge_8_grad/Switch&quot;\\n  input: &quot;^gradients/decoder/while/Merge_8_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/Switch_8_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Merge_8_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/Merge_8_grad/Switch:1&quot;\\n  input: &quot;^gradients/decoder/while/Merge_8_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/Switch_8_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Enter_1_grad/Exit&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/decoder/while/Merge_1_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Enter_3_grad/Exit&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/decoder/while/Merge_3_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Enter_4_grad/Exit&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/decoder/while/Merge_4_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Enter_5_grad/Exit&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/decoder/while/Merge_5_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Enter_8_grad/Exit&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/decoder/while/Merge_8_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayGrad/TensorArrayGradV3/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;decoder/TensorArray&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/dense/BiasAdd&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  op: &quot;TensorArrayGradV3&quot;\\n  input: &quot;gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayGrad/TensorArrayGradV3/Enter&quot;\\n  input: &quot;gradients/decoder/while/Merge_1_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/dense/BiasAdd&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;source&quot;\\n    value {\\n      s: &quot;gradients&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayGrad/gradient_flow&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/Merge_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;^gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/dense/BiasAdd&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Identity&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Identity&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/RefEnter&quot;\\n  input: &quot;decoder/while/Identity&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Identity&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Identity&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Identity&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/b_sync&quot;\\n  op: &quot;ControlTrigger&quot;\\n  input: &quot;^gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayWrite/TensorArrayWriteV3/StackPop&quot;\\n  input: &quot;^gradients/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/MatMul_1/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/MatMul_1/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/mod/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN/StackPop_1&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze_grad/Reshape/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/MatMul_1/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims_grad/Reshape/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax_grad/mul/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/Squeeze_grad/Reshape/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/MatMul_1/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims_grad/Reshape/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul_1/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul_1/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul_1/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split_grad/concat/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/StackPop_1&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/mod/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN/StackPop&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN/StackPop_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3&quot;\\n  op: &quot;TensorArrayReadV3&quot;\\n  input: &quot;gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  input: &quot;gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPop&quot;\\n  input: &quot;gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayGrad/gradient_flow&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/decoder/while/Merge_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;^gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3&quot;\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3&quot;\\n  input: &quot;^gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/Merge_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;^gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/Switch_1_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_1_grad/Rank&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_1_grad/mod&quot;\\n  op: &quot;FloorMod&quot;\\n  input: &quot;concat_1/axis&quot;\\n  input: &quot;gradients/concat_1_grad/Rank&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_1_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Exit_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_1_grad/ShapeN&quot;\\n  op: &quot;ShapeN&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Exit_2&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Exit_2&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_1_grad/ConcatOffset&quot;\\n  op: &quot;ConcatOffset&quot;\\n  input: &quot;gradients/concat_1_grad/mod&quot;\\n  input: &quot;gradients/concat_1_grad/ShapeN&quot;\\n  input: &quot;gradients/concat_1_grad/ShapeN:1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_1_grad/Slice&quot;\\n  op: &quot;Slice&quot;\\n  input: &quot;gradients/decoder/while/Enter_3_grad/Exit&quot;\\n  input: &quot;gradients/concat_1_grad/ConcatOffset&quot;\\n  input: &quot;gradients/concat_1_grad/ShapeN&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_1_grad/Slice_1&quot;\\n  op: &quot;Slice&quot;\\n  input: &quot;gradients/decoder/while/Enter_3_grad/Exit&quot;\\n  input: &quot;gradients/concat_1_grad/ConcatOffset:1&quot;\\n  input: &quot;gradients/concat_1_grad/ShapeN:1&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/concat_1_grad/Slice&quot;\\n  input: &quot;^gradients/concat_1_grad/Slice_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/concat_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/concat_1_grad/Slice&quot;\\n  input: &quot;^gradients/concat_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/concat_1_grad/Slice&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/concat_1_grad/Slice_1&quot;\\n  input: &quot;^gradients/concat_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/concat_1_grad/Slice_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_2_grad/Rank&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_2_grad/mod&quot;\\n  op: &quot;FloorMod&quot;\\n  input: &quot;concat_2/axis&quot;\\n  input: &quot;gradients/concat_2_grad/Rank&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_2_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Exit_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_2_grad/ShapeN&quot;\\n  op: &quot;ShapeN&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Exit_3&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Exit_3&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_2_grad/ConcatOffset&quot;\\n  op: &quot;ConcatOffset&quot;\\n  input: &quot;gradients/concat_2_grad/mod&quot;\\n  input: &quot;gradients/concat_2_grad/ShapeN&quot;\\n  input: &quot;gradients/concat_2_grad/ShapeN:1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_2_grad/Slice&quot;\\n  op: &quot;Slice&quot;\\n  input: &quot;gradients/decoder/while/Enter_4_grad/Exit&quot;\\n  input: &quot;gradients/concat_2_grad/ConcatOffset&quot;\\n  input: &quot;gradients/concat_2_grad/ShapeN&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_2_grad/Slice_1&quot;\\n  op: &quot;Slice&quot;\\n  input: &quot;gradients/decoder/while/Enter_4_grad/Exit&quot;\\n  input: &quot;gradients/concat_2_grad/ConcatOffset:1&quot;\\n  input: &quot;gradients/concat_2_grad/ShapeN:1&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_2_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/concat_2_grad/Slice&quot;\\n  input: &quot;^gradients/concat_2_grad/Slice_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/concat_2_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/concat_2_grad/Slice&quot;\\n  input: &quot;^gradients/concat_2_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/concat_2_grad/Slice&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_2_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/concat_2_grad/Slice_1&quot;\\n  input: &quot;^gradients/concat_2_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/concat_2_grad/Slice_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/TrainingHelperInitialize/cond/Merge_grad/cond_grad&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/decoder/while/Enter_8_grad/Exit&quot;\\n  input: &quot;decoder/TrainingHelperInitialize/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/Enter_8_grad/Exit&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/TrainingHelperInitialize/cond/Merge_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/decoder/TrainingHelperInitialize/cond/Merge_grad/cond_grad&quot;\\n}\\nnode {\\n  name: &quot;gradients/decoder/TrainingHelperInitialize/cond/Merge_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/TrainingHelperInitialize/cond/Merge_grad/cond_grad&quot;\\n  input: &quot;^gradients/decoder/TrainingHelperInitialize/cond/Merge_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/Enter_8_grad/Exit&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/TrainingHelperInitialize/cond/Merge_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/TrainingHelperInitialize/cond/Merge_grad/cond_grad:1&quot;\\n  input: &quot;^gradients/decoder/TrainingHelperInitialize/cond/Merge_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/Enter_8_grad/Exit&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/pred_id&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/pred_id&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/RefEnter&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/pred_id&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/pred_id&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/pred_id&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/pred_id&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/cond_grad&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/decoder/while/Merge_8_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/Switch_8_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/cond_grad&quot;\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/cond_grad&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/Switch_8_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/cond_grad:1&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/Switch_8_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/BiasAdd_grad/BiasAddGrad&quot;\\n  op: &quot;BiasAddGrad&quot;\\n  input: &quot;gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/BiasAdd_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/control_dependency&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/dense/BiasAdd_grad/BiasAddGrad&quot;\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/BiasAdd_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/control_dependency&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/dense/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/BiasAdd_grad/BiasAddGrad&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/dense/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/dense/BiasAdd_grad/BiasAddGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/TrainingHelperInitialize/cond/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  op: &quot;TensorArrayGradV3&quot;\\n  input: &quot;decoder/TrainingHelperInitialize/cond/TensorArrayReadV3/Switch&quot;\\n  input: &quot;decoder/TrainingHelperInitialize/cond/TensorArrayReadV3/Switch_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@TrainingHelper/TensorArray&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;source&quot;\\n    value {\\n      s: &quot;gradients&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/TrainingHelperInitialize/cond/TensorArrayReadV3_grad/TensorArrayGrad/gradient_flow&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/TrainingHelperInitialize/cond/TensorArrayReadV3/Switch_1&quot;\\n  input: &quot;^gradients/decoder/TrainingHelperInitialize/cond/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@TrainingHelper/TensorArray&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/TrainingHelperInitialize/cond/TensorArrayReadV3_grad/TensorArrayWrite/TensorArrayWriteV3&quot;\\n  op: &quot;TensorArrayWriteV3&quot;\\n  input: &quot;gradients/decoder/TrainingHelperInitialize/cond/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  input: &quot;decoder/TrainingHelperInitialize/cond/TensorArrayReadV3/index&quot;\\n  input: &quot;gradients/decoder/TrainingHelperInitialize/cond/Merge_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/decoder/TrainingHelperInitialize/cond/TensorArrayReadV3_grad/TensorArrayGrad/gradient_flow&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch_6&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;TrainingHelper/zeros_like&quot;\\n  input: &quot;decoder/TrainingHelperInitialize/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;gradients/Switch_6&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_1/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_1&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape_1&quot;\\n  input: &quot;gradients/zeros_1/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/TrainingHelperInitialize/cond/Switch_1_grad/cond_grad&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/decoder/TrainingHelperInitialize/cond/Merge_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/zeros_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;TrainingHelper/TensorArray&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Enter&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3/Enter_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;TrainingHelper/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Enter&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  op: &quot;TensorArrayGradV3&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3/Enter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3/Enter_1&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Enter&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;source&quot;\\n    value {\\n      s: &quot;gradients&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayGrad/gradient_flow&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3/Enter_1&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Enter&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayWrite/TensorArrayWriteV3/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/TrainingHelperNextInputs/add&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayWrite/TensorArrayWriteV3/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayWrite/TensorArrayWriteV3/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/TrainingHelperNextInputs/add&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayWrite/TensorArrayWriteV3/StackPush/Switch&quot;\\n  op: &quot;RefSwitch&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayWrite/TensorArrayWriteV3/RefEnter&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/TrainingHelperNextInputs/add&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayWrite/TensorArrayWriteV3/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayWrite/TensorArrayWriteV3/StackPush/Switch&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Switch_1&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/TrainingHelperNextInputs/add&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayWrite/TensorArrayWriteV3/f_sync&quot;\\n  op: &quot;ControlTrigger&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayWrite/TensorArrayWriteV3/StackPush&quot;\\n  input: &quot;^gradients/StackPush&quot;\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayWrite/TensorArrayWriteV3/Switch/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayWrite/TensorArrayWriteV3/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/TrainingHelperNextInputs/add&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayWrite/TensorArrayWriteV3/Switch&quot;\\n  op: &quot;RefSwitch&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayWrite/TensorArrayWriteV3/Switch/RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/TrainingHelperNextInputs/add&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayWrite/TensorArrayWriteV3/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayWrite/TensorArrayWriteV3/Switch&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/TrainingHelperNextInputs/add&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayWrite/TensorArrayWriteV3&quot;\\n  op: &quot;TensorArrayWriteV3&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayWrite/TensorArrayWriteV3/StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayGrad/gradient_flow&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch_7&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Enter&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Enter&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape_2&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;gradients/Switch_7&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Shape_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Shape_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/RefEnter&quot;\\n  input: &quot;gradients/Shape_2&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Shape_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch_8/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Shape_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch_8&quot;\\n  op: &quot;RefSwitch&quot;\\n  input: &quot;gradients/Switch_8/RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Shape_2&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/Switch_8&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Shape_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_2/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_2&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/StackPop&quot;\\n  input: &quot;gradients/zeros_2/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Switch_1_grad/cond_grad&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/zeros_2&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/MatMul/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;decoder/dense/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/BiasAdd_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/MatMul/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/MatMul_1/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/MatMul_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/MatMul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/MatMul_1/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/MatMul_1/RefEnter&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_2&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/MatMul_1/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/MatMul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/MatMul_1/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/MatMul_1/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/MatMul_1/StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/BiasAdd_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/BiasAdd/Enter_grad/b_acc&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 10\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/BiasAdd/Enter_grad/b_acc_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/BiasAdd/Enter_grad/b_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/BiasAdd/Enter_grad/b_acc_2&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/BiasAdd/Enter_grad/b_acc_1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/BiasAdd/Enter_grad/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/BiasAdd/Enter_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/BiasAdd/Enter_grad/b_acc_2&quot;\\n  input: &quot;gradients/b_count_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/BiasAdd/Enter_grad/Add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/BiasAdd/Enter_grad/Switch:1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/BiasAdd/Enter_grad/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/BiasAdd/Enter_grad/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/BiasAdd/Enter_grad/b_acc_3&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/BiasAdd/Enter_grad/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Switch_1_grad_1/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch_9&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;TrainingHelper/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3&quot;\\n  input: &quot;decoder/TrainingHelperInitialize/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape_3&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;gradients/Switch_9:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_3/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_3&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape_3&quot;\\n  input: &quot;gradients/zeros_3/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/TrainingHelperInitialize/cond/TensorArrayReadV3/Switch_1_grad/cond_grad&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/decoder/TrainingHelperInitialize/cond/TensorArrayReadV3_grad/TensorArrayWrite/TensorArrayWriteV3&quot;\\n  input: &quot;gradients/zeros_3&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Const_1&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch_10&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/Const_1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Const_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Switch_2_grad/cond_grad&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayWrite/TensorArrayWriteV3&quot;\\n  input: &quot;gradients/Switch_10:1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Enter_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;TrainingHelper/zeros_like&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Enter_grad/zeros/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Enter_grad/zeros&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Enter_grad/Shape&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Enter_grad/zeros/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Enter_grad/b_acc&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Enter_grad/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Enter_grad/b_acc_1&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Enter_grad/b_acc&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Enter_grad/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Enter_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Enter_grad/b_acc_1&quot;\\n  input: &quot;gradients/b_count_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Enter_grad/Add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Enter_grad/Switch:1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Switch_1_grad/cond_grad&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Enter_grad/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Enter_grad/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Enter_grad/b_acc_2&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Enter_grad/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/decoder/while/Merge_5_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/Switch_5_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul/Enter_grad/b_acc&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 32\\n          }\\n          dim {\\n            size: 10\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul/Enter_grad/b_acc_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul/Enter_grad/b_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul/Enter_grad/b_acc_2&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul/Enter_grad/b_acc_1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul/Enter_grad/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul/Enter_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul/Enter_grad/b_acc_2&quot;\\n  input: &quot;gradients/b_count_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul/Enter_grad/Add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul/Enter_grad/Switch:1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul/Enter_grad/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul/Enter_grad/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul/Enter_grad/b_acc_3&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul/Enter_grad/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Enter_1_grad/b_acc&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Enter_1_grad/b_acc_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Enter_1_grad/b_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Enter_1_grad/b_acc_2&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Enter_1_grad/b_acc_1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Enter_1_grad/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Enter_1_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Enter_1_grad/b_acc_2&quot;\\n  input: &quot;gradients/b_count_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Enter_1_grad/Add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Enter_1_grad/Switch:1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Switch_2_grad/cond_grad&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Enter_1_grad/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Enter_1_grad/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Enter_1_grad/b_acc_3&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Enter_1_grad/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_1&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/decoder/TrainingHelperInitialize/cond/Switch_1_grad/cond_grad&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Enter_grad/b_acc_2&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/TrainingHelperInitialize/cond/Switch_1_grad/cond_grad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/MatMul/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;decoder/attention_wrapper/attention_layer/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradients/AddN&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/MatMul/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/MatMul_1/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/MatMul_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/MatMul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/MatMul_1/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/MatMul_1/RefEnter&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/MatMul_1/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/MatMul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/MatMul_1/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/MatMul_1/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/MatMul_1/StackPop&quot;\\n  input: &quot;gradients/AddN&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_2&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/decoder/TrainingHelperInitialize/cond/TensorArrayReadV3/Switch_1_grad/cond_grad&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3/Enter_1_grad/b_acc_3&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/TrainingHelperInitialize/cond/TensorArrayReadV3/Switch_1_grad/cond_grad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/TrainingHelper/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  op: &quot;TensorArrayGradV3&quot;\\n  input: &quot;TrainingHelper/TensorArray&quot;\\n  input: &quot;gradients/AddN_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@TrainingHelper/TensorArray&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;source&quot;\\n    value {\\n      s: &quot;gradients&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/TrainingHelper/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGrad/gradient_flow&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/AddN_2&quot;\\n  input: &quot;^gradients/TrainingHelper/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@TrainingHelper/TensorArray&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/TrainingHelper/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGatherV3&quot;\\n  op: &quot;TensorArrayGatherV3&quot;\\n  input: &quot;gradients/TrainingHelper/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  input: &quot;TrainingHelper/TensorArrayUnstack/range&quot;\\n  input: &quot;gradients/TrainingHelper/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGrad/gradient_flow&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;element_shape&quot;\\n    value {\\n      shape {\\n        unknown_rank: true\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/TrainingHelper/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/AddN_2&quot;\\n  input: &quot;^gradients/TrainingHelper/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGatherV3&quot;\\n}\\nnode {\\n  name: &quot;gradients/TrainingHelper/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/TrainingHelper/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGatherV3&quot;\\n  input: &quot;^gradients/TrainingHelper/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/TrainingHelper/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGatherV3&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/TrainingHelper/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/AddN_2&quot;\\n  input: &quot;^gradients/TrainingHelper/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/TrainingHelperInitialize/cond/TensorArrayReadV3/Switch_1_grad/cond_grad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/Rank&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/mod/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1/axis&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/mod/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/mod/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1/axis&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/mod/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/mod/RefEnter&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1/axis&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1/axis&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/mod/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/mod/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1/axis&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/mod/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/mod/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1/axis&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/mod&quot;\\n  op: &quot;FloorMod&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/mod/StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/Rank&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/checked_cell_output&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/checked_cell_output&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/checked_cell_output&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN/RefEnter&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/checked_cell_output&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/checked_cell_output&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/checked_cell_output&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/checked_cell_output&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN/f_acc_1&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN/RefEnter_1&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN/StackPush_1&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN/RefEnter_1&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN/StackPop_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN/StackPop_1&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN/StackPop_1/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN&quot;\\n  op: &quot;ShapeN&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN/StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN/StackPop_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ConcatOffset&quot;\\n  op: &quot;ConcatOffset&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/mod&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN:1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/Slice&quot;\\n  op: &quot;Slice&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ConcatOffset&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/Slice_1&quot;\\n  op: &quot;Slice&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ConcatOffset:1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/ShapeN:1&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/Slice&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/Slice_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/Slice&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/Slice&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/Slice_1&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/Slice_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul/Enter_grad/b_acc&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 64\\n          }\\n          dim {\\n            size: 32\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul/Enter_grad/b_acc_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul/Enter_grad/b_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul/Enter_grad/b_acc_2&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul/Enter_grad/b_acc_1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul/Enter_grad/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul/Enter_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul/Enter_grad/b_acc_2&quot;\\n  input: &quot;gradients/b_count_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul/Enter_grad/Add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul/Enter_grad/Switch:1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul/Enter_grad/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul/Enter_grad/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul/Enter_grad/b_acc_3&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul/Enter_grad/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze_grad/Reshape/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze_grad/Reshape/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze_grad/Reshape/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze_grad/Reshape/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze_grad/Reshape/RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze_grad/Shape&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze_grad/Reshape/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze_grad/Reshape/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze_grad/Reshape/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze_grad/Reshape/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze_grad/Reshape/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/MatMul/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;transpose&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/MatMul&quot;\\n  op: &quot;BatchMatMul&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze_grad/Reshape&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/MatMul/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;adj_x&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;adj_y&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/MatMul_1/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/MatMul_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/MatMul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/MatMul_1/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/MatMul_1/RefEnter&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/MatMul_1/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/MatMul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/MatMul_1/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/MatMul_1/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/MatMul_1&quot;\\n  op: &quot;BatchMatMul&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/MatMul_1/StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Squeeze_grad/Reshape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;adj_x&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;adj_y&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims_grad/Reshape/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims_grad/Reshape/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims_grad/Reshape/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims_grad/Reshape/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims_grad/Reshape/RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims_grad/Shape&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims_grad/Reshape/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims_grad/Reshape/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims_grad/Reshape/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims_grad/Reshape/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims_grad/Reshape/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul/Enter_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;transpose&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul/Enter_grad/zeros/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul/Enter_grad/zeros&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul/Enter_grad/Shape&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul/Enter_grad/zeros/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul/Enter_grad/b_acc&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul/Enter_grad/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul/Enter_grad/b_acc_1&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul/Enter_grad/b_acc&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul/Enter_grad/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul/Enter_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul/Enter_grad/b_acc_1&quot;\\n  input: &quot;gradients/b_count_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul/Enter_grad/Add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul/Enter_grad/Switch:1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul/Enter_grad/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul/Enter_grad/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul/Enter_grad/b_acc_2&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul/Enter_grad/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/embedding_lookup_1_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT64\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\n\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\024\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/embedding_lookup_1_grad/ToInt32&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;gradients/embedding_lookup_1_grad/Shape&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/embedding_lookup_1_grad/Size&quot;\\n  op: &quot;Size&quot;\\n  input: &quot;ones&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/embedding_lookup_1_grad/ExpandDims/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/embedding_lookup_1_grad/ExpandDims&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;gradients/embedding_lookup_1_grad/Size&quot;\\n  input: &quot;gradients/embedding_lookup_1_grad/ExpandDims/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/embedding_lookup_1_grad/strided_slice/stack&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/embedding_lookup_1_grad/strided_slice/stack_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/embedding_lookup_1_grad/strided_slice/stack_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/embedding_lookup_1_grad/strided_slice&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;gradients/embedding_lookup_1_grad/ToInt32&quot;\\n  input: &quot;gradients/embedding_lookup_1_grad/strided_slice/stack&quot;\\n  input: &quot;gradients/embedding_lookup_1_grad/strided_slice/stack_1&quot;\\n  input: &quot;gradients/embedding_lookup_1_grad/strided_slice/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/embedding_lookup_1_grad/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/embedding_lookup_1_grad/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;gradients/embedding_lookup_1_grad/ExpandDims&quot;\\n  input: &quot;gradients/embedding_lookup_1_grad/strided_slice&quot;\\n  input: &quot;gradients/embedding_lookup_1_grad/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/embedding_lookup_1_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/TrainingHelper/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/embedding_lookup_1_grad/concat&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/embedding_lookup_1_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;ones&quot;\\n  input: &quot;gradients/embedding_lookup_1_grad/ExpandDims&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax_grad/mul/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax_grad/mul/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax_grad/mul/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax_grad/mul/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax_grad/mul/RefEnter&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax_grad/mul/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax_grad/mul/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax_grad/mul/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax_grad/mul/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims_grad/Reshape&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax_grad/mul/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax_grad/Sum/reduction_indices&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax_grad/mul&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax_grad/Sum/reduction_indices&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax_grad/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\377\\\\377\\\\377\\\\377\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax_grad/Sum&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax_grad/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax_grad/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/ExpandDims_grad/Reshape&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax_grad/Reshape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax_grad/sub&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax_grad/mul/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/Squeeze_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/Squeeze_grad/Reshape/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/Squeeze_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/Squeeze_grad/Reshape/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/Squeeze_grad/Reshape/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/Squeeze_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/Squeeze_grad/Reshape/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/Squeeze_grad/Reshape/RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/Squeeze_grad/Shape&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/Squeeze_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/Squeeze_grad/Reshape/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/Squeeze_grad/Reshape/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/Squeeze_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/Squeeze_grad/Reshape/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/Squeeze_grad/Reshape/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/Squeeze_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/Squeeze_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/Softmax_grad/mul_1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/Squeeze_grad/Reshape/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/MatMul/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/MatMul&quot;\\n  op: &quot;BatchMatMul&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/Squeeze_grad/Reshape&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/MatMul/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;adj_x&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;adj_y&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/MatMul_1/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/MatMul_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/MatMul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/MatMul_1/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/MatMul_1/RefEnter&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/MatMul_1/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/MatMul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/MatMul_1/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/MatMul_1/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/MatMul_1&quot;\\n  op: &quot;BatchMatMul&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/Squeeze_grad/Reshape&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/MatMul_1/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;adj_x&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;adj_y&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/checked_cell_output&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims_grad/Reshape/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims_grad/Reshape/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims_grad/Reshape/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims_grad/Reshape/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims_grad/Reshape/RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims_grad/Shape&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims_grad/Reshape/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims_grad/Reshape/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims_grad/Reshape/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims_grad/Reshape/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims_grad/Reshape/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul/Enter_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul/Enter_grad/zeros/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul/Enter_grad/zeros&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul/Enter_grad/Shape&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul/Enter_grad/zeros/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul/Enter_grad/b_acc&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul/Enter_grad/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul/Enter_grad/b_acc_1&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul/Enter_grad/b_acc&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul/Enter_grad/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul/Enter_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul/Enter_grad/b_acc_1&quot;\\n  input: &quot;gradients/b_count_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul/Enter_grad/Add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul/Enter_grad/Switch:1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul/Enter_grad/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul/Enter_grad/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul/Enter_grad/b_acc_2&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul/Enter_grad/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_3&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/ExpandDims_grad/Reshape&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_1_grad/Slice&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/LuongAttention/memory_layer/Tensordot_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/MatMul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/LuongAttention/memory_layer/Tensordot_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/luong_attention/MatMul/Enter_grad/b_acc_2&quot;\\n  input: &quot;gradients/LuongAttention/memory_layer/Tensordot_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_4&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/decoder/while/Merge_4_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/AddN_3&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/Switch_4_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Tanh_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/Shape&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/RefEnter_1&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPush_1&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/RefEnter_1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/Shape_1&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPop_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPop_1/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Tanh_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Tanh_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul/RefEnter&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Tanh_1&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Tanh_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Tanh_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Tanh_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/AddN_4&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/Sum&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul_1/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul_1/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul_1/RefEnter&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid_2&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul_1/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul_1/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul_1/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul_1/StackPop&quot;\\n  input: &quot;gradients/AddN_4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul_1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/Sum_1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/Reshape&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/Reshape&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/Reshape_1&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/LuongAttention/memory_layer/Tensordot/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradients/LuongAttention/memory_layer/Tensordot_grad/Reshape&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/Reshape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/LuongAttention/memory_layer/Tensordot/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/Reshape&quot;\\n  input: &quot;gradients/LuongAttention/memory_layer/Tensordot_grad/Reshape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/LuongAttention/memory_layer/Tensordot/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/LuongAttention/memory_layer/Tensordot/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/LuongAttention/memory_layer/Tensordot/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/LuongAttention/memory_layer/Tensordot/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/LuongAttention/memory_layer/Tensordot/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/LuongAttention/memory_layer/Tensordot/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/LuongAttention/memory_layer/Tensordot/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/LuongAttention/memory_layer/Tensordot/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/LuongAttention/memory_layer/Tensordot/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^gradients/LuongAttention/memory_layer/Tensordot/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/LuongAttention/memory_layer/Tensordot/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid_2_grad/SigmoidGrad&quot;\\n  op: &quot;SigmoidGrad&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul_1/StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Tanh_1_grad/TanhGrad&quot;\\n  op: &quot;TanhGrad&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/mul/StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_2_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/LuongAttention/memory_layer/Tensordot/Reshape_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/transpose&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/LuongAttention/memory_layer/Tensordot/Reshape_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/LuongAttention/memory_layer/Tensordot/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/LuongAttention/memory_layer/Tensordot/Reshape_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/LuongAttention/memory_layer/Tensordot/Reshape_1_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot; \\\\000\\\\000\\\\000 \\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/LuongAttention/memory_layer/Tensordot/Reshape_1_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/LuongAttention/memory_layer/Tensordot/MatMul_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/LuongAttention/memory_layer/Tensordot/Reshape_1_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_5&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/decoder/while/Merge_3_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Tanh_1_grad/TanhGrad&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/Switch_3_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/Shape&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/RefEnter_1&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPush_1&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/RefEnter_1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/Shape_1&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPop_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPop_1/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/AddN_5&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/Sum&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/AddN_5&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/Sum_1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/Reshape&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/Reshape&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/Reshape_1&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/LuongAttention/memory_layer/Tensordot/transpose_grad/InvertPermutation&quot;\\n  op: &quot;InvertPermutation&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/concat_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/LuongAttention/memory_layer/Tensordot/transpose_grad/transpose&quot;\\n  op: &quot;Transpose&quot;\\n  input: &quot;gradients/LuongAttention/memory_layer/Tensordot/Reshape_grad/Reshape&quot;\\n  input: &quot;gradients/LuongAttention/memory_layer/Tensordot/transpose_grad/InvertPermutation&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tperm&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/LuongAttention/memory_layer/Tensordot/transpose_1_grad/InvertPermutation&quot;\\n  op: &quot;InvertPermutation&quot;\\n  input: &quot;LuongAttention/memory_layer/Tensordot/transpose_1/perm&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/LuongAttention/memory_layer/Tensordot/transpose_1_grad/transpose&quot;\\n  op: &quot;Transpose&quot;\\n  input: &quot;gradients/LuongAttention/memory_layer/Tensordot/Reshape_1_grad/Reshape&quot;\\n  input: &quot;gradients/LuongAttention/memory_layer/Tensordot/transpose_1_grad/InvertPermutation&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tperm&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;decoder/while/Identity_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/Shape&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/RefEnter_1&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPush_1&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/RefEnter_1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/Shape_1&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPop_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPop_1/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Identity_3&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Identity_3&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul/RefEnter&quot;\\n  input: &quot;decoder/while/Identity_3&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Identity_3&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Identity_3&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Identity_3&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/Sum&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul_1/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul_1/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul_1/RefEnter&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul_1/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul_1/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul_1/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul_1/StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul_1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/Sum_1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/Reshape&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/Reshape&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/Reshape_1&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Tanh&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/Shape&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/RefEnter_1&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPush_1&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/RefEnter_1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/Shape_1&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPop_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPop_1/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Tanh&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Tanh&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul/RefEnter&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Tanh&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Tanh&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Tanh&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Tanh&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/Sum&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul_1/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul_1/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul_1/RefEnter&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid_1&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul_1/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul_1/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul_1/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul_1/StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_1_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul_1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/Sum_1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/Reshape&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/Reshape&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/Reshape_1&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid_grad/SigmoidGrad&quot;\\n  op: &quot;SigmoidGrad&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/mul_1/StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid_1_grad/SigmoidGrad&quot;\\n  op: &quot;SigmoidGrad&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul_1/StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Tanh_grad/TanhGrad&quot;\\n  op: &quot;TanhGrad&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/mul/StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_1_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split:2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs/RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/Shape&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid_grad/SigmoidGrad&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/Sum&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid_grad/SigmoidGrad&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/Sum_1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/Reshape&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/Reshape&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/Reshape_1&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Switch_3_grad_1/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/mul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split_grad/concat/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split/split_dim&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split_grad/concat/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split_grad/concat/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split/split_dim&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split_grad/concat/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split_grad/concat/RefEnter&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split/split_dim&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split/split_dim&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split_grad/concat/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split_grad/concat/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split/split_dim&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split_grad/concat/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split_grad/concat/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split/split_dim&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split_grad/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid_1_grad/SigmoidGrad&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Tanh_grad/TanhGrad&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/add_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/Sigmoid_2_grad/SigmoidGrad&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split_grad/concat/StackPop&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 4\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_6&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul/Enter_grad/b_acc_2&quot;\\n  input: &quot;gradients/LuongAttention/memory_layer/Tensordot/transpose_grad/transpose&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/MatMul/Enter_grad/b_acc_2&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/transpose_grad/InvertPermutation&quot;\\n  op: &quot;InvertPermutation&quot;\\n  input: &quot;transpose/perm&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/transpose_grad/transpose&quot;\\n  op: &quot;Transpose&quot;\\n  input: &quot;gradients/AddN_6&quot;\\n  input: &quot;gradients/transpose_grad/InvertPermutation&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tperm&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd_grad/BiasAddGrad&quot;\\n  op: &quot;BiasAddGrad&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split_grad/concat&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split_grad/concat&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd_grad/BiasAddGrad&quot;\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split_grad/concat&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/split_grad/concat&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd_grad/BiasAddGrad&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd_grad/BiasAddGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_grad/Rank&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 3\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_grad/mod&quot;\\n  op: &quot;FloorMod&quot;\\n  input: &quot;concat/axis&quot;\\n  input: &quot;gradients/concat_grad/Rank&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArrayStack/TensorArrayGatherV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_grad/ShapeN&quot;\\n  op: &quot;ShapeN&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArrayStack/TensorArrayGatherV3&quot;\\n  input: &quot;ReverseSequence&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_grad/ConcatOffset&quot;\\n  op: &quot;ConcatOffset&quot;\\n  input: &quot;gradients/concat_grad/mod&quot;\\n  input: &quot;gradients/concat_grad/ShapeN&quot;\\n  input: &quot;gradients/concat_grad/ShapeN:1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_grad/Slice&quot;\\n  op: &quot;Slice&quot;\\n  input: &quot;gradients/transpose_grad/transpose&quot;\\n  input: &quot;gradients/concat_grad/ConcatOffset&quot;\\n  input: &quot;gradients/concat_grad/ShapeN&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_grad/Slice_1&quot;\\n  op: &quot;Slice&quot;\\n  input: &quot;gradients/transpose_grad/transpose&quot;\\n  input: &quot;gradients/concat_grad/ConcatOffset:1&quot;\\n  input: &quot;gradients/concat_grad/ShapeN:1&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/concat_grad/Slice&quot;\\n  input: &quot;^gradients/concat_grad/Slice_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/concat_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/concat_grad/Slice&quot;\\n  input: &quot;^gradients/concat_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/concat_grad/Slice&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/concat_grad/Slice_1&quot;\\n  input: &quot;^gradients/concat_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/concat_grad/Slice_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1/RefEnter&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1/StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/b_acc&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 128\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/b_acc_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/b_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/b_acc_2&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/b_acc_1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/b_acc_2&quot;\\n  input: &quot;gradients/b_count_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/Add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/Switch:1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/b_acc_3&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  op: &quot;TensorArrayGradV3&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArray&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Exit_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/TensorArray&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;source&quot;\\n    value {\\n      s: &quot;gradients&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayGrad/gradient_flow&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Exit_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/TensorArray&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayScatter/TensorArrayScatterV3&quot;\\n  op: &quot;TensorArrayScatterV3&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArrayStack/range&quot;\\n  input: &quot;gradients/concat_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayGrad/gradient_flow&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/ReverseSequence_grad/ReverseSequence&quot;\\n  op: &quot;ReverseSequence&quot;\\n  input: &quot;gradients/concat_grad/tuple/control_dependency_1&quot;\\n  input: &quot;encoder_inputs_length&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tlen&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;batch_dim&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;seq_dim&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/Rank&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat/axis&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat/axis&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod/RefEnter&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat/axis&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat/axis&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat/axis&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat/axis&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod&quot;\\n  op: &quot;FloorMod&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod/StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/Rank&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/RefEnter&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/f_acc_1&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Identity_4&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/RefEnter_1&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Identity_4&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/StackPush_1&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/RefEnter_1&quot;\\n  input: &quot;decoder/while/Identity_4&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Identity_4&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/StackPop_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Identity_4&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/StackPop_1&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/StackPop_1/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Identity_4&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN&quot;\\n  op: &quot;ShapeN&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/StackPop_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ConcatOffset&quot;\\n  op: &quot;ConcatOffset&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN:1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/Slice&quot;\\n  op: &quot;Slice&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ConcatOffset&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/Slice_1&quot;\\n  op: &quot;Slice&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ConcatOffset:1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN:1&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/Slice&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/Slice_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/Slice&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/Slice&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/Slice_1&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/Slice_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/b_acc&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 84\\n          }\\n          dim {\\n            size: 128\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/b_acc_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/b_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/b_acc_2&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/b_acc_1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/b_acc_2&quot;\\n  input: &quot;gradients/b_count_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/Add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/Switch:1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/b_acc_3&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  op: &quot;TensorArrayGradV3&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArray&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Exit_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/TensorArray&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;source&quot;\\n    value {\\n      s: &quot;gradients&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayGrad/gradient_flow&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Exit_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/TensorArray&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayScatter/TensorArrayScatterV3&quot;\\n  op: &quot;TensorArrayScatterV3&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArrayStack/range&quot;\\n  input: &quot;gradients/ReverseSequence_grad/ReverseSequence&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayGrad/gradient_flow&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/Rank&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/mod/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat/axis&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/mod/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/mod/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat/axis&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/mod/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/mod/RefEnter&quot;\\n  input: &quot;decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat/axis&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat/axis&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/mod/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/mod/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat/axis&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/mod/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/mod/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat/axis&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/mod&quot;\\n  op: &quot;FloorMod&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/mod/StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/Rank&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;decoder/while/Identity_8&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Identity_8&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Identity_8&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN/RefEnter&quot;\\n  input: &quot;decoder/while/Identity_8&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Identity_8&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Identity_8&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Identity_8&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN/f_acc_1&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Identity_5&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN/RefEnter_1&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Identity_5&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN/StackPush_1&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN/RefEnter_1&quot;\\n  input: &quot;decoder/while/Identity_5&quot;\\n  input: &quot;^gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Identity_5&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN/StackPop_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Identity_5&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/decoder/while/decoder/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN/StackPop_1&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN/StackPop_1/RefEnter&quot;\\n  input: &quot;^gradients/Sub&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/while/Identity_5&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN&quot;\\n  op: &quot;ShapeN&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN/StackPop&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN/StackPop_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ConcatOffset&quot;\\n  op: &quot;ConcatOffset&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/mod&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN:1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/Slice&quot;\\n  op: &quot;Slice&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ConcatOffset&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/Slice_1&quot;\\n  op: &quot;Slice&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ConcatOffset:1&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/ShapeN:1&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/Slice&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/Slice_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/Slice&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/Slice&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/Slice_1&quot;\\n  input: &quot;^gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/Slice_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Switch_4_grad_1/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/concat_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Exit_2_grad/b_exit&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/concat_1_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Exit_3_grad/b_exit&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/concat_2_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Exit_1_grad/b_exit&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayScatter/TensorArrayScatterV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Switch_8_grad_1/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/decoder/while/Switch_5_grad_1/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/concat_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Switch_2_grad/b_switch&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Exit_2_grad/b_exit&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Switch_2_grad_1/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Switch_3_grad/b_switch&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Exit_3_grad/b_exit&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Switch_3_grad_1/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Switch_1_grad/b_switch&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Exit_1_grad/b_exit&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Switch_1_grad_1/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Exit_2_grad/b_exit&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/concat_1_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Exit_3_grad/b_exit&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/concat_2_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Exit_1_grad/b_exit&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayScatter/TensorArrayScatterV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_2_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Switch_2_grad/b_switch&quot;\\n  input: &quot;gradients/b_count_6&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/Switch_2_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_2_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Merge_2_grad/Switch&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_2_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_2_grad/Switch&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Merge_2_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/Switch_2_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_2_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_2_grad/Switch:1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Merge_2_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/Switch_2_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_3_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Switch_3_grad/b_switch&quot;\\n  input: &quot;gradients/b_count_6&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/Switch_3_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_3_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Merge_3_grad/Switch&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_3_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_3_grad/Switch&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Merge_3_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/Switch_3_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_3_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_3_grad/Switch:1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Merge_3_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/Switch_3_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_1_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Switch_1_grad/b_switch&quot;\\n  input: &quot;gradients/b_count_6&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/Switch_1_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Merge_1_grad/Switch&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_1_grad/Switch&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Merge_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/Switch_1_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_1_grad/Switch:1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Merge_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/Switch_1_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Switch_2_grad/b_switch&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Exit_2_grad/b_exit&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Switch_2_grad_1/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Switch_3_grad/b_switch&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Exit_3_grad/b_exit&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Switch_3_grad_1/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Switch_1_grad/b_switch&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Exit_1_grad/b_exit&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Switch_1_grad_1/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Enter_2_grad/Exit&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_2_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Enter_3_grad/Exit&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_3_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Enter_1_grad/Exit&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_1_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_2_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Switch_2_grad/b_switch&quot;\\n  input: &quot;gradients/b_count_10&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/bw/bw/while/Switch_2_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_2_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Merge_2_grad/Switch&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_2_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_2_grad/Switch&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Merge_2_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/bw/bw/while/Switch_2_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_2_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_2_grad/Switch:1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Merge_2_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/bw/bw/while/Switch_2_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_3_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Switch_3_grad/b_switch&quot;\\n  input: &quot;gradients/b_count_10&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/bw/bw/while/Switch_3_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_3_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Merge_3_grad/Switch&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_3_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_3_grad/Switch&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Merge_3_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/bw/bw/while/Switch_3_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_3_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_3_grad/Switch:1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Merge_3_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/bw/bw/while/Switch_3_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_1_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Switch_1_grad/b_switch&quot;\\n  input: &quot;gradients/b_count_10&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/bw/bw/while/Switch_1_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Merge_1_grad/Switch&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_1_grad/Switch&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Merge_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/bw/bw/while/Switch_1_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_1_grad/Switch:1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Merge_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/bw/bw/while/Switch_1_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/LSTMCellZeroState/zeros_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/LSTMCellZeroState/zeros_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Enter_2_grad/Exit&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/LSTMCellZeroState/zeros_grad/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/zeros_like/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/Identity_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/zeros_like/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/zeros_like/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/Identity_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/zeros_like/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/zeros_like/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Identity_2&quot;\\n  input: &quot;^gradients/Add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/Identity_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/zeros_like/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/zeros_like/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/Identity_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/zeros_like/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/zeros_like/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/Identity_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/zeros_like/b_sync&quot;\\n  op: &quot;ControlTrigger&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/zeros_like/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/Select/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/zeros_like/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/Select/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Select_grad/Select/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul_1/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/mul_1/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul_1/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split_grad/concat/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/StackPop&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/zeros_like&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/zeros_like/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/Select/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/GreaterEqual_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/Select/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/Select/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/GreaterEqual_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/Select/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/Select/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/GreaterEqual_1&quot;\\n  input: &quot;^gradients/Add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/GreaterEqual_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/Select/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/Select/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/GreaterEqual_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/Select/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/Select/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/GreaterEqual_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/Select&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/Select/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_2_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/zeros_like&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/Select_1&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/Select/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/zeros_like&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_2_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/Select&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/Select_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/Select&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/Select&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/Select_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/Select_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/LSTMCellZeroState/zeros_1_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/LSTMCellZeroState/zeros_1_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Enter_3_grad/Exit&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/LSTMCellZeroState/zeros_1_grad/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/zeros_like/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/Identity_3&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/zeros_like/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/zeros_like/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/Identity_3&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/zeros_like/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/zeros_like/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Identity_3&quot;\\n  input: &quot;^gradients/Add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/Identity_3&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/zeros_like/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/zeros_like/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/Identity_3&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/zeros_like/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/zeros_like/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/Identity_3&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/zeros_like&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/zeros_like/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/Select/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/GreaterEqual_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/Select/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/Select/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/GreaterEqual_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/Select/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/Select/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/GreaterEqual_2&quot;\\n  input: &quot;^gradients/Add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/GreaterEqual_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/Select/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/Select/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/GreaterEqual_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/Select/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/Select/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/GreaterEqual_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/Select&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/Select/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_3_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/zeros_like&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/Select_1&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/Select/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/zeros_like&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_3_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/Select&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/Select_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/Select&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/Select&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/Select_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/Select_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayGrad/TensorArrayGradV3/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArray&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  op: &quot;TensorArrayGradV3&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayGrad/TensorArrayGradV3/Enter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_1_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;source&quot;\\n    value {\\n      s: &quot;gradients&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayGrad/gradient_flow&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/Identity&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/Identity&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Identity&quot;\\n  input: &quot;^gradients/Add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/Identity&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/Identity&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/Identity&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3&quot;\\n  op: &quot;TensorArrayReadV3&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayGrad/gradient_flow&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Merge_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Merge_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/Switch_1_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Enter_2_grad/Exit&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_2_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Enter_3_grad/Exit&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_3_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Enter_1_grad/Exit&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_1_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_grad/zeros_like/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_grad/zeros_like&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_grad/zeros_like/Enter&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_grad/Select/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/GreaterEqual&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_grad/Select/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_grad/Select/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/GreaterEqual&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_grad/Select/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_grad/Select/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/GreaterEqual&quot;\\n  input: &quot;^gradients/Add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/GreaterEqual&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_grad/Select/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_grad/Select/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/GreaterEqual&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_grad/Select/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_grad/Select/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/GreaterEqual&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_grad/Select&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_grad/Select/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_grad/zeros_like&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_grad/Select_1&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_grad/Select/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_grad/zeros_like&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Select_grad/Select&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Select_grad/Select_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_grad/Select&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Select_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/Select_grad/Select&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_grad/Select_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/Select_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/Select_grad/Select_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/LSTMCellZeroState/zeros_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/LSTMCellZeroState/zeros_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Enter_2_grad/Exit&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/LSTMCellZeroState/zeros_grad/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/zeros_like/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/Identity_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/zeros_like/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/zeros_like/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/Identity_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/zeros_like/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/zeros_like/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Identity_2&quot;\\n  input: &quot;^gradients/Add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/Identity_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/zeros_like/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/zeros_like/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/Identity_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/zeros_like/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/zeros_like/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/Identity_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/zeros_like/b_sync&quot;\\n  op: &quot;ControlTrigger&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/zeros_like/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/Select/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/zeros_like/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/Select/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Select_grad/Select/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul_1/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/mul_1/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul_1/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split_grad/concat/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/MatMul_1/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/mod/StackPop&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/ShapeN/StackPop&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/zeros_like&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/zeros_like/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/Select/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/GreaterEqual_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/Select/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/Select/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/GreaterEqual_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/Select/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/Select/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/GreaterEqual_1&quot;\\n  input: &quot;^gradients/Add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/GreaterEqual_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/Select/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/Select/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/GreaterEqual_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/Select/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/Select/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/GreaterEqual_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/Select&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/Select/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_2_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/zeros_like&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/Select_1&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/Select/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/zeros_like&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_2_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/Select&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/Select_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/Select&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/Select&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/Select_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/Select_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/LSTMCellZeroState/zeros_1_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/LSTMCellZeroState/zeros_1_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Enter_3_grad/Exit&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/LSTMCellZeroState/zeros_1_grad/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/zeros_like/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/Identity_3&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/zeros_like/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/zeros_like/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/Identity_3&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/zeros_like/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/zeros_like/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Identity_3&quot;\\n  input: &quot;^gradients/Add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/Identity_3&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/zeros_like/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/zeros_like/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/Identity_3&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/zeros_like/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/zeros_like/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/Identity_3&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/zeros_like&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/zeros_like/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/Select/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/GreaterEqual_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/Select/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/Select/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/GreaterEqual_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/Select/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/Select/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/GreaterEqual_2&quot;\\n  input: &quot;^gradients/Add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/GreaterEqual_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/Select/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/Select/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/GreaterEqual_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/Select/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/Select/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/GreaterEqual_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/Select&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/Select/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_3_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/zeros_like&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/Select_1&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/Select/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/zeros_like&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_3_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/Select&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/Select_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/Select&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/Select&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/Select_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/Select_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayGrad/TensorArrayGradV3/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArray&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  op: &quot;TensorArrayGradV3&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayGrad/TensorArrayGradV3/Enter&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_1_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;source&quot;\\n    value {\\n      s: &quot;gradients&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayGrad/gradient_flow&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/Identity&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/Identity&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Identity&quot;\\n  input: &quot;^gradients/Add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/Identity&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/Identity&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/Identity&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3&quot;\\n  op: &quot;TensorArrayReadV3&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayGrad/gradient_flow&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Merge_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Merge_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/bw/bw/while/Switch_1_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select/Enter_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select/Enter_grad/zeros/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select/Enter_grad/zeros&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select/Enter_grad/Shape&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select/Enter_grad/zeros/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select/Enter_grad/b_acc&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select/Enter_grad/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select/Enter_grad/b_acc_1&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select/Enter_grad/b_acc&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select/Enter_grad/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select/Enter_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select/Enter_grad/b_acc_1&quot;\\n  input: &quot;gradients/b_count_6&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select/Enter_grad/Add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select/Enter_grad/Switch:1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select/Enter_grad/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select/Enter_grad/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Select/Enter_grad/b_acc_2&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select/Enter_grad/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_7&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/Select_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Tanh_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/Shape&quot;\\n  input: &quot;^gradients/Add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/RefEnter_1&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPush_1&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/RefEnter_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/Shape_1&quot;\\n  input: &quot;^gradients/Add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPop_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPop_1/RefEnter&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Tanh_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Tanh_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Tanh_1&quot;\\n  input: &quot;^gradients/Add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Tanh_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Tanh_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Tanh_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/AddN_7&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul_1/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul_1/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul_1/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid_2&quot;\\n  input: &quot;^gradients/Add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul_1/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul_1/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul_1/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul_1/StackPop&quot;\\n  input: &quot;gradients/AddN_7&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/Sum_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/Reshape&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/Reshape&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/Reshape_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Switch_1_grad_1/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_grad/zeros_like/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_grad/zeros_like&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_grad/zeros_like/Enter&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_grad/Select/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/GreaterEqual&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_grad/Select/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_grad/Select/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/GreaterEqual&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_grad/Select/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_grad/Select/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/GreaterEqual&quot;\\n  input: &quot;^gradients/Add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/GreaterEqual&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_grad/Select/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_grad/Select/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/GreaterEqual&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_grad/Select/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_grad/Select/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/GreaterEqual&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_grad/Select&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_grad/Select/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_grad/zeros_like&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_grad/Select_1&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_grad/Select/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_grad/zeros_like&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Select_grad/Select&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Select_grad/Select_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_grad/Select&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Select_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/bw/bw/while/Select_grad/Select&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_grad/Select_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/Select_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/bw/bw/while/Select_grad/Select_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/zeros_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/zeros_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select/Enter_grad/b_acc_2&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/zeros_grad/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid_2_grad/SigmoidGrad&quot;\\n  op: &quot;SigmoidGrad&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul_1/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Tanh_1_grad/TanhGrad&quot;\\n  op: &quot;TanhGrad&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/mul/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_2_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select/Enter_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select/Enter_grad/zeros/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select/Enter_grad/zeros&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select/Enter_grad/Shape&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select/Enter_grad/zeros/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select/Enter_grad/b_acc&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select/Enter_grad/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select/Enter_grad/b_acc_1&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select/Enter_grad/b_acc&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select/Enter_grad/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select/Enter_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select/Enter_grad/b_acc_1&quot;\\n  input: &quot;gradients/b_count_10&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select/Enter_grad/Add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select/Enter_grad/Switch:1&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select/Enter_grad/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select/Enter_grad/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Select/Enter_grad/b_acc_2&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select/Enter_grad/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_8&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/Select_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Tanh_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs/RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/Shape&quot;\\n  input: &quot;^gradients/Add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs/RefEnter_1&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs/StackPush_1&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs/RefEnter_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/Shape_1&quot;\\n  input: &quot;^gradients/Add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs/StackPop_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs/StackPop_1/RefEnter&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Tanh_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Tanh_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Tanh_1&quot;\\n  input: &quot;^gradients/Add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Tanh_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Tanh_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Tanh_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/AddN_8&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul_1/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul_1/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul_1/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid_2&quot;\\n  input: &quot;^gradients/Add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul_1/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul_1/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul_1/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul_1/StackPop&quot;\\n  input: &quot;gradients/AddN_8&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/Sum_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/Reshape&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/Reshape&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/Reshape_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Switch_1_grad_1/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_9&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Tanh_1_grad/TanhGrad&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/Select_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/Shape&quot;\\n  input: &quot;^gradients/Add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/RefEnter_1&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPush_1&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/RefEnter_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/Shape_1&quot;\\n  input: &quot;^gradients/Add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPop_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPop_1/RefEnter&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/AddN_9&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/AddN_9&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/Sum_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/Reshape&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/Reshape&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/Reshape_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/zeros_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/zeros_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select/Enter_grad/b_acc_2&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/zeros_grad/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid_2_grad/SigmoidGrad&quot;\\n  op: &quot;SigmoidGrad&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul_1/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Tanh_1_grad/TanhGrad&quot;\\n  op: &quot;TanhGrad&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/mul/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_2_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/Identity_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/Shape&quot;\\n  input: &quot;^gradients/Add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/RefEnter_1&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPush_1&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/RefEnter_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/Shape_1&quot;\\n  input: &quot;^gradients/Add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPop_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPop_1/RefEnter&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/zeros_like/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/mul&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/mul_1/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/mul_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/mul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/mul_1/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/mul_1/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid&quot;\\n  input: &quot;^gradients/Add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/mul_1/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/mul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/mul_1/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/mul_1/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/mul_1/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/mul_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/Sum_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/Reshape&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/Reshape&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/Reshape_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Tanh&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/Shape&quot;\\n  input: &quot;^gradients/Add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/RefEnter_1&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPush_1&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/RefEnter_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/Shape_1&quot;\\n  input: &quot;^gradients/Add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPop_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPop_1/RefEnter&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Tanh&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Tanh&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Tanh&quot;\\n  input: &quot;^gradients/Add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Tanh&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Tanh&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Tanh&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul_1/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul_1/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul_1/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid_1&quot;\\n  input: &quot;^gradients/Add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul_1/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul_1/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul_1/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul_1/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_1_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/Sum_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/Reshape&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/Reshape&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/Reshape_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_10&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Tanh_1_grad/TanhGrad&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/Select_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs/RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/Shape&quot;\\n  input: &quot;^gradients/Add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs/RefEnter_1&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs/StackPush_1&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs/RefEnter_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/Shape_1&quot;\\n  input: &quot;^gradients/Add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs/StackPop_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs/StackPop_1/RefEnter&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/AddN_10&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/AddN_10&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/Sum_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/Reshape&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/Reshape&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/Reshape_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid_grad/SigmoidGrad&quot;\\n  op: &quot;SigmoidGrad&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/mul_1/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_11&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/Select_1_grad/Select&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid_1_grad/SigmoidGrad&quot;\\n  op: &quot;SigmoidGrad&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul_1/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Tanh_grad/TanhGrad&quot;\\n  op: &quot;TanhGrad&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/mul/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/mul_1_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/Identity_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs/RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/Shape&quot;\\n  input: &quot;^gradients/Add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs/RefEnter_1&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs/StackPush_1&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs/RefEnter_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/Shape_1&quot;\\n  input: &quot;^gradients/Add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs/StackPop_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs/StackPop_1/RefEnter&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/zeros_like/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/mul&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/mul_1/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/mul_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/mul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/mul_1/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/mul_1/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid&quot;\\n  input: &quot;^gradients/Add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/mul_1/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/mul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/mul_1/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/mul_1/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/mul_1/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/mul_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/Sum_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/Reshape&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/Reshape&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/Reshape_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Tanh&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs/RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/Shape&quot;\\n  input: &quot;^gradients/Add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs/RefEnter_1&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs/StackPush_1&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs/RefEnter_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/Shape_1&quot;\\n  input: &quot;^gradients/Add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs/StackPop_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs/StackPop_1/RefEnter&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Tanh&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Tanh&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Tanh&quot;\\n  input: &quot;^gradients/Add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Tanh&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Tanh&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Tanh&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul_1/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul_1/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul_1/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid_1&quot;\\n  input: &quot;^gradients/Add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul_1/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul_1/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul_1/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul_1/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_1_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/Sum_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/BroadcastGradientArgs/StackPop_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/Reshape&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/Reshape&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/Reshape_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split:2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs/RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/Shape&quot;\\n  input: &quot;^gradients/Add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid_grad/SigmoidGrad&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid_grad/SigmoidGrad&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/Sum_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/Reshape&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/Reshape&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/Reshape_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Switch_2_grad_1/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/AddN_11&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid_grad/SigmoidGrad&quot;\\n  op: &quot;SigmoidGrad&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/mul_1/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_12&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/bw/bw/while/Select_1_grad/Select&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid_1_grad/SigmoidGrad&quot;\\n  op: &quot;SigmoidGrad&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul_1/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Tanh_grad/TanhGrad&quot;\\n  op: &quot;TanhGrad&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/mul/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/mul_1_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split_grad/concat/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split/split_dim&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split_grad/concat/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split_grad/concat/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split/split_dim&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split_grad/concat/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split_grad/concat/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split/split_dim&quot;\\n  input: &quot;^gradients/Add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split/split_dim&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split_grad/concat/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split_grad/concat/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split/split_dim&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split_grad/concat/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split_grad/concat/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split/split_dim&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split_grad/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid_1_grad/SigmoidGrad&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Tanh_grad/TanhGrad&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/add_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/Sigmoid_2_grad/SigmoidGrad&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split_grad/concat/StackPop&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 4\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split:2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/BroadcastGradientArgs/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/BroadcastGradientArgs/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/BroadcastGradientArgs/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/BroadcastGradientArgs/RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/Shape&quot;\\n  input: &quot;^gradients/Add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/BroadcastGradientArgs/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/BroadcastGradientArgs/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/BroadcastGradientArgs/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/BroadcastGradientArgs/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid_grad/SigmoidGrad&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/BroadcastGradientArgs/StackPop&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid_grad/SigmoidGrad&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/Sum_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/Reshape&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/Reshape&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/Reshape_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Switch_2_grad_1/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/AddN_12&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd_grad/BiasAddGrad&quot;\\n  op: &quot;BiasAddGrad&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split_grad/concat&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split_grad/concat&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd_grad/BiasAddGrad&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split_grad/concat&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/split_grad/concat&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd_grad/BiasAddGrad&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd_grad/BiasAddGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split_grad/concat/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split/split_dim&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split_grad/concat/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split_grad/concat/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split/split_dim&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split_grad/concat/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split_grad/concat/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split/split_dim&quot;\\n  input: &quot;^gradients/Add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split/split_dim&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split_grad/concat/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split_grad/concat/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split/split_dim&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split_grad/concat/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split_grad/concat/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split/split_dim&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split_grad/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid_1_grad/SigmoidGrad&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Tanh_grad/TanhGrad&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/add_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/Sigmoid_2_grad/SigmoidGrad&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split_grad/concat/StackPop&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 4\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat&quot;\\n  input: &quot;^gradients/Add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/b_acc&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 64\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/b_acc_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/b_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/b_acc_2&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/b_acc_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/b_acc_2&quot;\\n  input: &quot;gradients/b_count_6&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/Add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/Switch:1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/b_acc_3&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd_grad/BiasAddGrad&quot;\\n  op: &quot;BiasAddGrad&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split_grad/concat&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split_grad/concat&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd_grad/BiasAddGrad&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split_grad/concat&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/split_grad/concat&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd_grad/BiasAddGrad&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd_grad/BiasAddGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/Rank&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat/axis&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat/axis&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat/axis&quot;\\n  input: &quot;^gradients/Add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat/axis&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat/axis&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat/axis&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod&quot;\\n  op: &quot;FloorMod&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/Rank&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/TensorArrayReadV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/TensorArrayReadV3&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/TensorArrayReadV3&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/TensorArrayReadV3&quot;\\n  input: &quot;^gradients/Add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/TensorArrayReadV3&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/TensorArrayReadV3&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/TensorArrayReadV3&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN&quot;\\n  op: &quot;ShapeN&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/zeros_like/StackPop&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/ConcatOffset&quot;\\n  op: &quot;ConcatOffset&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/mod&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN:1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/Slice&quot;\\n  op: &quot;Slice&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/ConcatOffset&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/Slice_1&quot;\\n  op: &quot;Slice&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/ConcatOffset:1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/ShapeN:1&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/Slice&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/Slice_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/Slice&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/Slice&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/Slice_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/Slice_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/b_acc&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 36\\n          }\\n          dim {\\n            size: 64\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/b_acc_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/b_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/b_acc_2&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/b_acc_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/b_acc_2&quot;\\n  input: &quot;gradients/b_count_6&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/Add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/Switch:1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/b_acc_3&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/MatMul/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/MatMul/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/MatMul_1/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/MatMul_1/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/MatMul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/MatMul_1/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/MatMul_1/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat&quot;\\n  input: &quot;^gradients/Add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/MatMul_1/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/MatMul_1/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/MatMul_1/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/MatMul_1/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/MatMul_1/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd/Enter_grad/b_acc&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 64\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd/Enter_grad/b_acc_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd/Enter_grad/b_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd/Enter_grad/b_acc_2&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd/Enter_grad/b_acc_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd/Enter_grad/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd/Enter_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd/Enter_grad/b_acc_2&quot;\\n  input: &quot;gradients/b_count_10&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd/Enter_grad/Add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd/Enter_grad/Switch:1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd/Enter_grad/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd/Enter_grad/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd/Enter_grad/b_acc_3&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd/Enter_grad/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArray_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3/Enter_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  op: &quot;TensorArrayGradV3&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3/Enter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3/Enter_1&quot;\\n  input: &quot;^gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;source&quot;\\n    value {\\n      s: &quot;gradients&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3_grad/TensorArrayGrad/gradient_flow&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3/Enter_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3_grad/TensorArrayWrite/TensorArrayWriteV3&quot;\\n  op: &quot;TensorArrayWriteV3&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3_grad/TensorArrayGrad/gradient_flow&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_13&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/concat_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/Select_2_grad/Select&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/Rank&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/mod/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat/axis&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/mod/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/mod/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat/axis&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/mod/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/mod/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat/axis&quot;\\n  input: &quot;^gradients/Add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat/axis&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/mod/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/mod/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat/axis&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/mod/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/mod/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat/axis&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/mod&quot;\\n  op: &quot;FloorMod&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/mod/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/Rank&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/TensorArrayReadV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/ShapeN/f_acc&quot;\\n  op: &quot;Stack&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/TensorArrayReadV3&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/ShapeN/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/ShapeN/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/TensorArrayReadV3&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/ShapeN/StackPush&quot;\\n  op: &quot;StackPush&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/ShapeN/RefEnter&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/while/TensorArrayReadV3&quot;\\n  input: &quot;^gradients/Add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/TensorArrayReadV3&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/ShapeN/StackPop/RefEnter&quot;\\n  op: &quot;RefEnter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/ShapeN/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/TensorArrayReadV3&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/ShapeN/StackPop&quot;\\n  op: &quot;StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/ShapeN/StackPop/RefEnter&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/TensorArrayReadV3&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/ShapeN&quot;\\n  op: &quot;ShapeN&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/ShapeN/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/zeros_like/StackPop&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/ConcatOffset&quot;\\n  op: &quot;ConcatOffset&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/mod&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/ShapeN&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/ShapeN:1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/Slice&quot;\\n  op: &quot;Slice&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/ConcatOffset&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/ShapeN&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/Slice_1&quot;\\n  op: &quot;Slice&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/ConcatOffset:1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/ShapeN:1&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/Slice&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/Slice_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/Slice&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/Slice&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/Slice_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/Slice_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul/Enter_grad/b_acc&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 36\\n          }\\n          dim {\\n            size: 64\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul/Enter_grad/b_acc_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul/Enter_grad/b_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul/Enter_grad/b_acc_2&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul/Enter_grad/b_acc_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul/Enter_grad/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul/Enter_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul/Enter_grad/b_acc_2&quot;\\n  input: &quot;gradients/b_count_10&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul/Enter_grad/Add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul/Enter_grad/Switch:1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul/Enter_grad/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul/Enter_grad/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul/Enter_grad/b_acc_3&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul/Enter_grad/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_14&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/b_acc_3&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/BiasAdd/Enter_grad/b_acc_3&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/b_acc_3&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1_grad/b_acc&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1_grad/b_acc_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1_grad/b_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/fw/fw/while/bidirectional_rnn/fw/fw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1_grad/b_acc_2&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1_grad/b_acc_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1_grad/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1_grad/b_acc_2&quot;\\n  input: &quot;gradients/b_count_6&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1_grad/Add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1_grad/Switch:1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3_grad/TensorArrayWrite/TensorArrayWriteV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1_grad/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1_grad/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1_grad/b_acc_3&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1_grad/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/while/Switch_3_grad_1/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/AddN_13&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArray_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3/Enter_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  op: &quot;TensorArrayGradV3&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3/Enter&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3/Enter_1&quot;\\n  input: &quot;^gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;source&quot;\\n    value {\\n      s: &quot;gradients&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3_grad/TensorArrayGrad/gradient_flow&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3/Enter_1&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3_grad/TensorArrayWrite/TensorArrayWriteV3&quot;\\n  op: &quot;TensorArrayWriteV3&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPop&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3_grad/TensorArrayGrad/gradient_flow&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_15&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/concat_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/bw/bw/while/Select_2_grad/Select&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_16&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/b_acc_3&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell_1/lstm_cell/MatMul/Enter_grad/b_acc_3&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/fw/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/b_acc_3&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  op: &quot;TensorArrayGradV3&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArray_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1_grad/b_acc_3&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/TensorArray_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;source&quot;\\n    value {\\n      s: &quot;gradients&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGrad/gradient_flow&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1_grad/b_acc_3&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/fw/TensorArray_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGatherV3&quot;\\n  op: &quot;TensorArrayGatherV3&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  input: &quot;bidirectional_rnn/fw/fw/TensorArrayUnstack/range&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGrad/gradient_flow&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;element_shape&quot;\\n    value {\\n      shape {\\n        unknown_rank: true\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1_grad/b_acc_3&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGatherV3&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGatherV3&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGatherV3&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/fw/fw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1_grad/b_acc_3&quot;\\n  input: &quot;^gradients/bidirectional_rnn/fw/fw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1_grad/b_acc_3&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter_1_grad/b_acc&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter_1_grad/b_acc_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter_1_grad/b_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;gradients/bidirectional_rnn/bw/bw/while/bidirectional_rnn/bw/bw/while/&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter_1_grad/b_acc_2&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter_1_grad/b_acc_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter_1_grad/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter_1_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter_1_grad/b_acc_2&quot;\\n  input: &quot;gradients/b_count_10&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter_1_grad/Add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter_1_grad/Switch:1&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3_grad/TensorArrayWrite/TensorArrayWriteV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter_1_grad/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter_1_grad/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter_1_grad/b_acc_3&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter_1_grad/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/while/Switch_3_grad_1/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;gradients/AddN_15&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  op: &quot;TensorArrayGradV3&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArray_1&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter_1_grad/b_acc_3&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/TensorArray_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;source&quot;\\n    value {\\n      s: &quot;gradients&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGrad/gradient_flow&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter_1_grad/b_acc_3&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/bw/bw/TensorArray_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGatherV3&quot;\\n  op: &quot;TensorArrayGatherV3&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGrad/TensorArrayGradV3&quot;\\n  input: &quot;bidirectional_rnn/bw/bw/TensorArrayUnstack/range&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGrad/gradient_flow&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;element_shape&quot;\\n    value {\\n      shape {\\n        unknown_rank: true\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter_1_grad/b_acc_3&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGatherV3&quot;\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGatherV3&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/bw/bw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGatherV3&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/bw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter_1_grad/b_acc_3&quot;\\n  input: &quot;^gradients/bidirectional_rnn/bw/bw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter_1_grad/b_acc_3&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/bidirectional_rnn/bw/ReverseSequence_grad/ReverseSequence&quot;\\n  op: &quot;ReverseSequence&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/bw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/tuple/control_dependency&quot;\\n  input: &quot;encoder_inputs_length&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tlen&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;batch_dim&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;seq_dim&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_17&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/bidirectional_rnn/fw/fw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/bidirectional_rnn/bw/ReverseSequence_grad/ReverseSequence&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/bidirectional_rnn/fw/fw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGatherV3&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/embedding_lookup_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT64\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\n\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\024\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/embedding_lookup_grad/ToInt32&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;gradients/embedding_lookup_grad/Shape&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/embedding_lookup_grad/Size&quot;\\n  op: &quot;Size&quot;\\n  input: &quot;encoder_inputs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/embedding_lookup_grad/ExpandDims/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/embedding_lookup_grad/ExpandDims&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;gradients/embedding_lookup_grad/Size&quot;\\n  input: &quot;gradients/embedding_lookup_grad/ExpandDims/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/embedding_lookup_grad/strided_slice/stack&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/embedding_lookup_grad/strided_slice/stack_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/embedding_lookup_grad/strided_slice/stack_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/embedding_lookup_grad/strided_slice&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;gradients/embedding_lookup_grad/ToInt32&quot;\\n  input: &quot;gradients/embedding_lookup_grad/strided_slice/stack&quot;\\n  input: &quot;gradients/embedding_lookup_grad/strided_slice/stack_1&quot;\\n  input: &quot;gradients/embedding_lookup_grad/strided_slice/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/embedding_lookup_grad/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/embedding_lookup_grad/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;gradients/embedding_lookup_grad/ExpandDims&quot;\\n  input: &quot;gradients/embedding_lookup_grad/strided_slice&quot;\\n  input: &quot;gradients/embedding_lookup_grad/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/embedding_lookup_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/AddN_17&quot;\\n  input: &quot;gradients/embedding_lookup_grad/concat&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/embedding_lookup_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;encoder_inputs&quot;\\n  input: &quot;gradients/embedding_lookup_grad/ExpandDims&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;gradients/embedding_lookup_1_grad/Reshape&quot;\\n  input: &quot;gradients/embedding_lookup_grad/Reshape&quot;\\n  input: &quot;gradients/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_1/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/concat_1&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;gradients/embedding_lookup_1_grad/Reshape_1&quot;\\n  input: &quot;gradients/embedding_lookup_grad/Reshape_1&quot;\\n  input: &quot;gradients/concat_1/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;beta1_power/initial_value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.899999976158\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;beta1_power&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;beta1_power/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;beta1_power&quot;\\n  input: &quot;beta1_power/initial_value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;beta1_power/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;beta1_power&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;beta2_power/initial_value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.999000012875\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;beta2_power&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;beta2_power/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;beta2_power&quot;\\n  input: &quot;beta2_power/initial_value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;beta2_power/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;beta2_power&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Variable/Adam/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 10\\n          }\\n          dim {\\n            size: 20\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Variable/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 10\\n        }\\n        dim {\\n          size: 20\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Variable/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Variable/Adam&quot;\\n  input: &quot;Variable/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Variable/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Variable/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Variable/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 10\\n          }\\n          dim {\\n            size: 20\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Variable/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 10\\n        }\\n        dim {\\n          size: 20\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Variable/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Variable/Adam_1&quot;\\n  input: &quot;Variable/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Variable/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Variable/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Adam/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 36\\n          }\\n          dim {\\n            size: 64\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 36\\n        }\\n        dim {\\n          size: 64\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Adam&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 36\\n          }\\n          dim {\\n            size: 64\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 36\\n        }\\n        dim {\\n          size: 64\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Adam_1&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/bias/Adam/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 64\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/bias/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 64\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/bias/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/bias/Adam&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/bias/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/bias/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/bias/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/bias/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 64\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/bias/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 64\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/bias/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/bias/Adam_1&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/bias/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bidirectional_rnn/fw/lstm_cell/bias/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/bias/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;memory_layer/kernel/Adam/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@memory_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 32\\n          }\\n          dim {\\n            size: 32\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;memory_layer/kernel/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@memory_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 32\\n        }\\n        dim {\\n          size: 32\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;memory_layer/kernel/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;memory_layer/kernel/Adam&quot;\\n  input: &quot;memory_layer/kernel/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@memory_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;memory_layer/kernel/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;memory_layer/kernel/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@memory_layer/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;memory_layer/kernel/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@memory_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 32\\n          }\\n          dim {\\n            size: 32\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;memory_layer/kernel/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@memory_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 32\\n        }\\n        dim {\\n          size: 32\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;memory_layer/kernel/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;memory_layer/kernel/Adam_1&quot;\\n  input: &quot;memory_layer/kernel/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@memory_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;memory_layer/kernel/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;memory_layer/kernel/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@memory_layer/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/kernel/Adam/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 84\\n          }\\n          dim {\\n            size: 128\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/kernel/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 84\\n        }\\n        dim {\\n          size: 128\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/kernel/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/kernel/Adam&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/kernel/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/kernel/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/kernel/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/kernel/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 84\\n          }\\n          dim {\\n            size: 128\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/kernel/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 84\\n        }\\n        dim {\\n          size: 128\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/kernel/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/kernel/Adam_1&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/kernel/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/kernel/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/kernel/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/bias/Adam/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 128\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/bias/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 128\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/bias/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/bias/Adam&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/bias/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/bias/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/bias/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/bias/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 128\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/bias/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 128\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/bias/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/bias/Adam_1&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/bias/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/lstm_cell/bias/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/bias/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/attention_layer/kernel/Adam/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/attention_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 64\\n          }\\n          dim {\\n            size: 32\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/attention_layer/kernel/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/attention_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 64\\n        }\\n        dim {\\n          size: 32\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/attention_layer/kernel/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;decoder/attention_wrapper/attention_layer/kernel/Adam&quot;\\n  input: &quot;decoder/attention_wrapper/attention_layer/kernel/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/attention_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/attention_layer/kernel/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/attention_wrapper/attention_layer/kernel/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/attention_layer/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/attention_layer/kernel/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/attention_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 64\\n          }\\n          dim {\\n            size: 32\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/attention_layer/kernel/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/attention_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 64\\n        }\\n        dim {\\n          size: 32\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/attention_layer/kernel/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;decoder/attention_wrapper/attention_layer/kernel/Adam_1&quot;\\n  input: &quot;decoder/attention_wrapper/attention_layer/kernel/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/attention_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/attention_wrapper/attention_layer/kernel/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/attention_wrapper/attention_layer/kernel/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/attention_layer/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/kernel/Adam/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 32\\n          }\\n          dim {\\n            size: 10\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/kernel/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 32\\n        }\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/kernel/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;decoder/dense/kernel/Adam&quot;\\n  input: &quot;decoder/dense/kernel/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/kernel/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/dense/kernel/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/kernel/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 32\\n          }\\n          dim {\\n            size: 10\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/kernel/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 32\\n        }\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/kernel/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;decoder/dense/kernel/Adam_1&quot;\\n  input: &quot;decoder/dense/kernel/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/kernel/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/dense/kernel/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/bias/Adam/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 10\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/bias/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/bias/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;decoder/dense/bias/Adam&quot;\\n  input: &quot;decoder/dense/bias/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/bias/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/dense/bias/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/bias/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 10\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/bias/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/bias/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;decoder/dense/bias/Adam_1&quot;\\n  input: &quot;decoder/dense/bias/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;decoder/dense/bias/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;decoder/dense/bias/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/learning_rate&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0010000000475\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/beta1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.899999976158\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/beta2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.999000012875\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/epsilon&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 9.99999993923e-09\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/Unique&quot;\\n  op: &quot;Unique&quot;\\n  input: &quot;gradients/concat_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;out_idx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Adam/update_Variable/Unique&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/strided_slice/stack&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/strided_slice/stack_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/strided_slice/stack_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/strided_slice&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;Adam/update_Variable/Shape&quot;\\n  input: &quot;Adam/update_Variable/strided_slice/stack&quot;\\n  input: &quot;Adam/update_Variable/strided_slice/stack_1&quot;\\n  input: &quot;Adam/update_Variable/strided_slice/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/UnsortedSegmentSum&quot;\\n  op: &quot;UnsortedSegmentSum&quot;\\n  input: &quot;gradients/concat&quot;\\n  input: &quot;Adam/update_Variable/Unique:1&quot;\\n  input: &quot;Adam/update_Variable/strided_slice&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tindices&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/sub/x&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;Adam/update_Variable/sub/x&quot;\\n  input: &quot;beta2_power/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/Sqrt&quot;\\n  op: &quot;Sqrt&quot;\\n  input: &quot;Adam/update_Variable/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Adam/learning_rate&quot;\\n  input: &quot;Adam/update_Variable/Sqrt&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/sub_1/x&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/sub_1&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;Adam/update_Variable/sub_1/x&quot;\\n  input: &quot;beta1_power/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/truediv&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;Adam/update_Variable/mul&quot;\\n  input: &quot;Adam/update_Variable/sub_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/sub_2/x&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/sub_2&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;Adam/update_Variable/sub_2/x&quot;\\n  input: &quot;Adam/beta1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Adam/update_Variable/UnsortedSegmentSum&quot;\\n  input: &quot;Adam/update_Variable/sub_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/mul_2&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Variable/Adam/read&quot;\\n  input: &quot;Adam/beta1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Variable/Adam&quot;\\n  input: &quot;Adam/update_Variable/mul_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/ScatterAdd&quot;\\n  op: &quot;ScatterAdd&quot;\\n  input: &quot;Variable/Adam&quot;\\n  input: &quot;Adam/update_Variable/Unique&quot;\\n  input: &quot;Adam/update_Variable/mul_1&quot;\\n  input: &quot;^Adam/update_Variable/Assign&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tindices&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/mul_3&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Adam/update_Variable/UnsortedSegmentSum&quot;\\n  input: &quot;Adam/update_Variable/UnsortedSegmentSum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/sub_3/x&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/sub_3&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;Adam/update_Variable/sub_3/x&quot;\\n  input: &quot;Adam/beta2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/mul_4&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Adam/update_Variable/mul_3&quot;\\n  input: &quot;Adam/update_Variable/sub_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/mul_5&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Variable/Adam_1/read&quot;\\n  input: &quot;Adam/beta2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/Assign_1&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Variable/Adam_1&quot;\\n  input: &quot;Adam/update_Variable/mul_5&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/ScatterAdd_1&quot;\\n  op: &quot;ScatterAdd&quot;\\n  input: &quot;Variable/Adam_1&quot;\\n  input: &quot;Adam/update_Variable/Unique&quot;\\n  input: &quot;Adam/update_Variable/mul_4&quot;\\n  input: &quot;^Adam/update_Variable/Assign_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tindices&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/Sqrt_1&quot;\\n  op: &quot;Sqrt&quot;\\n  input: &quot;Adam/update_Variable/ScatterAdd_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/mul_6&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Adam/update_Variable/truediv&quot;\\n  input: &quot;Adam/update_Variable/ScatterAdd&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;Adam/update_Variable/Sqrt_1&quot;\\n  input: &quot;Adam/epsilon&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/truediv_1&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;Adam/update_Variable/mul_6&quot;\\n  input: &quot;Adam/update_Variable/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/AssignSub&quot;\\n  op: &quot;AssignSub&quot;\\n  input: &quot;Variable&quot;\\n  input: &quot;Adam/update_Variable/truediv_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_Variable/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^Adam/update_Variable/AssignSub&quot;\\n  input: &quot;^Adam/update_Variable/ScatterAdd&quot;\\n  input: &quot;^Adam/update_Variable/ScatterAdd_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_bidirectional_rnn/fw/lstm_cell/kernel/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/kernel&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Adam&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/kernel/Adam_1&quot;\\n  input: &quot;beta1_power/read&quot;\\n  input: &quot;beta2_power/read&quot;\\n  input: &quot;Adam/learning_rate&quot;\\n  input: &quot;Adam/beta1&quot;\\n  input: &quot;Adam/beta2&quot;\\n  input: &quot;Adam/epsilon&quot;\\n  input: &quot;gradients/AddN_16&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_bidirectional_rnn/fw/lstm_cell/bias/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/bias&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/bias/Adam&quot;\\n  input: &quot;bidirectional_rnn/fw/lstm_cell/bias/Adam_1&quot;\\n  input: &quot;beta1_power/read&quot;\\n  input: &quot;beta2_power/read&quot;\\n  input: &quot;Adam/learning_rate&quot;\\n  input: &quot;Adam/beta1&quot;\\n  input: &quot;Adam/beta2&quot;\\n  input: &quot;Adam/epsilon&quot;\\n  input: &quot;gradients/AddN_14&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bidirectional_rnn/fw/lstm_cell/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_memory_layer/kernel/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;memory_layer/kernel&quot;\\n  input: &quot;memory_layer/kernel/Adam&quot;\\n  input: &quot;memory_layer/kernel/Adam_1&quot;\\n  input: &quot;beta1_power/read&quot;\\n  input: &quot;beta2_power/read&quot;\\n  input: &quot;Adam/learning_rate&quot;\\n  input: &quot;Adam/beta1&quot;\\n  input: &quot;Adam/beta2&quot;\\n  input: &quot;Adam/epsilon&quot;\\n  input: &quot;gradients/LuongAttention/memory_layer/Tensordot/transpose_1_grad/transpose&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@memory_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_decoder/attention_wrapper/lstm_cell/kernel/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/kernel&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/kernel/Adam&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/kernel/Adam_1&quot;\\n  input: &quot;beta1_power/read&quot;\\n  input: &quot;beta2_power/read&quot;\\n  input: &quot;Adam/learning_rate&quot;\\n  input: &quot;Adam/beta1&quot;\\n  input: &quot;Adam/beta2&quot;\\n  input: &quot;Adam/epsilon&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/MatMul/Enter_grad/b_acc_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_decoder/attention_wrapper/lstm_cell/bias/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/bias&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/bias/Adam&quot;\\n  input: &quot;decoder/attention_wrapper/lstm_cell/bias/Adam_1&quot;\\n  input: &quot;beta1_power/read&quot;\\n  input: &quot;beta2_power/read&quot;\\n  input: &quot;Adam/learning_rate&quot;\\n  input: &quot;Adam/beta1&quot;\\n  input: &quot;Adam/beta2&quot;\\n  input: &quot;Adam/epsilon&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_wrapper/lstm_cell/lstm_cell/lstm_cell/BiasAdd/Enter_grad/b_acc_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/lstm_cell/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_decoder/attention_wrapper/attention_layer/kernel/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;decoder/attention_wrapper/attention_layer/kernel&quot;\\n  input: &quot;decoder/attention_wrapper/attention_layer/kernel/Adam&quot;\\n  input: &quot;decoder/attention_wrapper/attention_layer/kernel/Adam_1&quot;\\n  input: &quot;beta1_power/read&quot;\\n  input: &quot;beta2_power/read&quot;\\n  input: &quot;Adam/learning_rate&quot;\\n  input: &quot;Adam/beta1&quot;\\n  input: &quot;Adam/beta2&quot;\\n  input: &quot;Adam/epsilon&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/decoder/attention_wrapper/attention_layer/MatMul/Enter_grad/b_acc_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/attention_wrapper/attention_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_decoder/dense/kernel/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;decoder/dense/kernel&quot;\\n  input: &quot;decoder/dense/kernel/Adam&quot;\\n  input: &quot;decoder/dense/kernel/Adam_1&quot;\\n  input: &quot;beta1_power/read&quot;\\n  input: &quot;beta2_power/read&quot;\\n  input: &quot;Adam/learning_rate&quot;\\n  input: &quot;Adam/beta1&quot;\\n  input: &quot;Adam/beta2&quot;\\n  input: &quot;Adam/epsilon&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/MatMul/Enter_grad/b_acc_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_decoder/dense/bias/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;decoder/dense/bias&quot;\\n  input: &quot;decoder/dense/bias/Adam&quot;\\n  input: &quot;decoder/dense/bias/Adam_1&quot;\\n  input: &quot;beta1_power/read&quot;\\n  input: &quot;beta2_power/read&quot;\\n  input: &quot;Adam/learning_rate&quot;\\n  input: &quot;Adam/beta1&quot;\\n  input: &quot;Adam/beta2&quot;\\n  input: &quot;Adam/epsilon&quot;\\n  input: &quot;gradients/decoder/while/BasicDecoderStep/dense/BiasAdd/Enter_grad/b_acc_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@decoder/dense/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;beta1_power/read&quot;\\n  input: &quot;Adam/beta1&quot;\\n  input: &quot;^Adam/update_Variable/group_deps&quot;\\n  input: &quot;^Adam/update_bidirectional_rnn/fw/lstm_cell/kernel/ApplyAdam&quot;\\n  input: &quot;^Adam/update_bidirectional_rnn/fw/lstm_cell/bias/ApplyAdam&quot;\\n  input: &quot;^Adam/update_memory_layer/kernel/ApplyAdam&quot;\\n  input: &quot;^Adam/update_decoder/attention_wrapper/lstm_cell/kernel/ApplyAdam&quot;\\n  input: &quot;^Adam/update_decoder/attention_wrapper/lstm_cell/bias/ApplyAdam&quot;\\n  input: &quot;^Adam/update_decoder/attention_wrapper/attention_layer/kernel/ApplyAdam&quot;\\n  input: &quot;^Adam/update_decoder/dense/kernel/ApplyAdam&quot;\\n  input: &quot;^Adam/update_decoder/dense/bias/ApplyAdam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;beta1_power&quot;\\n  input: &quot;Adam/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;beta2_power/read&quot;\\n  input: &quot;Adam/beta2&quot;\\n  input: &quot;^Adam/update_Variable/group_deps&quot;\\n  input: &quot;^Adam/update_bidirectional_rnn/fw/lstm_cell/kernel/ApplyAdam&quot;\\n  input: &quot;^Adam/update_bidirectional_rnn/fw/lstm_cell/bias/ApplyAdam&quot;\\n  input: &quot;^Adam/update_memory_layer/kernel/ApplyAdam&quot;\\n  input: &quot;^Adam/update_decoder/attention_wrapper/lstm_cell/kernel/ApplyAdam&quot;\\n  input: &quot;^Adam/update_decoder/attention_wrapper/lstm_cell/bias/ApplyAdam&quot;\\n  input: &quot;^Adam/update_decoder/attention_wrapper/attention_layer/kernel/ApplyAdam&quot;\\n  input: &quot;^Adam/update_decoder/dense/kernel/ApplyAdam&quot;\\n  input: &quot;^Adam/update_decoder/dense/bias/ApplyAdam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/Assign_1&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;beta2_power&quot;\\n  input: &quot;Adam/mul_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^Adam/update_Variable/group_deps&quot;\\n  input: &quot;^Adam/update_bidirectional_rnn/fw/lstm_cell/kernel/ApplyAdam&quot;\\n  input: &quot;^Adam/update_bidirectional_rnn/fw/lstm_cell/bias/ApplyAdam&quot;\\n  input: &quot;^Adam/update_memory_layer/kernel/ApplyAdam&quot;\\n  input: &quot;^Adam/update_decoder/attention_wrapper/lstm_cell/kernel/ApplyAdam&quot;\\n  input: &quot;^Adam/update_decoder/attention_wrapper/lstm_cell/bias/ApplyAdam&quot;\\n  input: &quot;^Adam/update_decoder/attention_wrapper/attention_layer/kernel/ApplyAdam&quot;\\n  input: &quot;^Adam/update_decoder/dense/kernel/ApplyAdam&quot;\\n  input: &quot;^Adam/update_decoder/dense/bias/ApplyAdam&quot;\\n  input: &quot;^Adam/Assign&quot;\\n  input: &quot;^Adam/Assign_1&quot;\\n}\\nnode {\\n  name: &quot;init&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^Variable/Assign&quot;\\n  input: &quot;^bidirectional_rnn/fw/lstm_cell/kernel/Assign&quot;\\n  input: &quot;^bidirectional_rnn/fw/lstm_cell/bias/Assign&quot;\\n  input: &quot;^memory_layer/kernel/Assign&quot;\\n  input: &quot;^decoder/attention_wrapper/lstm_cell/kernel/Assign&quot;\\n  input: &quot;^decoder/attention_wrapper/lstm_cell/bias/Assign&quot;\\n  input: &quot;^decoder/attention_wrapper/attention_layer/kernel/Assign&quot;\\n  input: &quot;^decoder/dense/kernel/Assign&quot;\\n  input: &quot;^decoder/dense/bias/Assign&quot;\\n  input: &quot;^beta1_power/Assign&quot;\\n  input: &quot;^beta2_power/Assign&quot;\\n  input: &quot;^Variable/Adam/Assign&quot;\\n  input: &quot;^Variable/Adam_1/Assign&quot;\\n  input: &quot;^bidirectional_rnn/fw/lstm_cell/kernel/Adam/Assign&quot;\\n  input: &quot;^bidirectional_rnn/fw/lstm_cell/kernel/Adam_1/Assign&quot;\\n  input: &quot;^bidirectional_rnn/fw/lstm_cell/bias/Adam/Assign&quot;\\n  input: &quot;^bidirectional_rnn/fw/lstm_cell/bias/Adam_1/Assign&quot;\\n  input: &quot;^memory_layer/kernel/Adam/Assign&quot;\\n  input: &quot;^memory_layer/kernel/Adam_1/Assign&quot;\\n  input: &quot;^decoder/attention_wrapper/lstm_cell/kernel/Adam/Assign&quot;\\n  input: &quot;^decoder/attention_wrapper/lstm_cell/kernel/Adam_1/Assign&quot;\\n  input: &quot;^decoder/attention_wrapper/lstm_cell/bias/Adam/Assign&quot;\\n  input: &quot;^decoder/attention_wrapper/lstm_cell/bias/Adam_1/Assign&quot;\\n  input: &quot;^decoder/attention_wrapper/attention_layer/kernel/Adam/Assign&quot;\\n  input: &quot;^decoder/attention_wrapper/attention_layer/kernel/Adam_1/Assign&quot;\\n  input: &quot;^decoder/dense/kernel/Adam/Assign&quot;\\n  input: &quot;^decoder/dense/kernel/Adam_1/Assign&quot;\\n  input: &quot;^decoder/dense/bias/Adam/Assign&quot;\\n  input: &quot;^decoder/dense/bias/Adam_1/Assign&quot;\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.324218408367&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_graph(tf.get_default_graph().as_graph_def())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
